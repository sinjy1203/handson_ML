{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_train = x_train_full[:5000] / 255., x_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 328,810\n",
      "Trainable params: 328,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = []\n",
    "layer += [keras.layers.Flatten(input_shape=(28, 28))]\n",
    "for i in range(3):\n",
    "    if i == 2:\n",
    "        layer += [keras.layers.Dense(10, activation='softmax')] \n",
    "    else:\n",
    "        layer += [keras.layers.Dense(300, activation='relu')]\n",
    "model2 = keras.models.Sequential(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 328,810\n",
      "Trainable params: 328,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x176e0730208>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x176e0730ec8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x176eea45548>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x176eea605c8>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7192 - accuracy: 0.7665 - val_loss: 0.5005 - val_accuracy: 0.8324\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4865 - accuracy: 0.8318 - val_loss: 0.4475 - val_accuracy: 0.8540\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4419 - accuracy: 0.8451 - val_loss: 0.4137 - val_accuracy: 0.8622\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4141 - accuracy: 0.8553 - val_loss: 0.4144 - val_accuracy: 0.8596\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3949 - accuracy: 0.8610 - val_loss: 0.4526 - val_accuracy: 0.8306\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3788 - accuracy: 0.8666 - val_loss: 0.3734 - val_accuracy: 0.8722\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3659 - accuracy: 0.8703 - val_loss: 0.3633 - val_accuracy: 0.8754\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3530 - accuracy: 0.8750 - val_loss: 0.3720 - val_accuracy: 0.8686\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3429 - accuracy: 0.8773 - val_loss: 0.3633 - val_accuracy: 0.8708\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3337 - accuracy: 0.8803 - val_loss: 0.3388 - val_accuracy: 0.8774\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3250 - accuracy: 0.8837 - val_loss: 0.3479 - val_accuracy: 0.8780\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3179 - accuracy: 0.8862 - val_loss: 0.3425 - val_accuracy: 0.8782\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3091 - accuracy: 0.8889 - val_loss: 0.3262 - val_accuracy: 0.8844\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3031 - accuracy: 0.8917 - val_loss: 0.3280 - val_accuracy: 0.8812\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2962 - accuracy: 0.8925 - val_loss: 0.3147 - val_accuracy: 0.8858\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2914 - accuracy: 0.8951 - val_loss: 0.3280 - val_accuracy: 0.8824\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2843 - accuracy: 0.8977 - val_loss: 0.3138 - val_accuracy: 0.8870\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2782 - accuracy: 0.8988 - val_loss: 0.3157 - val_accuracy: 0.8884\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2736 - accuracy: 0.9018 - val_loss: 0.3240 - val_accuracy: 0.8848\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2679 - accuracy: 0.9043 - val_loss: 0.3143 - val_accuracy: 0.8882\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2637 - accuracy: 0.9044 - val_loss: 0.3117 - val_accuracy: 0.8886\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2600 - accuracy: 0.9060 - val_loss: 0.3109 - val_accuracy: 0.8896\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2550 - accuracy: 0.9078 - val_loss: 0.3003 - val_accuracy: 0.8928\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2502 - accuracy: 0.9100 - val_loss: 0.3008 - val_accuracy: 0.8944\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2456 - accuracy: 0.9123 - val_loss: 0.3071 - val_accuracy: 0.8896\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2415 - accuracy: 0.9132 - val_loss: 0.3058 - val_accuracy: 0.8898\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2365 - accuracy: 0.9155 - val_loss: 0.2966 - val_accuracy: 0.8938\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2336 - accuracy: 0.9159 - val_loss: 0.2958 - val_accuracy: 0.8940\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2295 - accuracy: 0.9180 - val_loss: 0.3052 - val_accuracy: 0.8876\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2254 - accuracy: 0.9189 - val_loss: 0.3158 - val_accuracy: 0.8864\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=30, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7191544771194458,\n",
       "  0.4864506721496582,\n",
       "  0.4419199526309967,\n",
       "  0.41412392258644104,\n",
       "  0.3949027359485626,\n",
       "  0.37881579995155334,\n",
       "  0.36587169766426086,\n",
       "  0.3530019521713257,\n",
       "  0.34285035729408264,\n",
       "  0.33369511365890503,\n",
       "  0.3250378966331482,\n",
       "  0.31790533661842346,\n",
       "  0.30913156270980835,\n",
       "  0.3030637800693512,\n",
       "  0.2962428033351898,\n",
       "  0.29138171672821045,\n",
       "  0.28431135416030884,\n",
       "  0.2782234847545624,\n",
       "  0.27356860041618347,\n",
       "  0.267943799495697,\n",
       "  0.2636605501174927,\n",
       "  0.26004594564437866,\n",
       "  0.25498202443122864,\n",
       "  0.25023889541625977,\n",
       "  0.24561168253421783,\n",
       "  0.24148671329021454,\n",
       "  0.2365272045135498,\n",
       "  0.23364636301994324,\n",
       "  0.22947964072227478,\n",
       "  0.22539584338665009],\n",
       " 'accuracy': [0.7664545178413391,\n",
       "  0.831818163394928,\n",
       "  0.845127284526825,\n",
       "  0.8552727103233337,\n",
       "  0.8609636425971985,\n",
       "  0.866563618183136,\n",
       "  0.8703272938728333,\n",
       "  0.875,\n",
       "  0.8773272633552551,\n",
       "  0.8802727460861206,\n",
       "  0.8836727142333984,\n",
       "  0.8862181901931763,\n",
       "  0.8888909220695496,\n",
       "  0.8917090892791748,\n",
       "  0.8925091028213501,\n",
       "  0.8951272964477539,\n",
       "  0.8977454304695129,\n",
       "  0.8987636566162109,\n",
       "  0.9017636179924011,\n",
       "  0.9043454527854919,\n",
       "  0.9044181704521179,\n",
       "  0.906036376953125,\n",
       "  0.9077818393707275,\n",
       "  0.9099636077880859,\n",
       "  0.9123272895812988,\n",
       "  0.9132363796234131,\n",
       "  0.9154909253120422,\n",
       "  0.9159454703330994,\n",
       "  0.9179999828338623,\n",
       "  0.9189090728759766],\n",
       " 'val_loss': [0.5005245804786682,\n",
       "  0.44751280546188354,\n",
       "  0.41368427872657776,\n",
       "  0.4144171476364136,\n",
       "  0.45258286595344543,\n",
       "  0.37342649698257446,\n",
       "  0.3632795810699463,\n",
       "  0.37204983830451965,\n",
       "  0.36334407329559326,\n",
       "  0.33880800008773804,\n",
       "  0.34793275594711304,\n",
       "  0.34254902601242065,\n",
       "  0.3262068033218384,\n",
       "  0.3279508054256439,\n",
       "  0.3147432208061218,\n",
       "  0.3279794752597809,\n",
       "  0.3138428330421448,\n",
       "  0.31574615836143494,\n",
       "  0.3240225315093994,\n",
       "  0.3143009841442108,\n",
       "  0.3116896450519562,\n",
       "  0.3108958601951599,\n",
       "  0.3002697825431824,\n",
       "  0.300801157951355,\n",
       "  0.30710703134536743,\n",
       "  0.30579495429992676,\n",
       "  0.29658085107803345,\n",
       "  0.29581740498542786,\n",
       "  0.30516305565834045,\n",
       "  0.3158388137817383],\n",
       " 'val_accuracy': [0.8324000239372253,\n",
       "  0.8539999723434448,\n",
       "  0.8622000217437744,\n",
       "  0.8596000075340271,\n",
       "  0.8306000232696533,\n",
       "  0.8722000122070312,\n",
       "  0.8754000067710876,\n",
       "  0.8686000108718872,\n",
       "  0.8708000183105469,\n",
       "  0.8773999810218811,\n",
       "  0.878000020980835,\n",
       "  0.8781999945640564,\n",
       "  0.8844000101089478,\n",
       "  0.8812000155448914,\n",
       "  0.8858000040054321,\n",
       "  0.8823999762535095,\n",
       "  0.8870000243186951,\n",
       "  0.8884000182151794,\n",
       "  0.8848000168800354,\n",
       "  0.8881999850273132,\n",
       "  0.8885999917984009,\n",
       "  0.8895999789237976,\n",
       "  0.892799973487854,\n",
       "  0.8944000005722046,\n",
       "  0.8895999789237976,\n",
       "  0.8898000121116638,\n",
       "  0.8938000202178955,\n",
       "  0.8939999938011169,\n",
       "  0.8876000046730042,\n",
       "  0.8863999843597412]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 883us/step - loss: 0.3466 - accuracy: 0.8735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.346558153629303, 0.8734999895095825]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 28, 28), (5160,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 200)               1800      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 82,401\n",
      "Trainable params: 82,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(200, activation='relu', input_shape=(8,)))\n",
    "model.add(keras.layers.Dense(200, activation='relu'))\n",
    "model.add(keras.layers.Dense(200, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6645 - val_loss: 1.0767\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.8758\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 1.1325\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 2.5315\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3604 - val_loss: 0.5100\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3307\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.3290\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.4210\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3204\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3366\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 0.3457\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3097 - val_loss: 0.3703\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.4132\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.4503\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.2920\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.3051\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.2820\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.3144\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2911 - val_loss: 0.4334\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.2849\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2855 - val_loss: 0.2733\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 0.2914\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 0.2788\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 0.3610\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 0.3593\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2766 - val_loss: 0.4012\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2749 - val_loss: 0.2950\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2726 - val_loss: 0.4919\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2727 - val_loss: 0.3205\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2705 - val_loss: 0.5971\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.3339\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2679 - val_loss: 0.6037\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2703 - val_loss: 0.5062\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2665 - val_loss: 0.6182\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2694 - val_loss: 0.2948\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2641 - val_loss: 0.2840\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2622 - val_loss: 0.2664\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2598 - val_loss: 0.3376\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2608 - val_loss: 0.2905\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2597 - val_loss: 0.4293\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2607 - val_loss: 0.3250\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2609 - val_loss: 0.3198\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2582 - val_loss: 0.3279\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2565 - val_loss: 0.3667\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2536 - val_loss: 0.2792\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2531 - val_loss: 0.3103\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2521 - val_loss: 0.2759\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2513 - val_loss: 0.2562\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2505 - val_loss: 0.3012\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2500 - val_loss: 0.2671\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2481 - val_loss: 0.2960\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2499 - val_loss: 0.3691\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2479 - val_loss: 0.2742\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2497 - val_loss: 0.3731\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2471 - val_loss: 0.2577\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2447 - val_loss: 0.4249\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2468 - val_loss: 0.3039\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2450 - val_loss: 0.2760\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2409 - val_loss: 0.5450\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2452 - val_loss: 0.3281\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2431 - val_loss: 0.2551\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2420 - val_loss: 0.2885\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2421 - val_loss: 0.2563\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2383 - val_loss: 0.2632\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2389 - val_loss: 0.3094\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2395 - val_loss: 0.3001\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2370 - val_loss: 0.3426\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2374 - val_loss: 0.2758\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.240 - 0s 1ms/step - loss: 0.2366 - val_loss: 0.4088\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2362 - val_loss: 0.3305\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2358 - val_loss: 0.3463\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2375 - val_loss: 0.2963\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2362 - val_loss: 0.2916\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2367 - val_loss: 0.3024\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2323 - val_loss: 0.2481\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2309 - val_loss: 0.2805\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2331 - val_loss: 0.2615\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2341 - val_loss: 0.2823\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2301 - val_loss: 0.2666\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2301 - val_loss: 0.2817\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2289 - val_loss: 0.2759\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2292 - val_loss: 0.3608\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2267 - val_loss: 0.2752\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2269 - val_loss: 0.3205\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2250 - val_loss: 0.2688\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2261 - val_loss: 0.3556\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2254 - val_loss: 0.2692\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2249 - val_loss: 0.3538\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2269 - val_loss: 0.3035\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2252 - val_loss: 0.3299\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2256 - val_loss: 0.2661\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2238 - val_loss: 0.3312\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2213 - val_loss: 0.2726\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2200 - val_loss: 0.3294\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2216 - val_loss: 0.2665\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2196 - val_loss: 0.3292\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2194 - val_loss: 0.2835\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2197 - val_loss: 0.5600\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2206 - val_loss: 0.3320\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2170 - val_loss: 0.3653\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 30)           930         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = keras.layers.Input(shape=(8, ))\n",
    "x = keras.layers.Dense(30, activation='relu')(input_)\n",
    "x = keras.layers.Dense(30, activation='relu')(x)\n",
    "y = keras.layers.Concatenate()([input_, x])\n",
    "output_ = keras.layers.Dense(1)(y)\n",
    "model = keras.models.Model(inputs=input_, outputs=output_)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model,'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()\n",
    "# model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 931us/step - loss: 2.5491 - output_1_loss: 2.4316 - output_2_loss: 3.6071 - val_loss: 2.2609 - val_output_1_loss: 2.1855 - val_output_2_loss: 2.9389\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 681us/step - loss: 0.9824 - output_1_loss: 0.8333 - output_2_loss: 2.3242 - val_loss: 0.8716 - val_output_1_loss: 0.7170 - val_output_2_loss: 2.2626\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.8091 - output_1_loss: 0.6924 - output_2_loss: 1.8598 - val_loss: 0.7873 - val_output_1_loss: 0.6431 - val_output_2_loss: 2.0846\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 701us/step - loss: 0.7433 - output_1_loss: 0.6424 - output_2_loss: 1.6517 - val_loss: 0.7370 - val_output_1_loss: 0.6032 - val_output_2_loss: 1.9415\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.7005 - output_1_loss: 0.6078 - output_2_loss: 1.5349 - val_loss: 0.6943 - val_output_1_loss: 0.5764 - val_output_2_loss: 1.7553\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.6679 - output_1_loss: 0.5800 - output_2_loss: 1.4586 - val_loss: 0.6490 - val_output_1_loss: 0.5465 - val_output_2_loss: 1.5709\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.6405 - output_1_loss: 0.5562 - output_2_loss: 1.3992 - val_loss: 0.6151 - val_output_1_loss: 0.5233 - val_output_2_loss: 1.4414\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.6175 - output_1_loss: 0.5361 - output_2_loss: 1.3499 - val_loss: 0.5828 - val_output_1_loss: 0.4970 - val_output_2_loss: 1.3548\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.5973 - output_1_loss: 0.5183 - output_2_loss: 1.3077 - val_loss: 0.5613 - val_output_1_loss: 0.4791 - val_output_2_loss: 1.3013\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 769us/step - loss: 0.5800 - output_1_loss: 0.5034 - output_2_loss: 1.2687 - val_loss: 0.5514 - val_output_1_loss: 0.4716 - val_output_2_loss: 1.2691\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wide_and_deep_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             multiple                  210       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             multiple                  930       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             multiple                  36        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             multiple                  31        \n",
      "=================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "mnist = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train /255.\n",
    "x_test = x_test / 255.\n",
    "x_train, y_train, x_val, y_val = x_train[:50000], y_train[:50000], \\\n",
    "x_train[50000:], y_train[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 28, 28), (50000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 328,810\n",
      "Trainable params: 328,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.layers.Input(shape=(28, 28))\n",
    "x = keras.layers.Flatten()(input_layer)\n",
    "x = keras.layers.Dense(300, activation='relu')(x)\n",
    "x = keras.layers.Dense(300, activation='relu')(x)\n",
    "output_layer = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01), \n",
    "             loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_03_24-19_35_41'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1563 [..............................] - ETA: 0s - loss: 2.3316 - accuracy: 0.0938WARNING:tensorflow:From C:\\Users\\sinjy\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1563 [..............................] - ETA: 11:42 - loss: 2.3063 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_begin` time: 0.0060s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.8887s). Check your callbacks.\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.6483 - accuracy: 0.8373 - val_loss: 0.3110 - val_accuracy: 0.9135\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3022 - accuracy: 0.9131 - val_loss: 0.2458 - val_accuracy: 0.9303\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2496 - accuracy: 0.9283 - val_loss: 0.2150 - val_accuracy: 0.9384\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2151 - accuracy: 0.9385 - val_loss: 0.1882 - val_accuracy: 0.9486\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1893 - accuracy: 0.9460 - val_loss: 0.1712 - val_accuracy: 0.9523\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1687 - accuracy: 0.9517 - val_loss: 0.1573 - val_accuracy: 0.9556\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1522 - accuracy: 0.9565 - val_loss: 0.1444 - val_accuracy: 0.9604\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1380 - accuracy: 0.9609 - val_loss: 0.1369 - val_accuracy: 0.9642\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1259 - accuracy: 0.9640 - val_loss: 0.1320 - val_accuracy: 0.9651\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1160 - accuracy: 0.9670 - val_loss: 0.1215 - val_accuracy: 0.9675\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1064 - accuracy: 0.9697 - val_loss: 0.1170 - val_accuracy: 0.9700\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0986 - accuracy: 0.9726 - val_loss: 0.1118 - val_accuracy: 0.9692\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0912 - accuracy: 0.9744 - val_loss: 0.1068 - val_accuracy: 0.9703\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0850 - accuracy: 0.9764 - val_loss: 0.1043 - val_accuracy: 0.9709\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0796 - accuracy: 0.9778 - val_loss: 0.1027 - val_accuracy: 0.9728\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0740 - accuracy: 0.9801 - val_loss: 0.0980 - val_accuracy: 0.9730\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0694 - accuracy: 0.9816 - val_loss: 0.0995 - val_accuracy: 0.9728\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0649 - accuracy: 0.9826 - val_loss: 0.0924 - val_accuracy: 0.9743\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0609 - accuracy: 0.9840 - val_loss: 0.0895 - val_accuracy: 0.9752\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0573 - accuracy: 0.9847 - val_loss: 0.0878 - val_accuracy: 0.9758\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0535 - accuracy: 0.9860 - val_loss: 0.0884 - val_accuracy: 0.9758\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0506 - accuracy: 0.9870 - val_loss: 0.0900 - val_accuracy: 0.9748\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0476 - accuracy: 0.9880 - val_loss: 0.0850 - val_accuracy: 0.9754\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0450 - accuracy: 0.9884 - val_loss: 0.0852 - val_accuracy: 0.9761\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0423 - accuracy: 0.9896 - val_loss: 0.0846 - val_accuracy: 0.9761\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0398 - accuracy: 0.9904 - val_loss: 0.0838 - val_accuracy: 0.9767\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0378 - accuracy: 0.9905 - val_loss: 0.0823 - val_accuracy: 0.9775\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0355 - accuracy: 0.9916 - val_loss: 0.0818 - val_accuracy: 0.9768\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0335 - accuracy: 0.9920 - val_loss: 0.0804 - val_accuracy: 0.9771\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0317 - accuracy: 0.9928 - val_loss: 0.0803 - val_accuracy: 0.9775\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0300 - accuracy: 0.9933 - val_loss: 0.0799 - val_accuracy: 0.9780\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0285 - accuracy: 0.9940 - val_loss: 0.0786 - val_accuracy: 0.9785\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0268 - accuracy: 0.9940 - val_loss: 0.0769 - val_accuracy: 0.9787\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0254 - accuracy: 0.9949 - val_loss: 0.0807 - val_accuracy: 0.9771\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0240 - accuracy: 0.9953 - val_loss: 0.0786 - val_accuracy: 0.9785\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0229 - accuracy: 0.9956 - val_loss: 0.0783 - val_accuracy: 0.9778\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0217 - accuracy: 0.9960 - val_loss: 0.0776 - val_accuracy: 0.9788\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0207 - accuracy: 0.9963 - val_loss: 0.0786 - val_accuracy: 0.9783\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0196 - accuracy: 0.9968 - val_loss: 0.0771 - val_accuracy: 0.9791\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0185 - accuracy: 0.9972 - val_loss: 0.0759 - val_accuracy: 0.9794\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0177 - accuracy: 0.9973 - val_loss: 0.0809 - val_accuracy: 0.9779\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0168 - accuracy: 0.9974 - val_loss: 0.0777 - val_accuracy: 0.9791\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0160 - accuracy: 0.9979 - val_loss: 0.0766 - val_accuracy: 0.9789\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0152 - accuracy: 0.9978 - val_loss: 0.0788 - val_accuracy: 0.9793\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0145 - accuracy: 0.9982 - val_loss: 0.0790 - val_accuracy: 0.9790\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0138 - accuracy: 0.9985 - val_loss: 0.0802 - val_accuracy: 0.9783\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0131 - accuracy: 0.9984 - val_loss: 0.0787 - val_accuracy: 0.9796\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0125 - accuracy: 0.9986 - val_loss: 0.0791 - val_accuracy: 0.9788\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0120 - accuracy: 0.9987 - val_loss: 0.0780 - val_accuracy: 0.9795\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0115 - accuracy: 0.9988 - val_loss: 0.0788 - val_accuracy: 0.9799\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0109 - accuracy: 0.9989 - val_loss: 0.0795 - val_accuracy: 0.9784\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0104 - accuracy: 0.9992 - val_loss: 0.0780 - val_accuracy: 0.9802\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.0797 - val_accuracy: 0.9788\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0096 - accuracy: 0.9993 - val_loss: 0.0781 - val_accuracy: 0.9796\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0092 - accuracy: 0.9993 - val_loss: 0.0799 - val_accuracy: 0.9796\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 0.0793 - val_accuracy: 0.9793\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 0.0794 - val_accuracy: 0.9797\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.0804 - val_accuracy: 0.9795\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.0799 - val_accuracy: 0.9788\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 0.0075 - accuracy: 0.9995 - val_loss: 0.0804 - val_accuracy: 0.9793\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.0824 - val_accuracy: 0.9790\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.0800 - val_accuracy: 0.9798\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.0809 - val_accuracy: 0.9795\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.0810 - val_accuracy: 0.9794\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0810 - val_accuracy: 0.9802\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0059 - accuracy: 0.9997 - val_loss: 0.0812 - val_accuracy: 0.9800\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0058 - accuracy: 0.9997 - val_loss: 0.0817 - val_accuracy: 0.9801\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0055 - accuracy: 0.9999 - val_loss: 0.0831 - val_accuracy: 0.9790\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0814 - val_accuracy: 0.9804\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.0832 - val_accuracy: 0.9792\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.0820 - val_accuracy: 0.9800\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0830 - val_accuracy: 0.9795\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.0831 - val_accuracy: 0.9792\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0831 - val_accuracy: 0.9796\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0842 - val_accuracy: 0.9794\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0839 - val_accuracy: 0.9797\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0832 - val_accuracy: 0.9799\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.0845 - val_accuracy: 0.9797\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0837 - val_accuracy: 0.9800\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9797\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0848 - val_accuracy: 0.9799\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0849 - val_accuracy: 0.9793\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0848 - val_accuracy: 0.9800\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0844 - val_accuracy: 0.9796\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0860 - val_accuracy: 0.9801\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9795\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9796\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9798\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0864 - val_accuracy: 0.9794\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0860 - val_accuracy: 0.9798\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9799\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9802\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9800\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9800\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9801\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9802\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9796\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9800\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9802\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(x_train, y_train, epochs=100, \n",
    "                   validation_data=(x_val, y_val), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "a[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 8번.\n",
    "# cifar10 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "cifar10 = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_val = x_train_full[:40000] / 255, x_train_full[40000:] / 255\n",
    "# y_train, y_val = y_train_full[:40000], y_train_full[40000:]\n",
    "# x_test = x_test / 255.\n",
    "x_train, x_val = x_train_full[:40000], x_train_full[40000:]\n",
    "y_train, y_val = y_train_full[:40000], y_train_full[40000:]\n",
    "\n",
    "x_mean = x_train.mean(axis=0)\n",
    "x_std = x_train.std(axis=0)\n",
    "\n",
    "x_train = (x_train - x_mean) / x_std\n",
    "x_val = (x_val - x_mean) / x_std\n",
    "x_test = (x_test - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. 100개의 뉴런을 가진 은닉층 20개로 신경망 만들기( he초기화, elu활성화함수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "NEURONS = 100\n",
    "HIDDEN = 20\n",
    "ACTIVATION = 'elu'\n",
    "INITIALIZER = 'he_normal'\n",
    "\n",
    "Dense = partial(keras.layers.Dense, units=NEURONS, activation=ACTIVATION,\n",
    "                                  kernel_initializer=INITIALIZER)\n",
    "\n",
    "layers_lst = []\n",
    "\n",
    "layers_lst += [keras.layers.Flatten(input_shape=(32, 32, 3))]\n",
    "for i in range(HIDDEN):\n",
    "    layers_lst += [Dense()]\n",
    "layers_lst += [keras.layers.Dense(10, activation='softmax', \n",
    "                                  kernel_initializer=INITIALIZER)]\n",
    "\n",
    "model = keras.models.Sequential(layers_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1250 [..............................] - ETA: 0s - loss: 1.8298 - accuracy: 0.2812WARNING:tensorflow:From C:\\Users\\sinjy\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1250 [..............................] - ETA: 9:28 - loss: 4.8505 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_begin` time: 0.0100s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.8946s). Check your callbacks.\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0692 - accuracy: 0.2633 - val_loss: 1.8341 - val_accuracy: 0.3249\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8109 - accuracy: 0.3453 - val_loss: 1.8010 - val_accuracy: 0.3426\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7323 - accuracy: 0.3749 - val_loss: 1.7771 - val_accuracy: 0.3601\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6799 - accuracy: 0.3950 - val_loss: 1.6974 - val_accuracy: 0.3938\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6364 - accuracy: 0.4120 - val_loss: 1.6807 - val_accuracy: 0.4018\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5943 - accuracy: 0.4314 - val_loss: 1.6619 - val_accuracy: 0.4059\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5610 - accuracy: 0.4406 - val_loss: 1.7246 - val_accuracy: 0.3995\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5262 - accuracy: 0.4531 - val_loss: 1.5800 - val_accuracy: 0.4394\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5018 - accuracy: 0.4636 - val_loss: 1.6525 - val_accuracy: 0.4199\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4760 - accuracy: 0.4712 - val_loss: 1.6411 - val_accuracy: 0.4289\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4515 - accuracy: 0.4798 - val_loss: 1.5558 - val_accuracy: 0.4501\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4279 - accuracy: 0.4882 - val_loss: 1.5482 - val_accuracy: 0.4522\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4075 - accuracy: 0.4971 - val_loss: 1.5521 - val_accuracy: 0.4507\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3875 - accuracy: 0.5020 - val_loss: 1.5121 - val_accuracy: 0.4618\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3716 - accuracy: 0.5107 - val_loss: 1.5184 - val_accuracy: 0.4594\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3468 - accuracy: 0.5195 - val_loss: 1.4861 - val_accuracy: 0.4764\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3325 - accuracy: 0.5245 - val_loss: 1.5213 - val_accuracy: 0.4745\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3154 - accuracy: 0.5301 - val_loss: 1.4998 - val_accuracy: 0.4667\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2959 - accuracy: 0.5373 - val_loss: 1.5381 - val_accuracy: 0.4715\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2775 - accuracy: 0.5440 - val_loss: 1.5134 - val_accuracy: 0.4722\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2656 - accuracy: 0.5450 - val_loss: 1.5503 - val_accuracy: 0.4701\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2470 - accuracy: 0.5536 - val_loss: 1.5327 - val_accuracy: 0.4704\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2286 - accuracy: 0.5604 - val_loss: 1.5205 - val_accuracy: 0.4751\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2164 - accuracy: 0.5645 - val_loss: 1.4898 - val_accuracy: 0.4796\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.1999 - accuracy: 0.5695 - val_loss: 1.5221 - val_accuracy: 0.4797\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.1885 - accuracy: 0.5753 - val_loss: 1.5422 - val_accuracy: 0.4788\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.1695 - accuracy: 0.5802 - val_loss: 1.5506 - val_accuracy: 0.4832\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.1546 - accuracy: 0.5870 - val_loss: 1.5057 - val_accuracy: 0.4927\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.1405 - accuracy: 0.5921 - val_loss: 1.5283 - val_accuracy: 0.4862\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.1293 - accuracy: 0.5934 - val_loss: 1.5955 - val_accuracy: 0.4831\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.1149 - accuracy: 0.6006 - val_loss: 1.5382 - val_accuracy: 0.4795\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.1057 - accuracy: 0.6031 - val_loss: 1.5343 - val_accuracy: 0.4897\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0853 - accuracy: 0.6146 - val_loss: 1.5631 - val_accuracy: 0.4776\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0713 - accuracy: 0.6122 - val_loss: 1.5841 - val_accuracy: 0.4837\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0643 - accuracy: 0.6181 - val_loss: 1.5613 - val_accuracy: 0.4939\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0488 - accuracy: 0.6253 - val_loss: 1.7064 - val_accuracy: 0.4649\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0331 - accuracy: 0.6283 - val_loss: 1.6247 - val_accuracy: 0.4721\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0227 - accuracy: 0.6324 - val_loss: 1.6399 - val_accuracy: 0.4818\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0202 - accuracy: 0.6331 - val_loss: 1.5714 - val_accuracy: 0.4862\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0035 - accuracy: 0.6408 - val_loss: 1.6016 - val_accuracy: 0.4829\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9911 - accuracy: 0.6444 - val_loss: 1.6157 - val_accuracy: 0.4875\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9820 - accuracy: 0.6478 - val_loss: 1.5978 - val_accuracy: 0.4901\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9698 - accuracy: 0.6520 - val_loss: 1.6200 - val_accuracy: 0.4960\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9588 - accuracy: 0.6539 - val_loss: 1.6963 - val_accuracy: 0.4737\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9472 - accuracy: 0.6603 - val_loss: 1.7562 - val_accuracy: 0.4633\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9414 - accuracy: 0.6633 - val_loss: 1.6850 - val_accuracy: 0.4916\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9282 - accuracy: 0.6654 - val_loss: 1.7126 - val_accuracy: 0.4800\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9210 - accuracy: 0.6698 - val_loss: 1.7109 - val_accuracy: 0.4811\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9066 - accuracy: 0.6756 - val_loss: 1.7497 - val_accuracy: 0.4824\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8992 - accuracy: 0.6778 - val_loss: 1.7771 - val_accuracy: 0.4703\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8896 - accuracy: 0.6822 - val_loss: 1.7125 - val_accuracy: 0.4835\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8807 - accuracy: 0.6854 - val_loss: 1.6687 - val_accuracy: 0.4824\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8751 - accuracy: 0.6854 - val_loss: 1.7544 - val_accuracy: 0.4874\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8592 - accuracy: 0.6928 - val_loss: 1.7087 - val_accuracy: 0.4834\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8590 - accuracy: 0.6937 - val_loss: 1.7481 - val_accuracy: 0.4910\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8510 - accuracy: 0.6963 - val_loss: 1.7107 - val_accuracy: 0.4839\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8340 - accuracy: 0.7032 - val_loss: 1.7151 - val_accuracy: 0.4907\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8312 - accuracy: 0.7018 - val_loss: 1.7418 - val_accuracy: 0.4947\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8197 - accuracy: 0.7062 - val_loss: 1.8431 - val_accuracy: 0.4674\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8208 - accuracy: 0.7040 - val_loss: 1.8558 - val_accuracy: 0.4665\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8156 - accuracy: 0.7114 - val_loss: 1.7976 - val_accuracy: 0.4912\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7956 - accuracy: 0.7141 - val_loss: 1.8392 - val_accuracy: 0.4910\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7892 - accuracy: 0.7212 - val_loss: 1.8511 - val_accuracy: 0.4819\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7814 - accuracy: 0.7209 - val_loss: 1.8234 - val_accuracy: 0.4840\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7823 - accuracy: 0.7204 - val_loss: 1.8337 - val_accuracy: 0.4694\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7754 - accuracy: 0.7222 - val_loss: 1.8381 - val_accuracy: 0.4725\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7622 - accuracy: 0.7271 - val_loss: 1.8030 - val_accuracy: 0.4833\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7587 - accuracy: 0.7297 - val_loss: 1.8157 - val_accuracy: 0.4807\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7530 - accuracy: 0.7305 - val_loss: 1.8320 - val_accuracy: 0.4836\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7419 - accuracy: 0.7337 - val_loss: 1.8487 - val_accuracy: 0.4890\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7412 - accuracy: 0.7380 - val_loss: 1.8970 - val_accuracy: 0.4762\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7246 - accuracy: 0.7416 - val_loss: 1.9093 - val_accuracy: 0.4777\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7208 - accuracy: 0.7420 - val_loss: 1.8944 - val_accuracy: 0.4789\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7219 - accuracy: 0.7425 - val_loss: 1.9083 - val_accuracy: 0.4851\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7109 - accuracy: 0.7447 - val_loss: 1.9292 - val_accuracy: 0.4866\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6980 - accuracy: 0.7503 - val_loss: 1.9574 - val_accuracy: 0.4760\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6999 - accuracy: 0.7517 - val_loss: 1.9146 - val_accuracy: 0.4752\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7000 - accuracy: 0.7511 - val_loss: 1.9152 - val_accuracy: 0.4786\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6888 - accuracy: 0.7557 - val_loss: 2.0638 - val_accuracy: 0.4800\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6886 - accuracy: 0.7525 - val_loss: 1.9819 - val_accuracy: 0.4771\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6738 - accuracy: 0.7612 - val_loss: 1.9706 - val_accuracy: 0.4754\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6746 - accuracy: 0.7592 - val_loss: 1.9749 - val_accuracy: 0.4823\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6638 - accuracy: 0.7638 - val_loss: 1.9942 - val_accuracy: 0.4687\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6541 - accuracy: 0.7671 - val_loss: 1.9686 - val_accuracy: 0.4824\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6520 - accuracy: 0.7693 - val_loss: 1.9497 - val_accuracy: 0.4760\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6450 - accuracy: 0.7705 - val_loss: 2.0240 - val_accuracy: 0.4791\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6376 - accuracy: 0.7716 - val_loss: 2.0338 - val_accuracy: 0.4814\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6413 - accuracy: 0.7731 - val_loss: 2.0481 - val_accuracy: 0.4835\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6396 - accuracy: 0.7724 - val_loss: 2.1947 - val_accuracy: 0.4498\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6329 - accuracy: 0.7748 - val_loss: 1.9889 - val_accuracy: 0.4764\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6065 - accuracy: 0.7817 - val_loss: 2.0871 - val_accuracy: 0.4720\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6105 - accuracy: 0.7836 - val_loss: 2.0823 - val_accuracy: 0.4738\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6217 - accuracy: 0.7773 - val_loss: 2.0684 - val_accuracy: 0.4768\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6050 - accuracy: 0.7865 - val_loss: 2.1004 - val_accuracy: 0.4768\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6044 - accuracy: 0.7846 - val_loss: 2.1169 - val_accuracy: 0.4709\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6034 - accuracy: 0.7864 - val_loss: 2.2277 - val_accuracy: 0.4569\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6007 - accuracy: 0.7883 - val_loss: 2.0945 - val_accuracy: 0.4836\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5854 - accuracy: 0.7942 - val_loss: 2.1047 - val_accuracy: 0.4761\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5955 - accuracy: 0.7893 - val_loss: 2.1516 - val_accuracy: 0.4736\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5856 - accuracy: 0.7916 - val_loss: 2.1650 - val_accuracy: 0.4724\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = \"./model\"\n",
    "log_dir = './my_logs'\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01), \n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=32, epochs=100, \n",
    "          validation_data=(x_val, y_val), callbacks=[tensorboard_cb])\n",
    "model.save(os.path.join(model_path, \"Deep_model_3_25.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(model_path, 'Deep_model_3_25.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 70.8810 - accuracy: 0.4017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[70.88101959228516, 0.4016999900341034]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Nadam optimizer, early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './my_logs/simple_2'\n",
    "model_path = './model/model_3_25.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1250 [..............................] - ETA: 0s - loss: 1.7801 - accuracy: 0.3438WARNING:tensorflow:From C:\\Users\\sinjy\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1250 [..............................] - ETA: 9:50 - loss: 1.7538 - accuracy: 0.3281WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0100s vs `on_train_batch_end` time: 0.9301s). Check your callbacks.\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 1.2423 - accuracy: 0.5652 - val_loss: 1.4738 - val_accuracy: 0.5034\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.1910 - accuracy: 0.5789 - val_loss: 1.4717 - val_accuracy: 0.5003\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.1650 - accuracy: 0.5918 - val_loss: 1.4396 - val_accuracy: 0.5116\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1373 - accuracy: 0.6034 - val_loss: 1.4591 - val_accuracy: 0.5076\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1132 - accuracy: 0.6107 - val_loss: 1.4949 - val_accuracy: 0.5037\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0942 - accuracy: 0.6154 - val_loss: 1.5302 - val_accuracy: 0.4943\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0796 - accuracy: 0.6222 - val_loss: 1.4839 - val_accuracy: 0.5031\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0574 - accuracy: 0.6298 - val_loss: 1.4935 - val_accuracy: 0.5065\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0391 - accuracy: 0.6353 - val_loss: 1.4931 - val_accuracy: 0.5110\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0249 - accuracy: 0.6412 - val_loss: 1.5692 - val_accuracy: 0.4853\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.0108 - accuracy: 0.6493 - val_loss: 1.5407 - val_accuracy: 0.5052\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.9925 - accuracy: 0.6517 - val_loss: 1.5075 - val_accuracy: 0.5111\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 0.9881 - accuracy: 0.6517 - val_loss: 1.5367 - val_accuracy: 0.5046\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0005), \n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=32, epochs=100,\n",
    "         validation_data=(x_val, y_val), \n",
    "          callbacks=[tensorboard_cb, early_stopping_cb])\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 178.0827 - accuracy: 0.3344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[178.08274841308594, 0.3343999981880188]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './my_logs/batchnorm_2'\n",
    "model_path = './model/model_3_26.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "NEURONS = 100\n",
    "HIDDEN = 20\n",
    "ACTIVATION = 'elu'\n",
    "INITIALIZER = 'he_normal'\n",
    "\n",
    "Dense = partial(keras.layers.Dense, units=NEURONS, kernel_initializer=INITIALIZER)\n",
    "\n",
    "layers_lst = []\n",
    "\n",
    "layers_lst += [keras.layers.Flatten(input_shape=(32, 32, 3))]\n",
    "for i in range(HIDDEN):\n",
    "    layers_lst += [Dense()]\n",
    "    layers_lst += [keras.layers.BatchNormalization()]\n",
    "    layers_lst += [keras.layers.Activation(ACTIVATION)]\n",
    "layers_lst += [keras.layers.Dense(10, activation='softmax', \n",
    "                                  kernel_initializer=INITIALIZER)]\n",
    "\n",
    "model = keras.models.Sequential(layers_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1250 [..............................] - ETA: 14:06 - loss: 1.3042 - accuracy: 0.4844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 1.3250s). Check your callbacks.\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.9603 - accuracy: 0.6639 - val_loss: 1.4364 - val_accuracy: 0.5237\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.9392 - accuracy: 0.6725 - val_loss: 1.5152 - val_accuracy: 0.5008\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.9303 - accuracy: 0.6733 - val_loss: 1.4970 - val_accuracy: 0.5198\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 0.9189 - accuracy: 0.6789 - val_loss: 1.4939 - val_accuracy: 0.5175\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 0.9004 - accuracy: 0.6855 - val_loss: 1.5163 - val_accuracy: 0.5168\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8926 - accuracy: 0.6851 - val_loss: 1.4231 - val_accuracy: 0.5337\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 0.8887 - accuracy: 0.6895 - val_loss: 1.4771 - val_accuracy: 0.5187\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 0.8783 - accuracy: 0.6939 - val_loss: 1.5330 - val_accuracy: 0.5055\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 0.8684 - accuracy: 0.6958 - val_loss: 1.5229 - val_accuracy: 0.5118\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 0.8568 - accuracy: 0.6991 - val_loss: 1.5645 - val_accuracy: 0.4951\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 0.8481 - accuracy: 0.7036 - val_loss: 1.5939 - val_accuracy: 0.4936\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 0.8394 - accuracy: 0.7068 - val_loss: 1.5083 - val_accuracy: 0.5169\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 0.8325 - accuracy: 0.7072 - val_loss: 1.6797 - val_accuracy: 0.4967\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.8319 - accuracy: 0.7106 - val_loss: 1.6760 - val_accuracy: 0.4825\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.8188 - accuracy: 0.7138 - val_loss: 1.5637 - val_accuracy: 0.5130\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.8168 - accuracy: 0.7113 - val_loss: 1.5545 - val_accuracy: 0.5153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c67e828508>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0005), \n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=32, epochs=100,\n",
    "         validation_data=(x_val, y_val), \n",
    "          callbacks=[tensorboard_cb, early_stopping_cb, checkpoint_cb])\n",
    "# model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5645 - accuracy: 0.5101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5645298957824707, 0.5101000070571899]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. selu, 자기정규화(입력 특성 표준화, 르쿤 초기화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './my_logs/selu_4'\n",
    "model_path = './model/model_3_26.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "keras.backend.clear_session()\n",
    "\n",
    "NEURONS = 100\n",
    "HIDDEN = 20\n",
    "ACTIVATION = 'selu'\n",
    "INITIALIZER = 'lecun_normal'\n",
    "\n",
    "Dense = partial(keras.layers.Dense, units=NEURONS, \n",
    "                activation=ACTIVATION, kernel_initializer=INITIALIZER)\n",
    "\n",
    "layers_lst = []\n",
    "\n",
    "layers_lst += [keras.layers.Flatten(input_shape=(32, 32, 3))]\n",
    "for i in range(HIDDEN):\n",
    "    layers_lst += [Dense()]\n",
    "layers_lst += [keras.layers.Dense(10, activation='softmax', \n",
    "                                  kernel_initializer=INITIALIZER)]\n",
    "\n",
    "model = keras.models.Sequential(layers_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1250 [..............................] - ETA: 11:01 - loss: 2.7338 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 1.0469s). Check your callbacks.\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.8933 - accuracy: 0.3111 - val_loss: 1.7792 - val_accuracy: 0.3498\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.7162 - accuracy: 0.3788 - val_loss: 1.6754 - val_accuracy: 0.3930\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.6403 - accuracy: 0.4124 - val_loss: 1.6801 - val_accuracy: 0.3950\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.5819 - accuracy: 0.4315 - val_loss: 1.6054 - val_accuracy: 0.4323\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.5402 - accuracy: 0.4459 - val_loss: 1.6114 - val_accuracy: 0.4247\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.5046 - accuracy: 0.4570 - val_loss: 1.5554 - val_accuracy: 0.4488\n",
      "Epoch 7/100\n",
      "1149/1250 [==========================>...] - ETA: 0s - loss: 1.4761 - accuracy: 0.4696"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c31f84620724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m model.fit(x=x_train, y=y_train, batch_size=32, epochs=100,\n\u001b[0;32m      8\u001b[0m          \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m           callbacks=[tensorboard_cb, early_stopping_cb, checkpoint_cb])\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# model.save(model_path)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.00005), \n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=32, epochs=100,\n",
    "         validation_data=(x_val, y_val), \n",
    "          callbacks=[tensorboard_cb, early_stopping_cb, checkpoint_cb])\n",
    "# model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4603 - accuracy: 0.4988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4603245258331299, 0.49880000948905945]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. alpha dropout, mcdropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './my_logs/alpha_dropout_3'\n",
    "model_path = './model/model_3_26.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "keras.backend.clear_session()\n",
    "\n",
    "NEURONS = 100\n",
    "HIDDEN = 20\n",
    "ACTIVATION = 'selu'\n",
    "INITIALIZER = 'lecun_normal'\n",
    "\n",
    "Dense = partial(keras.layers.Dense, units=NEURONS, \n",
    "                activation=ACTIVATION, kernel_initializer=INITIALIZER)\n",
    "\n",
    "layers_lst = []\n",
    "\n",
    "layers_lst += [keras.layers.Flatten(input_shape=(32, 32, 3))]\n",
    "for i in range(HIDDEN):\n",
    "    layers_lst += [keras.layers.AlphaDropout(.1)]\n",
    "    layers_lst += [Dense()]\n",
    "layers_lst += [keras.layers.AlphaDropout(.1)]\n",
    "layers_lst += [keras.layers.Dense(10, activation='softmax', \n",
    "                                  kernel_initializer=INITIALIZER)]\n",
    "\n",
    "model = keras.models.Sequential(layers_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1250 [..............................] - ETA: 11:18 - loss: 2.8122 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 1.0762s). Check your callbacks.\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 2.1810 - accuracy: 0.1908 - val_loss: 2.9838 - val_accuracy: 0.2300\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.9937 - accuracy: 0.2402 - val_loss: 6.2338 - val_accuracy: 0.2500\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.9254 - accuracy: 0.2663 - val_loss: 6.8157 - val_accuracy: 0.2859\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.8691 - accuracy: 0.2963 - val_loss: 6.5770 - val_accuracy: 0.2866\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.8297 - accuracy: 0.3125 - val_loss: 7.5576 - val_accuracy: 0.2969\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.7972 - accuracy: 0.3305 - val_loss: 7.3005 - val_accuracy: 0.3294\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.7640 - accuracy: 0.3477 - val_loss: 7.4837 - val_accuracy: 0.3596\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.7332 - accuracy: 0.3603 - val_loss: 7.5265 - val_accuracy: 0.3516\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.7127 - accuracy: 0.3745 - val_loss: 7.3212 - val_accuracy: 0.3637\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.6895 - accuracy: 0.3851 - val_loss: 7.1710 - val_accuracy: 0.3814\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.6681 - accuracy: 0.3904 - val_loss: 6.6660 - val_accuracy: 0.3931\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.6550 - accuracy: 0.3971 - val_loss: 8.1479 - val_accuracy: 0.3771\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.6484 - accuracy: 0.4036 - val_loss: 5.3602 - val_accuracy: 0.3910\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.6359 - accuracy: 0.4051 - val_loss: 6.1656 - val_accuracy: 0.3896\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.6216 - accuracy: 0.4094 - val_loss: 7.5994 - val_accuracy: 0.3730\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.6131 - accuracy: 0.4131 - val_loss: 6.4088 - val_accuracy: 0.3695\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.6102 - accuracy: 0.4151 - val_loss: 7.7133 - val_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.5991 - accuracy: 0.4234 - val_loss: 7.1049 - val_accuracy: 0.3952\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.5796 - accuracy: 0.4258 - val_loss: 7.0822 - val_accuracy: 0.3880\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.5788 - accuracy: 0.4267 - val_loss: 7.5704 - val_accuracy: 0.4052\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 1.5627 - accuracy: 0.4328 - val_loss: 6.6313 - val_accuracy: 0.4061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b3001c32c8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(model_path, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0005), \n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=32, epochs=100,\n",
    "         validation_data=(x_val, y_val), \n",
    "          callbacks=[tensorboard_cb, early_stopping_cb, checkpoint_cb])\n",
    "# model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 5.7211 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.721122741699219, 0.10000000149011612]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mcdropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout)\n",
    "    else layer for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout (MCAlphaDro (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_1 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_2 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_3 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_4 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_5 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_6 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_7 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_8 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_9 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_10 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_11 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_12 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_13 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_14 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_15 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_16 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_17 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_18 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_19 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_20 (MCAlpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mc_dropout_predict_probas(mc_model, x, n_samples=10):\n",
    "    y_probas = [mc_model.predict(x) for i in range(n_samples)]\n",
    "    return np.mean(y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, x, n_samples=10):\n",
    "    probas = mc_dropout_predict_probas(mc_model, x, n_samples=n_samples)\n",
    "    return np.argmax(probas, axis=1)\n",
    "\n",
    "pred = mc_dropout_predict_classes(mc_model, x_test)\n",
    "# accuracy = np.mean(y_test == pred[:, 0])\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0999"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.mean(y_test[:, 0] == pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. 1사이클스케줄링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2",
   "language": "python",
   "name": "tensorflow_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
