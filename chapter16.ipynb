{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "notebook_dir = Path.cwd().parent\n",
    "datasets_dir = notebook_dir / \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = keras.utils.get_file(datasets_dir / \"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"First\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_id = len(tokenizer.word_index)\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = tokenizer.document_count\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115394,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=1003854>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 5, 8, 7, 2, 0, 18, 5, 2, 5, 35, 1, 9, 23, 10, 21, 1, 19, 3, 8, 1, 0, 16, 1, 0, 22, 8, 3, 18, 1, 1, 12, 0, 4, 9, 15, 0, 19, 13, 8, 2, 6, 1, 8, 17, 0, 6, 1, 4, 8, 0, 14, 1, 0, 7, 22, 1, 4, 24, 26, 10, 10, 4, 11, 11, 23, 10, 7, 22, 1, 4, 24, 17, 0, 7, 22, 1, 4, 24, 26, 10, 10, 19, 5, 8, 7, 2, 0, 18, 5, 2, 5, 35, 1, 9, 23, 10, 15, 3, 13, 0]\n",
      "101\n",
      "[5, 8, 7, 2, 0, 18, 5, 2, 5, 35, 1, 9, 23, 10, 21, 1, 19, 3, 8, 1, 0, 16, 1, 0, 22, 8, 3, 18, 1, 1, 12, 0, 4, 9, 15, 0, 19, 13, 8, 2, 6, 1, 8, 17, 0, 6, 1, 4, 8, 0, 14, 1, 0, 7, 22, 1, 4, 24, 26, 10, 10, 4, 11, 11, 23, 10, 7, 22, 1, 4, 24, 17, 0, 7, 22, 1, 4, 24, 26, 10, 10, 19, 5, 8, 7, 2, 0, 18, 5, 2, 5, 35, 1, 9, 23, 10, 15, 3, 13, 0, 4]\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(2):\n",
    "    print(list(i.as_numpy_iterator()))\n",
    "    print(len(list(i.as_numpy_iterator())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x_batch, y_batch: (tf.one_hot(x_batch, depth=max_id), y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                    dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True, dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "history = model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(notebook_dir / \"model\" / \"char_rnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    x = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(x, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = preprocess([\"How are yo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinjy\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  8,  0, 12,  9,  1,  0, 15,  3, 13]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts(y_pred + 1)[0][-1:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    x_new = preprocess([text])\n",
    "    y_proba = model.predict(x_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t the maid of me as i see\n",
      "she is a scolding of a pi\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"t\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weat:\n",
      "percuady fithel than a puppet rook.\n",
      "all eld y\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"w\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w? kinesif! stran with; a puccess'\n",
      "fawry rusf; or y\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"w\", temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(lambda x_batch, y_batch: (tf.one_hot(x_batch, depth=max_id), y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(lambda x_batch, y_batch: (tf.one_hot(x_batch, depth=max_id),\n",
    "                                               y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True, dropout=0.2, \n",
    "                    batch_input_shape=[batch_size, None, max_id]),\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True, dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 26s 76ms/step - loss: 2.9056\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 25s 81ms/step - loss: 2.2891\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 2.1380\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 2.0546\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 1.9976\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 27s 88ms/step - loss: 1.9574\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 1.9249\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 1.9035\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 1.8853\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 1.8665\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 1.8539\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 27s 88ms/step - loss: 1.8437\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 1.8359\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 27s 88ms/step - loss: 1.8280\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 28s 88ms/step - loss: 1.8169\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 1.8089\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 1.8030\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 1.7987\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 1.7916\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 1.7856\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 27s 87ms/step - loss: 1.7813\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7790\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.7753\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7688\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7680\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.7627\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7594\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.7578\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.7533\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 28s 90ms/step - loss: 1.7534\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 1.7490\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 1.7476\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7468\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7437\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7391\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7416\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7392\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.7333\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.7323\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.7311\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7280\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7259\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7244\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7245\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 1.7229\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.7203\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7187\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 1.7197\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 1.7151\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 26s 84ms/step - loss: 1.7147\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "steps_per_epoch = train_size // batch_size // n_steps\n",
    "history = model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=50, \n",
    "                   callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\sinjy\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\sinjy\\anaconda3\\envs\\tensorflow_2\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fawn': 34701,\n",
       " 'tsukino': 52006,\n",
       " 'nunnery': 52007,\n",
       " 'sonja': 16816,\n",
       " 'vani': 63951,\n",
       " 'woods': 1408,\n",
       " 'spiders': 16115,\n",
       " 'hanging': 2345,\n",
       " 'woody': 2289,\n",
       " 'trawling': 52008,\n",
       " \"hold's\": 52009,\n",
       " 'comically': 11307,\n",
       " 'localized': 40830,\n",
       " 'disobeying': 30568,\n",
       " \"'royale\": 52010,\n",
       " \"harpo's\": 40831,\n",
       " 'canet': 52011,\n",
       " 'aileen': 19313,\n",
       " 'acurately': 52012,\n",
       " \"diplomat's\": 52013,\n",
       " 'rickman': 25242,\n",
       " 'arranged': 6746,\n",
       " 'rumbustious': 52014,\n",
       " 'familiarness': 52015,\n",
       " \"spider'\": 52016,\n",
       " 'hahahah': 68804,\n",
       " \"wood'\": 52017,\n",
       " 'transvestism': 40833,\n",
       " \"hangin'\": 34702,\n",
       " 'bringing': 2338,\n",
       " 'seamier': 40834,\n",
       " 'wooded': 34703,\n",
       " 'bravora': 52018,\n",
       " 'grueling': 16817,\n",
       " 'wooden': 1636,\n",
       " 'wednesday': 16818,\n",
       " \"'prix\": 52019,\n",
       " 'altagracia': 34704,\n",
       " 'circuitry': 52020,\n",
       " 'crotch': 11585,\n",
       " 'busybody': 57766,\n",
       " \"tart'n'tangy\": 52021,\n",
       " 'burgade': 14129,\n",
       " 'thrace': 52023,\n",
       " \"tom's\": 11038,\n",
       " 'snuggles': 52025,\n",
       " 'francesco': 29114,\n",
       " 'complainers': 52027,\n",
       " 'templarios': 52125,\n",
       " '272': 40835,\n",
       " '273': 52028,\n",
       " 'zaniacs': 52130,\n",
       " '275': 34706,\n",
       " 'consenting': 27631,\n",
       " 'snuggled': 40836,\n",
       " 'inanimate': 15492,\n",
       " 'uality': 52030,\n",
       " 'bronte': 11926,\n",
       " 'errors': 4010,\n",
       " 'dialogs': 3230,\n",
       " \"yomada's\": 52031,\n",
       " \"madman's\": 34707,\n",
       " 'dialoge': 30585,\n",
       " 'usenet': 52033,\n",
       " 'videodrome': 40837,\n",
       " \"kid'\": 26338,\n",
       " 'pawed': 52034,\n",
       " \"'girlfriend'\": 30569,\n",
       " \"'pleasure\": 52035,\n",
       " \"'reloaded'\": 52036,\n",
       " \"kazakos'\": 40839,\n",
       " 'rocque': 52037,\n",
       " 'mailings': 52038,\n",
       " 'brainwashed': 11927,\n",
       " 'mcanally': 16819,\n",
       " \"tom''\": 52039,\n",
       " 'kurupt': 25243,\n",
       " 'affiliated': 21905,\n",
       " 'babaganoosh': 52040,\n",
       " \"noe's\": 40840,\n",
       " 'quart': 40841,\n",
       " 'kids': 359,\n",
       " 'uplifting': 5034,\n",
       " 'controversy': 7093,\n",
       " 'kida': 21906,\n",
       " 'kidd': 23379,\n",
       " \"error'\": 52041,\n",
       " 'neurologist': 52042,\n",
       " 'spotty': 18510,\n",
       " 'cobblers': 30570,\n",
       " 'projection': 9878,\n",
       " 'fastforwarding': 40842,\n",
       " 'sters': 52043,\n",
       " \"eggar's\": 52044,\n",
       " 'etherything': 52045,\n",
       " 'gateshead': 40843,\n",
       " 'airball': 34708,\n",
       " 'unsinkable': 25244,\n",
       " 'stern': 7180,\n",
       " \"cervi's\": 52046,\n",
       " 'dnd': 40844,\n",
       " 'dna': 11586,\n",
       " 'insecurity': 20598,\n",
       " \"'reboot'\": 52047,\n",
       " 'trelkovsky': 11037,\n",
       " 'jaekel': 52048,\n",
       " 'sidebars': 52049,\n",
       " \"sforza's\": 52050,\n",
       " 'distortions': 17633,\n",
       " 'mutinies': 52051,\n",
       " 'sermons': 30602,\n",
       " '7ft': 40846,\n",
       " 'boobage': 52052,\n",
       " \"o'bannon's\": 52053,\n",
       " 'populations': 23380,\n",
       " 'chulak': 52054,\n",
       " 'mesmerize': 27633,\n",
       " 'quinnell': 52055,\n",
       " 'yahoo': 10307,\n",
       " 'meteorologist': 52057,\n",
       " 'beswick': 42577,\n",
       " 'boorman': 15493,\n",
       " 'voicework': 40847,\n",
       " \"ster'\": 52058,\n",
       " 'blustering': 22922,\n",
       " 'hj': 52059,\n",
       " 'intake': 27634,\n",
       " 'morally': 5621,\n",
       " 'jumbling': 40849,\n",
       " 'bowersock': 52060,\n",
       " \"'porky's'\": 52061,\n",
       " 'gershon': 16821,\n",
       " 'ludicrosity': 40850,\n",
       " 'coprophilia': 52062,\n",
       " 'expressively': 40851,\n",
       " \"india's\": 19500,\n",
       " \"post's\": 34710,\n",
       " 'wana': 52063,\n",
       " 'wang': 5283,\n",
       " 'wand': 30571,\n",
       " 'wane': 25245,\n",
       " 'edgeways': 52321,\n",
       " 'titanium': 34711,\n",
       " 'pinta': 40852,\n",
       " 'want': 178,\n",
       " 'pinto': 30572,\n",
       " 'whoopdedoodles': 52065,\n",
       " 'tchaikovsky': 21908,\n",
       " 'travel': 2103,\n",
       " \"'victory'\": 52066,\n",
       " 'copious': 11928,\n",
       " 'gouge': 22433,\n",
       " \"chapters'\": 52067,\n",
       " 'barbra': 6702,\n",
       " 'uselessness': 30573,\n",
       " \"wan'\": 52068,\n",
       " 'assimilated': 27635,\n",
       " 'petiot': 16116,\n",
       " 'most\\x85and': 52069,\n",
       " 'dinosaurs': 3930,\n",
       " 'wrong': 352,\n",
       " 'seda': 52070,\n",
       " 'stollen': 52071,\n",
       " 'sentencing': 34712,\n",
       " 'ouroboros': 40853,\n",
       " 'assimilates': 40854,\n",
       " 'colorfully': 40855,\n",
       " 'glenne': 27636,\n",
       " 'dongen': 52072,\n",
       " 'subplots': 4760,\n",
       " 'kiloton': 52073,\n",
       " 'chandon': 23381,\n",
       " \"effect'\": 34713,\n",
       " 'snugly': 27637,\n",
       " 'kuei': 40856,\n",
       " 'welcomed': 9092,\n",
       " 'dishonor': 30071,\n",
       " 'concurrence': 52075,\n",
       " 'stoicism': 23382,\n",
       " \"guys'\": 14896,\n",
       " \"beroemd'\": 52077,\n",
       " 'butcher': 6703,\n",
       " \"melfi's\": 40857,\n",
       " 'aargh': 30623,\n",
       " 'playhouse': 20599,\n",
       " 'wickedly': 11308,\n",
       " 'fit': 1180,\n",
       " 'labratory': 52078,\n",
       " 'lifeline': 40859,\n",
       " 'screaming': 1927,\n",
       " 'fix': 4287,\n",
       " 'cineliterate': 52079,\n",
       " 'fic': 52080,\n",
       " 'fia': 52081,\n",
       " 'fig': 34714,\n",
       " 'fmvs': 52082,\n",
       " 'fie': 52083,\n",
       " 'reentered': 52084,\n",
       " 'fin': 30574,\n",
       " 'doctresses': 52085,\n",
       " 'fil': 52086,\n",
       " 'zucker': 12606,\n",
       " 'ached': 31931,\n",
       " 'counsil': 52088,\n",
       " 'paterfamilias': 52089,\n",
       " 'songwriter': 13885,\n",
       " 'shivam': 34715,\n",
       " 'hurting': 9654,\n",
       " 'effects': 299,\n",
       " 'slauther': 52090,\n",
       " \"'flame'\": 52091,\n",
       " 'sommerset': 52092,\n",
       " 'interwhined': 52093,\n",
       " 'whacking': 27638,\n",
       " 'bartok': 52094,\n",
       " 'barton': 8775,\n",
       " 'frewer': 21909,\n",
       " \"fi'\": 52095,\n",
       " 'ingrid': 6192,\n",
       " 'stribor': 30575,\n",
       " 'approporiately': 52096,\n",
       " 'wobblyhand': 52097,\n",
       " 'tantalisingly': 52098,\n",
       " 'ankylosaurus': 52099,\n",
       " 'parasites': 17634,\n",
       " 'childen': 52100,\n",
       " \"jenkins'\": 52101,\n",
       " 'metafiction': 52102,\n",
       " 'golem': 17635,\n",
       " 'indiscretion': 40860,\n",
       " \"reeves'\": 23383,\n",
       " \"inamorata's\": 57781,\n",
       " 'brittannica': 52104,\n",
       " 'adapt': 7916,\n",
       " \"russo's\": 30576,\n",
       " 'guitarists': 48246,\n",
       " 'abbott': 10553,\n",
       " 'abbots': 40861,\n",
       " 'lanisha': 17649,\n",
       " 'magickal': 40863,\n",
       " 'mattter': 52105,\n",
       " \"'willy\": 52106,\n",
       " 'pumpkins': 34716,\n",
       " 'stuntpeople': 52107,\n",
       " 'estimate': 30577,\n",
       " 'ugghhh': 40864,\n",
       " 'gameplay': 11309,\n",
       " \"wern't\": 52108,\n",
       " \"n'sync\": 40865,\n",
       " 'sickeningly': 16117,\n",
       " 'chiara': 40866,\n",
       " 'disturbed': 4011,\n",
       " 'portmanteau': 40867,\n",
       " 'ineffectively': 52109,\n",
       " \"duchonvey's\": 82143,\n",
       " \"nasty'\": 37519,\n",
       " 'purpose': 1285,\n",
       " 'lazers': 52112,\n",
       " 'lightened': 28105,\n",
       " 'kaliganj': 52113,\n",
       " 'popularism': 52114,\n",
       " \"damme's\": 18511,\n",
       " 'stylistics': 30578,\n",
       " 'mindgaming': 52115,\n",
       " 'spoilerish': 46449,\n",
       " \"'corny'\": 52117,\n",
       " 'boerner': 34718,\n",
       " 'olds': 6792,\n",
       " 'bakelite': 52118,\n",
       " 'renovated': 27639,\n",
       " 'forrester': 27640,\n",
       " \"lumiere's\": 52119,\n",
       " 'gaskets': 52024,\n",
       " 'needed': 884,\n",
       " 'smight': 34719,\n",
       " 'master': 1297,\n",
       " \"edie's\": 25905,\n",
       " 'seeber': 40868,\n",
       " 'hiya': 52120,\n",
       " 'fuzziness': 52121,\n",
       " 'genesis': 14897,\n",
       " 'rewards': 12607,\n",
       " 'enthrall': 30579,\n",
       " \"'about\": 40869,\n",
       " \"recollection's\": 52122,\n",
       " 'mutilated': 11039,\n",
       " 'fatherlands': 52123,\n",
       " \"fischer's\": 52124,\n",
       " 'positively': 5399,\n",
       " '270': 34705,\n",
       " 'ahmed': 34720,\n",
       " 'zatoichi': 9836,\n",
       " 'bannister': 13886,\n",
       " 'anniversaries': 52127,\n",
       " \"helm's\": 30580,\n",
       " \"'work'\": 52128,\n",
       " 'exclaimed': 34721,\n",
       " \"'unfunny'\": 52129,\n",
       " '274': 52029,\n",
       " 'feeling': 544,\n",
       " \"wanda's\": 52131,\n",
       " 'dolan': 33266,\n",
       " '278': 52133,\n",
       " 'peacoat': 52134,\n",
       " 'brawny': 40870,\n",
       " 'mishra': 40871,\n",
       " 'worlders': 40872,\n",
       " 'protags': 52135,\n",
       " 'skullcap': 52136,\n",
       " 'dastagir': 57596,\n",
       " 'affairs': 5622,\n",
       " 'wholesome': 7799,\n",
       " 'hymen': 52137,\n",
       " 'paramedics': 25246,\n",
       " 'unpersons': 52138,\n",
       " 'heavyarms': 52139,\n",
       " 'affaire': 52140,\n",
       " 'coulisses': 52141,\n",
       " 'hymer': 40873,\n",
       " 'kremlin': 52142,\n",
       " 'shipments': 30581,\n",
       " 'pixilated': 52143,\n",
       " \"'00s\": 30582,\n",
       " 'diminishing': 18512,\n",
       " 'cinematic': 1357,\n",
       " 'resonates': 14898,\n",
       " 'simplify': 40874,\n",
       " \"nature'\": 40875,\n",
       " 'temptresses': 40876,\n",
       " 'reverence': 16822,\n",
       " 'resonated': 19502,\n",
       " 'dailey': 34722,\n",
       " '2\\x85': 52144,\n",
       " 'treize': 27641,\n",
       " 'majo': 52145,\n",
       " 'kiya': 21910,\n",
       " 'woolnough': 52146,\n",
       " 'thanatos': 39797,\n",
       " 'sandoval': 35731,\n",
       " 'dorama': 40879,\n",
       " \"o'shaughnessy\": 52147,\n",
       " 'tech': 4988,\n",
       " 'fugitives': 32018,\n",
       " 'teck': 30583,\n",
       " \"'e'\": 76125,\n",
       " 'doesn’t': 40881,\n",
       " 'purged': 52149,\n",
       " 'saying': 657,\n",
       " \"martians'\": 41095,\n",
       " 'norliss': 23418,\n",
       " 'dickey': 27642,\n",
       " 'dicker': 52152,\n",
       " \"'sependipity\": 52153,\n",
       " 'padded': 8422,\n",
       " 'ordell': 57792,\n",
       " \"sturges'\": 40882,\n",
       " 'independentcritics': 52154,\n",
       " 'tempted': 5745,\n",
       " \"atkinson's\": 34724,\n",
       " 'hounded': 25247,\n",
       " 'apace': 52155,\n",
       " 'clicked': 15494,\n",
       " \"'humor'\": 30584,\n",
       " \"martino's\": 17177,\n",
       " \"'supporting\": 52156,\n",
       " 'warmongering': 52032,\n",
       " \"zemeckis's\": 34725,\n",
       " 'lube': 21911,\n",
       " 'shocky': 52157,\n",
       " 'plate': 7476,\n",
       " 'plata': 40883,\n",
       " 'sturgess': 40884,\n",
       " \"nerds'\": 40885,\n",
       " 'plato': 20600,\n",
       " 'plath': 34726,\n",
       " 'platt': 40886,\n",
       " 'mcnab': 52159,\n",
       " 'clumsiness': 27643,\n",
       " 'altogether': 3899,\n",
       " 'massacring': 42584,\n",
       " 'bicenntinial': 52160,\n",
       " 'skaal': 40887,\n",
       " 'droning': 14360,\n",
       " 'lds': 8776,\n",
       " 'jaguar': 21912,\n",
       " \"cale's\": 34727,\n",
       " 'nicely': 1777,\n",
       " 'mummy': 4588,\n",
       " \"lot's\": 18513,\n",
       " 'patch': 10086,\n",
       " 'kerkhof': 50202,\n",
       " \"leader's\": 52161,\n",
       " \"'movie\": 27644,\n",
       " 'uncomfirmed': 52162,\n",
       " 'heirloom': 40888,\n",
       " 'wrangle': 47360,\n",
       " 'emotion\\x85': 52163,\n",
       " \"'stargate'\": 52164,\n",
       " 'pinoy': 40889,\n",
       " 'conchatta': 40890,\n",
       " 'broeke': 41128,\n",
       " 'advisedly': 40891,\n",
       " \"barker's\": 17636,\n",
       " 'descours': 52166,\n",
       " 'lots': 772,\n",
       " 'lotr': 9259,\n",
       " 'irs': 9879,\n",
       " 'lott': 52167,\n",
       " 'xvi': 40892,\n",
       " 'irk': 34728,\n",
       " 'irl': 52168,\n",
       " 'ira': 6887,\n",
       " 'belzer': 21913,\n",
       " 'irc': 52169,\n",
       " 'ire': 27645,\n",
       " 'requisites': 40893,\n",
       " 'discipline': 7693,\n",
       " 'lyoko': 52961,\n",
       " 'extend': 11310,\n",
       " 'nature': 873,\n",
       " \"'dickie'\": 52170,\n",
       " 'optimist': 40894,\n",
       " 'lapping': 30586,\n",
       " 'superficial': 3900,\n",
       " 'vestment': 52171,\n",
       " 'extent': 2823,\n",
       " 'tendons': 52172,\n",
       " \"heller's\": 52173,\n",
       " 'quagmires': 52174,\n",
       " 'miyako': 52175,\n",
       " 'moocow': 20601,\n",
       " \"coles'\": 52176,\n",
       " 'lookit': 40895,\n",
       " 'ravenously': 52177,\n",
       " 'levitating': 40896,\n",
       " 'perfunctorily': 52178,\n",
       " 'lookin': 30587,\n",
       " \"lot'\": 40898,\n",
       " 'lookie': 52179,\n",
       " 'fearlessly': 34870,\n",
       " 'libyan': 52181,\n",
       " 'fondles': 40899,\n",
       " 'gopher': 35714,\n",
       " 'wearying': 40901,\n",
       " \"nz's\": 52182,\n",
       " 'minuses': 27646,\n",
       " 'puposelessly': 52183,\n",
       " 'shandling': 52184,\n",
       " 'decapitates': 31268,\n",
       " 'humming': 11929,\n",
       " \"'nother\": 40902,\n",
       " 'smackdown': 21914,\n",
       " 'underdone': 30588,\n",
       " 'frf': 40903,\n",
       " 'triviality': 52185,\n",
       " 'fro': 25248,\n",
       " 'bothers': 8777,\n",
       " \"'kensington\": 52186,\n",
       " 'much': 73,\n",
       " 'muco': 34730,\n",
       " 'wiseguy': 22615,\n",
       " \"richie's\": 27648,\n",
       " 'tonino': 40904,\n",
       " 'unleavened': 52187,\n",
       " 'fry': 11587,\n",
       " \"'tv'\": 40905,\n",
       " 'toning': 40906,\n",
       " 'obese': 14361,\n",
       " 'sensationalized': 30589,\n",
       " 'spiv': 40907,\n",
       " 'spit': 6259,\n",
       " 'arkin': 7364,\n",
       " 'charleton': 21915,\n",
       " 'jeon': 16823,\n",
       " 'boardroom': 21916,\n",
       " 'doubts': 4989,\n",
       " 'spin': 3084,\n",
       " 'hepo': 53083,\n",
       " 'wildcat': 27649,\n",
       " 'venoms': 10584,\n",
       " 'misconstrues': 52191,\n",
       " 'mesmerising': 18514,\n",
       " 'misconstrued': 40908,\n",
       " 'rescinds': 52192,\n",
       " 'prostrate': 52193,\n",
       " 'majid': 40909,\n",
       " 'climbed': 16479,\n",
       " 'canoeing': 34731,\n",
       " 'majin': 52195,\n",
       " 'animie': 57804,\n",
       " 'sylke': 40910,\n",
       " 'conditioned': 14899,\n",
       " 'waddell': 40911,\n",
       " '3\\x85': 52196,\n",
       " 'hyperdrive': 41188,\n",
       " 'conditioner': 34732,\n",
       " 'bricklayer': 53153,\n",
       " 'hong': 2576,\n",
       " 'memoriam': 52198,\n",
       " 'inventively': 30592,\n",
       " \"levant's\": 25249,\n",
       " 'portobello': 20638,\n",
       " 'remand': 52200,\n",
       " 'mummified': 19504,\n",
       " 'honk': 27650,\n",
       " 'spews': 19505,\n",
       " 'visitations': 40912,\n",
       " 'mummifies': 52201,\n",
       " 'cavanaugh': 25250,\n",
       " 'zeon': 23385,\n",
       " \"jungle's\": 40913,\n",
       " 'viertel': 34733,\n",
       " 'frenchmen': 27651,\n",
       " 'torpedoes': 52202,\n",
       " 'schlessinger': 52203,\n",
       " 'torpedoed': 34734,\n",
       " 'blister': 69876,\n",
       " 'cinefest': 52204,\n",
       " 'furlough': 34735,\n",
       " 'mainsequence': 52205,\n",
       " 'mentors': 40914,\n",
       " 'academic': 9094,\n",
       " 'stillness': 20602,\n",
       " 'academia': 40915,\n",
       " 'lonelier': 52206,\n",
       " 'nibby': 52207,\n",
       " \"losers'\": 52208,\n",
       " 'cineastes': 40916,\n",
       " 'corporate': 4449,\n",
       " 'massaging': 40917,\n",
       " 'bellow': 30593,\n",
       " 'absurdities': 19506,\n",
       " 'expetations': 53241,\n",
       " 'nyfiken': 40918,\n",
       " 'mehras': 75638,\n",
       " 'lasse': 52209,\n",
       " 'visability': 52210,\n",
       " 'militarily': 33946,\n",
       " \"elder'\": 52211,\n",
       " 'gainsbourg': 19023,\n",
       " 'hah': 20603,\n",
       " 'hai': 13420,\n",
       " 'haj': 34736,\n",
       " 'hak': 25251,\n",
       " 'hal': 4311,\n",
       " 'ham': 4892,\n",
       " 'duffer': 53259,\n",
       " 'haa': 52213,\n",
       " 'had': 66,\n",
       " 'advancement': 11930,\n",
       " 'hag': 16825,\n",
       " \"hand'\": 25252,\n",
       " 'hay': 13421,\n",
       " 'mcnamara': 20604,\n",
       " \"mozart's\": 52214,\n",
       " 'duffel': 30731,\n",
       " 'haq': 30594,\n",
       " 'har': 13887,\n",
       " 'has': 44,\n",
       " 'hat': 2401,\n",
       " 'hav': 40919,\n",
       " 'haw': 30595,\n",
       " 'figtings': 52215,\n",
       " 'elders': 15495,\n",
       " 'underpanted': 52216,\n",
       " 'pninson': 52217,\n",
       " 'unequivocally': 27652,\n",
       " \"barbara's\": 23673,\n",
       " \"bello'\": 52219,\n",
       " 'indicative': 12997,\n",
       " 'yawnfest': 40920,\n",
       " 'hexploitation': 52220,\n",
       " \"loder's\": 52221,\n",
       " 'sleuthing': 27653,\n",
       " \"justin's\": 32622,\n",
       " \"'ball\": 52222,\n",
       " \"'summer\": 52223,\n",
       " \"'demons'\": 34935,\n",
       " \"mormon's\": 52225,\n",
       " \"laughton's\": 34737,\n",
       " 'debell': 52226,\n",
       " 'shipyard': 39724,\n",
       " 'unabashedly': 30597,\n",
       " 'disks': 40401,\n",
       " 'crowd': 2290,\n",
       " 'crowe': 10087,\n",
       " \"vancouver's\": 56434,\n",
       " 'mosques': 34738,\n",
       " 'crown': 6627,\n",
       " 'culpas': 52227,\n",
       " 'crows': 27654,\n",
       " 'surrell': 53344,\n",
       " 'flowless': 52229,\n",
       " 'sheirk': 52230,\n",
       " \"'three\": 40923,\n",
       " \"peterson'\": 52231,\n",
       " 'ooverall': 52232,\n",
       " 'perchance': 40924,\n",
       " 'bottom': 1321,\n",
       " 'chabert': 53363,\n",
       " 'sneha': 52233,\n",
       " 'inhuman': 13888,\n",
       " 'ichii': 52234,\n",
       " 'ursla': 52235,\n",
       " 'completly': 30598,\n",
       " 'moviedom': 40925,\n",
       " 'raddick': 52236,\n",
       " 'brundage': 51995,\n",
       " 'brigades': 40926,\n",
       " 'starring': 1181,\n",
       " \"'goal'\": 52237,\n",
       " 'caskets': 52238,\n",
       " 'willcock': 52239,\n",
       " \"threesome's\": 52240,\n",
       " \"mosque'\": 52241,\n",
       " \"cover's\": 52242,\n",
       " 'spaceships': 17637,\n",
       " 'anomalous': 40927,\n",
       " 'ptsd': 27655,\n",
       " 'shirdan': 52243,\n",
       " 'obscenity': 21962,\n",
       " 'lemmings': 30599,\n",
       " 'duccio': 30600,\n",
       " \"levene's\": 52244,\n",
       " \"'gorby'\": 52245,\n",
       " \"teenager's\": 25255,\n",
       " 'marshall': 5340,\n",
       " 'honeymoon': 9095,\n",
       " 'shoots': 3231,\n",
       " 'despised': 12258,\n",
       " 'okabasho': 52246,\n",
       " 'fabric': 8289,\n",
       " 'cannavale': 18515,\n",
       " 'raped': 3537,\n",
       " \"tutt's\": 52247,\n",
       " 'grasping': 17638,\n",
       " 'despises': 18516,\n",
       " \"thief's\": 40928,\n",
       " 'rapes': 8926,\n",
       " 'raper': 52248,\n",
       " \"eyre'\": 27656,\n",
       " 'walchek': 52249,\n",
       " \"elmo's\": 23386,\n",
       " 'perfumes': 40929,\n",
       " 'spurting': 21918,\n",
       " \"exposition'\\x85\": 52250,\n",
       " 'denoting': 52251,\n",
       " 'thesaurus': 34740,\n",
       " \"shoot'\": 40930,\n",
       " 'bonejack': 49759,\n",
       " 'simpsonian': 52253,\n",
       " 'hebetude': 30601,\n",
       " \"hallow's\": 34741,\n",
       " 'desperation\\x85': 52254,\n",
       " 'incinerator': 34742,\n",
       " 'congratulations': 10308,\n",
       " 'humbled': 52255,\n",
       " \"else's\": 5924,\n",
       " 'trelkovski': 40845,\n",
       " \"rape'\": 52256,\n",
       " \"'chapters'\": 59386,\n",
       " '1600s': 52257,\n",
       " 'martian': 7253,\n",
       " 'nicest': 25256,\n",
       " 'eyred': 52259,\n",
       " 'passenger': 9457,\n",
       " 'disgrace': 6041,\n",
       " 'moderne': 52260,\n",
       " 'barrymore': 5120,\n",
       " 'yankovich': 52261,\n",
       " 'moderns': 40931,\n",
       " 'studliest': 52262,\n",
       " 'bedsheet': 52263,\n",
       " 'decapitation': 14900,\n",
       " 'slurring': 52264,\n",
       " \"'nunsploitation'\": 52265,\n",
       " \"'character'\": 34743,\n",
       " 'cambodia': 9880,\n",
       " 'rebelious': 52266,\n",
       " 'pasadena': 27657,\n",
       " 'crowne': 40932,\n",
       " \"'bedchamber\": 52267,\n",
       " 'conjectural': 52268,\n",
       " 'appologize': 52269,\n",
       " 'halfassing': 52270,\n",
       " 'paycheque': 57816,\n",
       " 'palms': 20606,\n",
       " \"'islands\": 52271,\n",
       " 'hawked': 40933,\n",
       " 'palme': 21919,\n",
       " 'conservatively': 40934,\n",
       " 'larp': 64007,\n",
       " 'palma': 5558,\n",
       " 'smelling': 21920,\n",
       " 'aragorn': 12998,\n",
       " 'hawker': 52272,\n",
       " 'hawkes': 52273,\n",
       " 'explosions': 3975,\n",
       " 'loren': 8059,\n",
       " \"pyle's\": 52274,\n",
       " 'shootout': 6704,\n",
       " \"mike's\": 18517,\n",
       " \"driscoll's\": 52275,\n",
       " 'cogsworth': 40935,\n",
       " \"britian's\": 52276,\n",
       " 'childs': 34744,\n",
       " \"portrait's\": 52277,\n",
       " 'chain': 3626,\n",
       " 'whoever': 2497,\n",
       " 'puttered': 52278,\n",
       " 'childe': 52279,\n",
       " 'maywether': 52280,\n",
       " 'chair': 3036,\n",
       " \"rance's\": 52281,\n",
       " 'machu': 34745,\n",
       " 'ballet': 4517,\n",
       " 'grapples': 34746,\n",
       " 'summerize': 76152,\n",
       " 'freelance': 30603,\n",
       " \"andrea's\": 52283,\n",
       " '\\x91very': 52284,\n",
       " 'coolidge': 45879,\n",
       " 'mache': 18518,\n",
       " 'balled': 52285,\n",
       " 'grappled': 40937,\n",
       " 'macha': 18519,\n",
       " 'underlining': 21921,\n",
       " 'macho': 5623,\n",
       " 'oversight': 19507,\n",
       " 'machi': 25257,\n",
       " 'verbally': 11311,\n",
       " 'tenacious': 21922,\n",
       " 'windshields': 40938,\n",
       " 'paychecks': 18557,\n",
       " 'jerk': 3396,\n",
       " \"good'\": 11931,\n",
       " 'prancer': 34748,\n",
       " 'prances': 21923,\n",
       " 'olympus': 52286,\n",
       " 'lark': 21924,\n",
       " 'embark': 10785,\n",
       " 'gloomy': 7365,\n",
       " 'jehaan': 52287,\n",
       " 'turaqui': 52288,\n",
       " \"child'\": 20607,\n",
       " 'locked': 2894,\n",
       " 'pranced': 52289,\n",
       " 'exact': 2588,\n",
       " 'unattuned': 52290,\n",
       " 'minute': 783,\n",
       " 'skewed': 16118,\n",
       " 'hodgins': 40940,\n",
       " 'skewer': 34749,\n",
       " 'think\\x85': 52291,\n",
       " 'rosenstein': 38765,\n",
       " 'helmit': 52292,\n",
       " 'wrestlemanias': 34750,\n",
       " 'hindered': 16826,\n",
       " \"martha's\": 30604,\n",
       " 'cheree': 52293,\n",
       " \"pluckin'\": 52294,\n",
       " 'ogles': 40941,\n",
       " 'heavyweight': 11932,\n",
       " 'aada': 82190,\n",
       " 'chopping': 11312,\n",
       " 'strongboy': 61534,\n",
       " 'hegemonic': 41342,\n",
       " 'adorns': 40942,\n",
       " 'xxth': 41346,\n",
       " 'nobuhiro': 34751,\n",
       " 'capitães': 52298,\n",
       " 'kavogianni': 52299,\n",
       " 'antwerp': 13422,\n",
       " 'celebrated': 6538,\n",
       " 'roarke': 52300,\n",
       " 'baggins': 40943,\n",
       " 'cheeseburgers': 31270,\n",
       " 'matras': 52301,\n",
       " \"nineties'\": 52302,\n",
       " \"'craig'\": 52303,\n",
       " 'celebrates': 12999,\n",
       " 'unintentionally': 3383,\n",
       " 'drafted': 14362,\n",
       " 'climby': 52304,\n",
       " '303': 52305,\n",
       " 'oldies': 18520,\n",
       " 'climbs': 9096,\n",
       " 'honour': 9655,\n",
       " 'plucking': 34752,\n",
       " '305': 30074,\n",
       " 'address': 5514,\n",
       " 'menjou': 40944,\n",
       " \"'freak'\": 42592,\n",
       " 'dwindling': 19508,\n",
       " 'benson': 9458,\n",
       " 'white’s': 52307,\n",
       " 'shamelessness': 40945,\n",
       " 'impacted': 21925,\n",
       " 'upatz': 52308,\n",
       " 'cusack': 3840,\n",
       " \"flavia's\": 37567,\n",
       " 'effette': 52309,\n",
       " 'influx': 34753,\n",
       " 'boooooooo': 52310,\n",
       " 'dimitrova': 52311,\n",
       " 'houseman': 13423,\n",
       " 'bigas': 25259,\n",
       " 'boylen': 52312,\n",
       " 'phillipenes': 52313,\n",
       " 'fakery': 40946,\n",
       " \"grandpa's\": 27658,\n",
       " 'darnell': 27659,\n",
       " 'undergone': 19509,\n",
       " 'handbags': 52315,\n",
       " 'perished': 21926,\n",
       " 'pooped': 37778,\n",
       " 'vigour': 27660,\n",
       " 'opposed': 3627,\n",
       " 'etude': 52316,\n",
       " \"caine's\": 11799,\n",
       " 'doozers': 52317,\n",
       " 'photojournals': 34754,\n",
       " 'perishes': 52318,\n",
       " 'constrains': 34755,\n",
       " 'migenes': 40948,\n",
       " 'consoled': 30605,\n",
       " 'alastair': 16827,\n",
       " 'wvs': 52319,\n",
       " 'ooooooh': 52320,\n",
       " 'approving': 34756,\n",
       " 'consoles': 40949,\n",
       " 'disparagement': 52064,\n",
       " 'futureistic': 52322,\n",
       " 'rebounding': 52323,\n",
       " \"'date\": 52324,\n",
       " 'gregoire': 52325,\n",
       " 'rutherford': 21927,\n",
       " 'americanised': 34757,\n",
       " 'novikov': 82196,\n",
       " 'following': 1042,\n",
       " 'munroe': 34758,\n",
       " \"morita'\": 52326,\n",
       " 'christenssen': 52327,\n",
       " 'oatmeal': 23106,\n",
       " 'fossey': 25260,\n",
       " 'livered': 40950,\n",
       " 'listens': 13000,\n",
       " \"'marci\": 76164,\n",
       " \"otis's\": 52330,\n",
       " 'thanking': 23387,\n",
       " 'maude': 16019,\n",
       " 'extensions': 34759,\n",
       " 'ameteurish': 52332,\n",
       " \"commender's\": 52333,\n",
       " 'agricultural': 27661,\n",
       " 'convincingly': 4518,\n",
       " 'fueled': 17639,\n",
       " 'mahattan': 54014,\n",
       " \"paris's\": 40952,\n",
       " 'vulkan': 52336,\n",
       " 'stapes': 52337,\n",
       " 'odysessy': 52338,\n",
       " 'harmon': 12259,\n",
       " 'surfing': 4252,\n",
       " 'halloran': 23494,\n",
       " 'unbelieveably': 49580,\n",
       " \"'offed'\": 52339,\n",
       " 'quadrant': 30607,\n",
       " 'inhabiting': 19510,\n",
       " 'nebbish': 34760,\n",
       " 'forebears': 40953,\n",
       " 'skirmish': 34761,\n",
       " 'ocassionally': 52340,\n",
       " \"'resist\": 52341,\n",
       " 'impactful': 21928,\n",
       " 'spicier': 52342,\n",
       " 'touristy': 40954,\n",
       " \"'football'\": 52343,\n",
       " 'webpage': 40955,\n",
       " 'exurbia': 52345,\n",
       " 'jucier': 52346,\n",
       " 'professors': 14901,\n",
       " 'structuring': 34762,\n",
       " 'jig': 30608,\n",
       " 'overlord': 40956,\n",
       " 'disconnect': 25261,\n",
       " 'sniffle': 82201,\n",
       " 'slimeball': 40957,\n",
       " 'jia': 40958,\n",
       " 'milked': 16828,\n",
       " 'banjoes': 40959,\n",
       " 'jim': 1237,\n",
       " 'workforces': 52348,\n",
       " 'jip': 52349,\n",
       " 'rotweiller': 52350,\n",
       " 'mundaneness': 34763,\n",
       " \"'ninja'\": 52351,\n",
       " \"dead'\": 11040,\n",
       " \"cipriani's\": 40960,\n",
       " 'modestly': 20608,\n",
       " \"professor'\": 52352,\n",
       " 'shacked': 40961,\n",
       " 'bashful': 34764,\n",
       " 'sorter': 23388,\n",
       " 'overpowering': 16120,\n",
       " 'workmanlike': 18521,\n",
       " 'henpecked': 27662,\n",
       " 'sorted': 18522,\n",
       " \"jōb's\": 52354,\n",
       " \"'always\": 52355,\n",
       " \"'baptists\": 34765,\n",
       " 'dreamcatchers': 52356,\n",
       " \"'silence'\": 52357,\n",
       " 'hickory': 21929,\n",
       " 'fun\\x97yet': 52358,\n",
       " 'breakumentary': 52359,\n",
       " 'didn': 15496,\n",
       " 'didi': 52360,\n",
       " 'pealing': 52361,\n",
       " 'dispite': 40962,\n",
       " \"italy's\": 25262,\n",
       " 'instability': 21930,\n",
       " 'quarter': 6539,\n",
       " 'quartet': 12608,\n",
       " 'padmé': 52362,\n",
       " \"'bleedmedry\": 52363,\n",
       " 'pahalniuk': 52364,\n",
       " 'honduras': 52365,\n",
       " 'bursting': 10786,\n",
       " \"pablo's\": 41465,\n",
       " 'irremediably': 52367,\n",
       " 'presages': 40963,\n",
       " 'bowlegged': 57832,\n",
       " 'dalip': 65183,\n",
       " 'entering': 6260,\n",
       " 'newsradio': 76172,\n",
       " 'presaged': 54150,\n",
       " \"giallo's\": 27663,\n",
       " 'bouyant': 40964,\n",
       " 'amerterish': 52368,\n",
       " 'rajni': 18523,\n",
       " 'leeves': 30610,\n",
       " 'macauley': 34767,\n",
       " 'seriously': 612,\n",
       " 'sugercoma': 52369,\n",
       " 'grimstead': 52370,\n",
       " \"'fairy'\": 52371,\n",
       " 'zenda': 30611,\n",
       " \"'twins'\": 52372,\n",
       " 'realisation': 17640,\n",
       " 'highsmith': 27664,\n",
       " 'raunchy': 7817,\n",
       " 'incentives': 40965,\n",
       " 'flatson': 52374,\n",
       " 'snooker': 35097,\n",
       " 'crazies': 16829,\n",
       " 'crazier': 14902,\n",
       " 'grandma': 7094,\n",
       " 'napunsaktha': 52375,\n",
       " 'workmanship': 30612,\n",
       " 'reisner': 52376,\n",
       " \"sanford's\": 61306,\n",
       " '\\x91doña': 52377,\n",
       " 'modest': 6108,\n",
       " \"everything's\": 19153,\n",
       " 'hamer': 40966,\n",
       " \"couldn't'\": 52379,\n",
       " 'quibble': 13001,\n",
       " 'socking': 52380,\n",
       " 'tingler': 21931,\n",
       " 'gutman': 52381,\n",
       " 'lachlan': 40967,\n",
       " 'tableaus': 52382,\n",
       " 'headbanger': 52383,\n",
       " 'spoken': 2847,\n",
       " 'cerebrally': 34768,\n",
       " \"'road\": 23490,\n",
       " 'tableaux': 21932,\n",
       " \"proust's\": 40968,\n",
       " 'periodical': 40969,\n",
       " \"shoveller's\": 52385,\n",
       " 'tamara': 25263,\n",
       " 'affords': 17641,\n",
       " 'concert': 3249,\n",
       " \"yara's\": 87955,\n",
       " 'someome': 52386,\n",
       " 'lingering': 8424,\n",
       " \"abraham's\": 41511,\n",
       " 'beesley': 34769,\n",
       " 'cherbourg': 34770,\n",
       " 'kagan': 28624,\n",
       " 'snatch': 9097,\n",
       " \"miyazaki's\": 9260,\n",
       " 'absorbs': 25264,\n",
       " \"koltai's\": 40970,\n",
       " 'tingled': 64027,\n",
       " 'crossroads': 19511,\n",
       " 'rehab': 16121,\n",
       " 'falworth': 52389,\n",
       " 'sequals': 52390,\n",
       " ...}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word = {id_ + 3: word for word, id_ in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    id_to_word[id_] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> this film was just brilliant casting location scenery story'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([id_to_word[id_] for id_ in x_train[0][:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "train_size = info.splits[\"train\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x_batch, y_batch):\n",
    "    x_batch = tf.strings.substr(x_batch, 0, 300)\n",
    "    x_batch = tf.strings.regex_replace(x_batch, b\"<br\\\\s*/?>\", b\" \")\n",
    "    x_batch = tf.strings.regex_replace(x_batch, b\"[^a-zA-Z']\", b\" \")\n",
    "    x_batch = tf.strings.split(x_batch)\n",
    "    return x_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocabulary = Counter()\n",
    "for x_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
    "    for review in x_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214741), (b'the', 61137), (b'a', 38564)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "truncated_vocabulary = [\n",
    "    word for word, count in vocabulary.most_common()[:vocab_size]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   22,    12,    11, 10053]], dtype=int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.lookup(tf.constant([b\"This movie was faaaaaantastic\".split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(x_batch, y_batch):\n",
    "    return table.lookup(x_batch), y_batch\n",
    "\n",
    "train_set = datasets[\"train\"].batch(32).map(preprocess)\n",
    "train_set = train_set.map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 64s 76ms/step - loss: 0.6030 - accuracy: 0.6514\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.3779 - accuracy: 0.8370\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.2280 - accuracy: 0.9128\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.1356 - accuracy: 0.9532\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 62s 80ms/step - loss: 0.1002 - accuracy: 0.9648\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size, \n",
    "                          input_shape=[None], mask_zero=True),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "jupyter_dir = Path.cwd().parent\n",
    "log_dir = jupyter_dir / \"my_logs\" / \"imdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 72s 86ms/step - loss: 0.5928 - accuracy: 0.65740s - loss: 0.5929 - accuracy: 0.65\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 0.3730 - accuracy: 0.8415\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.2281 - accuracy: 0.9129\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 73s 94ms/step - loss: 0.1386 - accuracy: 0.9522\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 70s 90ms/step - loss: 0.1018 - accuracy: 0.9642\n"
     ]
    }
   ],
   "source": [
    "K = keras.backend\n",
    "embed_size = 128\n",
    "inputs = keras.layers.Input(shape=[None])\n",
    "mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs)\n",
    "z = keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size)(inputs)\n",
    "z = keras.layers.GRU(128, return_sequences=True)(z, mask=mask)\n",
    "z = keras.layers.GRU(128)(z, mask=mask)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(z)\n",
    "model = keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=5, \n",
    "                    callbacks=[keras.callbacks.TensorBoard(log_dir)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins import projector\n",
    "\n",
    "with open(log_dir / \"metadata.tsv\", \"w\") as f:\n",
    "    for subwords in truncated_vocabulary:\n",
    "        f.write(\"{}\\n\".format(subwords))\n",
    "    for unknown in range(1, 1000):\n",
    "        f.write(\"unknown #{}\\n\".format(unknown))\n",
    "        \n",
    "weights = tf.Variable(model.layers[1].get_weights()[0][1:])\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(log_dir / \"embedding.ckpt\")\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reuse pretrained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\", \n",
    "                  dtype=tf.string, input_shape=[], output_shape=[50]),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.5917 - accuracy: 0.6853\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.5210 - accuracy: 0.7461\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.5145 - accuracy: 0.7485\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.5103 - accuracy: 0.7513\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.5071 - accuracy: 0.7547\n"
     ]
    }
   ],
   "source": [
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "train_size = info.splits['train'].num_examples\n",
    "batch_size = 32\n",
    "train_set = datasets['train'].batch(batch_size).prefetch(1)\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "embed_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "\n",
    "encoder = keras.layers.LSTM(512, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(512)\n",
    "output_layer = keras.layers.Dense(vocab_size)\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, \n",
    "                                                 output_layer=output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings, initial_state=encoder_state,\n",
    "    sequence_length=sequence_lengths)\n",
    "y_proba = tf.nn.softmax(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(\n",
    "    inputs=[encoder_inputs, decoder_inputs, sequence_lengths], outputs=[y_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "32/32 [==============================] - 7s 146ms/step - loss: 4.6052\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 4.6037\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(100, size=10*1000).reshape(1000, 10)\n",
    "y = np.random.randint(100, size=15*1000).reshape(1000, 15)\n",
    "x_decoder = np.c_[np.zeros((1000, 1)), y[:, :-1]]\n",
    "seq_lengths = np.full([1000], 15)\n",
    "\n",
    "history = model.fit([x, x_decoder, seq_lengths], y, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, None, 10)          660       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 20)          1320      \n",
      "=================================================================\n",
      "Total params: 1,980\n",
      "Trainable params: 1,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(10, return_sequences=True, input_shape=[None, 10]),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(10, return_sequences=True))\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_width = 10\n",
    "decoder = tfa.seq2seq.beam_search_decoder.BeamSearchDecoder(\n",
    "    cell=decoder_cell, beam_width=beam_width, output_layer=output_layer)\n",
    "decoder_initial_state = tfa.seq2seq.beam_search_decoder.tile_batch(\n",
    "    encoder_state, multiplier=beam_width)\n",
    "outputs, _, _ = decoder(\n",
    "    decoder_embeddings, start_tokens=start_tokens, end_token=end_token, \n",
    "    initial_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(keras.layers.Layer):\n",
    "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        if max_dims % 2 == 1: max_dims += 1\n",
    "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
    "        pos_emb = np.empty((1, max_steps, max_dims))\n",
    "        pos_emb[0, :, ::2] = np.sin(p / 10000**(2 * i / max_dims)).T\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10000**(2 * i / max_dims)).T\n",
    "        self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs)\n",
    "        return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 512; max_steps=500; vocab_size=10000\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "positional_encoding = PositionalEncoding(max_steps, max_dims=embed_size)\n",
    "encoder_in = positional_encoding(encoder_embeddings)\n",
    "decoder_in = positional_encoding(decoder_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "    \n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "    \n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "    \n",
    "    attention_weights =tf.nn.softmax(logits, axis=-1)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1.000000e+01, 9.276602e-25]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       " array([[8.4332744e-26, 1.0000000e+00, 8.4332744e-26, 8.4332744e-26]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v)\n",
    "temp_out, temp_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[550. ,   5.5]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       " array([[4.2166372e-26, 4.2166372e-26, 5.0000000e-01, 5.0000000e-01]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v)\n",
    "temp_out, temp_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[5.500000e+02, 5.500000e+00],\n",
       "        [1.000000e+01, 9.276602e-25],\n",
       "        [5.500000e+00, 4.638301e-25]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       " array([[4.2166372e-26, 4.2166372e-26, 5.0000000e-01, 5.0000000e-01],\n",
       "        [8.4332744e-26, 1.0000000e+00, 8.4332744e-26, 8.4332744e-26],\n",
       "        [5.0000000e-01, 5.0000000e-01, 4.2166372e-26, 4.2166372e-26]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v)\n",
    "temp_out, temp_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // num_heads\n",
    "        \n",
    "        self.query_dense = keras.layers.Dense(d_model)\n",
    "        self.key_dense = keras.layers.Dense(d_model)\n",
    "        self.value_dense = keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = keras.layers.Dense(d_model)\n",
    "    \n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, \n",
    "                                           self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        \n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "        \n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        \n",
    "        outputs = self.dense(concat_attention)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name='encoder_layer'):\n",
    "    inputs = keras.layers.Input(shape=(None, d_model), name='inputs')\n",
    "    \n",
    "    padding_mask = keras.layers.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name='attention')({\n",
    "        'query': inputs, 'key': inputs, 'value': inputs,\n",
    "        'mask': padding_mask\n",
    "    })\n",
    "    \n",
    "    attention = keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "    \n",
    "    outputs = keras.layers.Dense(dff, activation='relu')(attention)\n",
    "    outputs = keras.layers.Dense(d_model)(outputs)\n",
    "    \n",
    "    outputs = keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "    \n",
    "    return keras.models.Model(inputs=[inputs, padding_mask], outputs=outputs, \n",
    "                             name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, diff, d_model, num_heads, dropout, \n",
    "            name='encoder'):\n",
    "    inputs = keras.layers.Input(shape=(None, ), name='inputs')\n",
    "    \n",
    "    padding_mask = keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "    \n",
    "    embeddings = keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= keras.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(diff, d_model, num_heads, dropout, \n",
    "                               name=\"encoder_layer_{}\".format(i))([outputs,\n",
    "                                                                  padding_mask])\n",
    "    return keras.models.Model(inputs=[inputs, padding_mask], \n",
    "                             outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look Ahead Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name='decoder_layer'):\n",
    "    inputs = keras.layers.Input(shape=(None, d_model), name='inputs')\n",
    "    enc_outputs = keras.layers.Input(shape=(None, d_model), \n",
    "                                     name='encoder_outputs')\n",
    "    \n",
    "    look_ahead_mask = keras.layers.Input(shape=(1, None, None), \n",
    "                                         name='look_ahead_mask')\n",
    "    \n",
    "    attention1 = MultiHeadAttention(d_model, num_heads, \n",
    "                                    name=\"attention_1\")(inputs={\n",
    "        'query': inputs, 'key': inputs, 'value': inputs, \n",
    "        'mask': look_ahead_mask\n",
    "    })\n",
    "    \n",
    "    attention1 = keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "    \n",
    "    attention2 = MultiHeadAttention(d_model, num_heads, \n",
    "                                   name=\"attention_2\")(inputs={\n",
    "        'query': attention1, 'key': enc_outputs, 'value': enc_outputs,\n",
    "        'mask': padding_mask\n",
    "    })\n",
    "    \n",
    "    attention2 = keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "    \n",
    "    outputs = keras.layers.Dense(dff, activation='relu')(attention2)\n",
    "    outputs = keras.layers.Dense(d_model)(outputs)\n",
    "    \n",
    "    outputs = keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "    \n",
    "    return keras.models.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff, d_model, num_heads, dropout, \n",
    "           name='decoder'):\n",
    "    inputs = keras.layers.Input(shape=(None, ), name='inputs')\n",
    "    enc_outputs = keras.layers.Input(shape=(None, d_model), \n",
    "                                     name='encoder_outputs')\n",
    "    \n",
    "    look_ahead_mask = keras.layers.Input(shape=(1, None, None), \n",
    "                                         name='look_ahead_mask')\n",
    "    padding_mask = keras.layers.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    embeddings = keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff, d_model, num_heads, dropout, \n",
    "                               name='decoder_layer_{}'.format(i),\n",
    "                )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "        \n",
    "    return keras.models.Model(inputs=[inputs, enc_outputs, \n",
    "                                      look_ahead_mask, padding_mask], \n",
    "                             outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff, d_model, num_heads, dropout, \n",
    "               name='transformer'):\n",
    "    inputs = keras.layers.Input(shape=(None, ), name='inputs')\n",
    "    dec_inputs = keras.layers.Input(shape=(None, ), name='dec_inputs')\n",
    "    \n",
    "    enc_padding_mask = keras.layers.Lambda(create_padding_mask, \n",
    "                                          output_shape=(1, 1, None), \n",
    "                                          name='enc_padding_mask')(inputs)\n",
    "    look_ahead_mask = keras.layers.Lambda(create_look_ahead_mask, \n",
    "                                         output_shape=(1, None, None), \n",
    "                                         name='look_ahead_mask')(dec_inputs)\n",
    "    dec_padding_mask = keras.layers.Lambda(create_padding_mask, \n",
    "                                          output_shape=(1, 1, None),\n",
    "                                          name='dec_padding_mask')(inputs)\n",
    "    \n",
    "    enc_outputs = encoder(vocab_size, num_layers, dff, d_model, num_heads, \n",
    "                         dropout)(inputs=[inputs, enc_padding_mask])\n",
    "    dec_outputs = decoder(vocab_size, num_layers, dff, d_model, num_heads, \n",
    "                         dropout)(inputs=[dec_inputs, enc_outputs, \n",
    "                                         look_ahead_mask, dec_padding_mask])\n",
    "    \n",
    "    outputs = keras.layers.Dense(vocab_size, name='outputs')(dec_outputs)\n",
    "    \n",
    "    return keras.models.Model(inputs=[inputs, dec_inputs], outputs=outputs, \n",
    "                             name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 8번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_kind = {'B', 'T', 'S', 'X', 'S', 'E', 'X', 'P', 'P', 'T', 'V'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B', 'E', 'P', 'S', 'T', 'V', 'X'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B'], dtype='<U1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(list(char_kind), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dic = {key: value+1 for value, key in enumerate(list(char_kind))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': 1, 'T': 2, 'B': 3, 'P': 4, 'E': 5, 'V': 6, 'S': 7}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'X', 2: 'T', 3: 'B', 4: 'P', 5: 'E', 6: 'V', 7: 'S'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dic_reverse = {key: value for value, key in char_dic.items()}\n",
    "char_dic_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_grammer = [\n",
    "    [('B', 1)],           # 0 state \n",
    "    [('T', 2), ('P', 3)], # 1 state\n",
    "    [('S', 2), ('X', 4)], # 2 state\n",
    "    [('T', 3), ('V', 5)], # 3 state\n",
    "    [('X', 3), ('S', 6)], # 4 state\n",
    "    [('P', 4), ('V', 6)], # 5 state\n",
    "    [('E', None)],           # 6 state\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer = [\n",
    "    [('B', 1)], \n",
    "    [('T', 2), ('P', 3)],\n",
    "    [(min_grammer, 4)],\n",
    "    [(min_grammer, 5)],\n",
    "    [('T', 6)],\n",
    "    [('P', 6)],\n",
    "    [('E', None)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reber(grammer):\n",
    "    state = 0\n",
    "    text = \"\"\n",
    "    while state is not None:\n",
    "        node_lst = grammer[state]\n",
    "        random_idx = np.random.randint(len(node_lst))\n",
    "        char, state = node_lst[random_idx]\n",
    "        if isinstance(char, list):\n",
    "            char = generate_reber(char)\n",
    "        text += char\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nonreber(grammer):\n",
    "    reber = generate_reber(grammer)\n",
    "    random_idx = np.random.randint(len(reber))\n",
    "    reber_char = reber[random_idx]\n",
    "    nonreber_char = np.random.choice(list(char_kind - set(reber_char)), 1)[0]\n",
    "    return reber[:random_idx] + nonreber_char + reber[random_idx + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BPBTSSSXSEPB'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_nonreber(grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_index(text):\n",
    "    return [char_dic[char] - 1 for char in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xysplit(x):\n",
    "    x, y = x[:, :-1], x[:, -1:]\n",
    "    x = tf.one_hot(x, depth=7)\n",
    "    y = y.to_tensor()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(size, shuffle=None):\n",
    "    data = [text_to_index(generate_reber(grammer)) + [1] for i in range(size // 2)]\n",
    "    data += [text_to_index(generate_nonreber(grammer)) + [0] for i in range(size // 2)]\n",
    "    \n",
    "    data_ragged = tf.ragged.constant(data, ragged_rank=1)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data_ragged)\n",
    "    if shuffle is not None:\n",
    "        dataset = dataset.shuffle(shuffle)\n",
    "    dataset = dataset.batch(32, drop_remainder=True).map(xysplit)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 2, 1, 0, 0, 1, 1, 1, 5, 5, 4, 1, 4, 1],\n",
       " [2, 1, 2, 1, 6, 6, 0, 6, 4, 1, 4, 1],\n",
       " [2, 3, 2, 3, 5, 5, 4, 3, 4, 1],\n",
       " [2, 1, 2, 3, 5, 5, 4, 1, 4, 1],\n",
       " [2, 3, 2, 1, 6, 0, 0, 5, 5, 4, 3, 4, 1],\n",
       " [2, 1, 2, 1, 6, 6, 6, 0, 0, 1, 5, 5, 4, 1, 4, 1],\n",
       " [2, 1, 2, 1, 0, 0, 5, 5, 4, 1, 4, 1],\n",
       " [2, 1, 2, 1, 0, 0, 1, 1, 5, 3, 0, 5, 5, 4, 1, 4, 1],\n",
       " [2, 1, 2, 3, 1, 5, 3, 6, 4, 1, 4, 1],\n",
       " [2, 1, 2, 3, 5, 3, 0, 1, 1, 1, 1, 5, 5, 4, 1, 4, 1]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = generate_dataset(10000, shuffle=10000)\n",
    "valid_dataset = generate_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(30, input_shape=(None, 7)),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "312/312 [==============================] - 3s 5ms/step - loss: 0.6883 - accuracy: 0.5365 - val_loss: 0.6745 - val_accuracy: 0.4945\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.6477 - accuracy: 0.5965 - val_loss: 0.6283 - val_accuracy: 0.4733\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5657 - accuracy: 0.7035 - val_loss: 0.5403 - val_accuracy: 0.7540\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8381 - val_loss: 0.3441 - val_accuracy: 0.8735\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.2825 - accuracy: 0.9038 - val_loss: 0.1934 - val_accuracy: 0.9456\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.1617 - accuracy: 0.9539 - val_loss: 0.1221 - val_accuracy: 0.9718\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9741 - val_loss: 0.0903 - val_accuracy: 0.9808\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0832 - accuracy: 0.9828 - val_loss: 0.0826 - val_accuracy: 0.9819\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0687 - accuracy: 0.9860 - val_loss: 0.0893 - val_accuracy: 0.9798\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0662 - accuracy: 0.9883 - val_loss: 0.0842 - val_accuracy: 0.9803\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0568 - accuracy: 0.9908 - val_loss: 0.0647 - val_accuracy: 0.9909\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0521 - accuracy: 0.9916 - val_loss: 0.0587 - val_accuracy: 0.9909\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0475 - accuracy: 0.9928 - val_loss: 0.0551 - val_accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0418 - accuracy: 0.9933 - val_loss: 0.0376 - val_accuracy: 0.9919\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0277 - accuracy: 0.9939 - val_loss: 0.0215 - val_accuracy: 0.9919\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0158 - accuracy: 0.9941 - val_loss: 0.5570 - val_accuracy: 0.8422\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0428 - accuracy: 0.9869 - val_loss: 0.0083 - val_accuracy: 0.9995\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9998 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9995\n",
      "Epoch 20/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f66cd76e08>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_dataset, validation_data=valid_dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipeline(x):\n",
    "    x = list(map(text_to_index, x))\n",
    "    x = tf.ragged.constant(x, ragged_rank=1)\n",
    "    x = tf.one_hot(x, depth=7)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strings = [\"BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE\",\n",
    "                \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE\"]\n",
    "\n",
    "x_test = test_pipeline(test_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[6.829202e-04],\n",
       "       [9.977852e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 9번"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'y']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \n",
    "          \"august\", \"september\", \"october\", \"november\", \"december\"]\n",
    "months_ = \"\"\n",
    "for i in months:\n",
    "    months_ += i\n",
    "alphabets = sorted(list(set(months_)))\n",
    "alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [str(i) for i in range(10)]\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " ',',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'y']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_chars = [\" \", \",\"] + numbers + alphabets\n",
    "input_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_chars = [\"-\"] + numbers\n",
    "output_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(1, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    month = np.random.randint(12)\n",
    "    day = np.random.randint(1, 32)\n",
    "    year = np.random.randint(1000, 10000)\n",
    "    input_data = months[month] + \" {0:02d}, {1:04d}\".format(day, year)\n",
    "    \n",
    "    target = \"{0}-{1:02d}-{2:02d}\".format(year, month+1, day)\n",
    "    return input_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('february 30, 8581', '8581-02-30')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_index(input_data, target): \n",
    "    input_index = [input_chars.index(i) for i in input_data]\n",
    "    target_index = [output_chars.index(i) for i in target]\n",
    "    return input_index, target_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "august 02, 6653 6653-08-02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([12, 30, 18, 30, 28, 29, 0, 2, 4, 1, 0, 8, 8, 7, 5],\n",
       " [7, 7, 6, 4, 0, 1, 9, 0, 1, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data, target = generate_data()\n",
    "print(input_data, target)\n",
    "\n",
    "char_to_index(input_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    x_batch, y_batch = batch[:, :-10], batch[:, -10:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(size, shuffle=None):\n",
    "    data = [[*char_to_index(*generate_data())] for i in range(size)]\n",
    "    data = [x[0] + x[1] for x in data]\n",
    "    data_ragged = tf.ragged.constant(data, ragged_rank=1)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data_ragged)\n",
    "    if shuffle is not None:\n",
    "        dataset = dataset.shuffle(shuffle)\n",
    "    dataset = dataset.batch(32).map(lambda x: (x[:, :-10], x[:, -10:]))\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generate_dataset(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[21, 12, 24, 30, 12, 27, 32, 0, 5, 2, 1, 0, 3, 9, 4, 2], [17, 16, 13, 27, 30, 12, 27, 32, 0, 3, 4, 1, 0, 6, 5, 9, 11], [12, 26, 27, 20, 22, 0, 4, 10, 1, 0, 5, 10, 5, 3], [15, 16, 14, 16, 23, 13, 16, 27, 0, 3, 5, 1, 0, 6, 7, 5, 4], [21, 30, 24, 16, 0, 4, 2, 1, 0, 10, 6, 4, 8], [21, 30, 24, 16, 0, 3, 3, 1, 0, 10, 5, 4, 11], [25, 14, 29, 25, 13, 16, 27, 0, 3, 11, 1, 0, 3, 8, 2, 8], [21, 30, 24, 16, 0, 2, 4, 1, 0, 10, 2, 6, 10], [21, 12, 24, 30, 12, 27, 32, 0, 2, 6, 1, 0, 7, 6, 11, 2], [12, 30, 18, 30, 28, 29, 0, 4, 6, 1, 0, 10, 9, 9, 3], [12, 26, 27, 20, 22, 0, 3, 9, 1, 0, 11, 9, 2, 5], [21, 12, 24, 30, 12, 27, 32, 0, 3, 2, 1, 0, 9, 10, 2, 6], [21, 12, 24, 30, 12, 27, 32, 0, 2, 4, 1, 0, 11, 10, 11, 10], [12, 26, 27, 20, 22, 0, 4, 3, 1, 0, 3, 11, 9, 5], [21, 30, 24, 16, 0, 5, 2, 1, 0, 8, 5, 11, 3], [12, 26, 27, 20, 22, 0, 2, 3, 1, 0, 11, 2, 8, 10], [12, 30, 18, 30, 28, 29, 0, 4, 6, 1, 0, 4, 4, 4, 10], [21, 30, 22, 32, 0, 2, 8, 1, 0, 8, 3, 9, 4], [12, 26, 27, 20, 22, 0, 4, 10, 1, 0, 11, 5, 7, 11], [12, 30, 18, 30, 28, 29, 0, 4, 9, 1, 0, 6, 6, 6, 11], [12, 30, 18, 30, 28, 29, 0, 3, 11, 1, 0, 4, 8, 9, 6], [12, 26, 27, 20, 22, 0, 3, 10, 1, 0, 9, 6, 3, 8], [25, 14, 29, 25, 13, 16, 27, 0, 4, 11, 1, 0, 9, 11, 2, 2], [12, 30, 18, 30, 28, 29, 0, 2, 7, 1, 0, 11, 6, 6, 2], [21, 30, 22, 32, 0, 2, 11, 1, 0, 9, 8, 9, 5], [24, 25, 31, 16, 23, 13, 16, 27, 0, 3, 10, 1, 0, 6, 11, 4, 11], [28, 16, 26, 29, 16, 23, 13, 16, 27, 0, 2, 8, 1, 0, 6, 10, 2, 2], [12, 30, 18, 30, 28, 29, 0, 5, 3, 1, 0, 8, 9, 5, 6], [25, 14, 29, 25, 13, 16, 27, 0, 3, 7, 1, 0, 6, 10, 3, 9], [15, 16, 14, 16, 23, 13, 16, 27, 0, 3, 7, 1, 0, 6, 7, 6, 2], [23, 12, 32, 0, 3, 11, 1, 0, 5, 5, 4, 2], [15, 16, 14, 16, 23, 13, 16, 27, 0, 2, 4, 1, 0, 3, 7, 8, 10]]>\n",
      "<tf.RaggedTensor [[2, 8, 3, 1, 0, 1, 2, 0, 4, 1], [5, 4, 8, 10, 0, 1, 3, 0, 2, 3], [4, 9, 4, 2, 0, 1, 5, 0, 3, 9], [5, 6, 4, 3, 0, 2, 3, 0, 2, 4], [9, 5, 3, 7, 0, 1, 7, 0, 3, 1], [9, 4, 3, 10, 0, 1, 7, 0, 2, 2], [2, 7, 1, 7, 0, 2, 1, 0, 2, 10], [9, 1, 5, 9, 0, 1, 7, 0, 1, 3], [6, 5, 10, 1, 0, 1, 2, 0, 1, 5], [9, 8, 8, 2, 0, 1, 9, 0, 3, 5], [10, 8, 1, 4, 0, 1, 5, 0, 2, 8], [8, 9, 1, 5, 0, 1, 2, 0, 2, 1], [10, 9, 10, 9, 0, 1, 2, 0, 1, 3], [2, 10, 8, 4, 0, 1, 5, 0, 3, 2], [7, 4, 10, 2, 0, 1, 7, 0, 4, 1], [10, 1, 7, 9, 0, 1, 5, 0, 1, 2], [3, 3, 3, 9, 0, 1, 9, 0, 3, 5], [7, 2, 8, 3, 0, 1, 8, 0, 1, 7], [10, 4, 6, 10, 0, 1, 5, 0, 3, 9], [5, 5, 5, 10, 0, 1, 9, 0, 3, 8], [3, 7, 8, 5, 0, 1, 9, 0, 2, 10], [8, 5, 2, 7, 0, 1, 5, 0, 2, 9], [8, 10, 1, 1, 0, 2, 1, 0, 3, 10], [10, 5, 5, 1, 0, 1, 9, 0, 1, 6], [8, 7, 8, 4, 0, 1, 8, 0, 1, 10], [5, 10, 3, 10, 0, 2, 2, 0, 2, 9], [5, 9, 1, 1, 0, 1, 10, 0, 1, 7], [7, 8, 4, 5, 0, 1, 9, 0, 4, 2], [5, 9, 2, 8, 0, 2, 1, 0, 2, 6], [5, 6, 5, 1, 0, 2, 3, 0, 2, 6], [4, 4, 3, 1, 0, 1, 6, 0, 2, 10], [2, 6, 7, 9, 0, 2, 3, 0, 1, 3]]>\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(1):\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate dataset ( book )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "def random_dates(n_dates):\n",
    "    min_date = date(1000, 1, 1).toordinal()\n",
    "    max_date = date(9999, 12, 31).toordinal()\n",
    "    \n",
    "    ordinals = np.random.randint(max_date - min_date + 1, size=n_dates) + min_date\n",
    "    \n",
    "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
    "    \n",
    "    x = [months[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
    "    y = [dt.isoformat() for dt in dates]\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 20, 7075 \t 7075-09-20\n",
      "May 15, 8579 \t 8579-05-15\n",
      "January 11, 7103 \t 7103-01-11\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_dates = 3\n",
    "x_examples, y_examples = random_dates(n_dates)\n",
    "for x, y in zip(x_examples, y_examples):\n",
    "    print(x, \"\\t\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([' ',\n",
       "  ',',\n",
       "  '0',\n",
       "  '1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  'A',\n",
       "  'D',\n",
       "  'F',\n",
       "  'J',\n",
       "  'M',\n",
       "  'N',\n",
       "  'O',\n",
       "  'S',\n",
       "  'a',\n",
       "  'b',\n",
       "  'c',\n",
       "  'e',\n",
       "  'g',\n",
       "  'h',\n",
       "  'i',\n",
       "  'l',\n",
       "  'm',\n",
       "  'n',\n",
       "  'o',\n",
       "  'p',\n",
       "  'r',\n",
       "  's',\n",
       "  't',\n",
       "  'u',\n",
       "  'v',\n",
       "  'y'],\n",
       " 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_chars = [\" \", \",\"] + [str(i) for i in range(10)] + sorted(list(set(\"\".join(months))))\n",
    "input_chars, len(input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_chars = [str(i) for i in range(10)] + [\"-\"]\n",
    "output_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_to_id(strings, chars):\n",
    "    return [chars.index(string) for string in strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 23, 31, 34, 23, 28, 21, 23, 32, 0, 4, 2, 1, 0, 9, 2, 9, 7]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_to_id(x_examples[0], input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings_to_id(y_examples[0], output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strs_to_tensor(date_strs, chars):\n",
    "    ids = [strings_to_id(i, chars) for i in date_strs]\n",
    "    tensor_ragged = tf.ragged.constant(ids, ragged_rank=1)\n",
    "    return (tensor_ragged + 1).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n_dates):\n",
    "    x, y = random_dates(n_dates)\n",
    "    return strs_to_tensor(x, input_chars), strs_to_tensor(y, output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x_train, y_train = generate_dataset(10000)\n",
    "x_val, y_val = generate_dataset(2000)\n",
    "x_test, y_test = generate_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18,), dtype=int32, numpy=\n",
       "array([16, 36, 28, 38,  1,  4,  6,  2,  1,  8,  5, 12, 11,  0,  0,  0,  0,\n",
       "        0])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 8s 17ms/step - loss: 2.0800 - accuracy: 0.2642 - val_loss: 1.3738 - val_accuracy: 0.4902\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 1.3944 - accuracy: 0.4942 - val_loss: 1.2108 - val_accuracy: 0.5534\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 1.0906 - accuracy: 0.6116 - val_loss: 1.0781 - val_accuracy: 0.6226\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.9491 - accuracy: 0.6571 - val_loss: 0.7606 - val_accuracy: 0.7153\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.8906 - accuracy: 0.6796 - val_loss: 0.6257 - val_accuracy: 0.7581\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.5777 - accuracy: 0.7743 - val_loss: 0.4706 - val_accuracy: 0.8133\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.4188 - accuracy: 0.8350 - val_loss: 1.7612 - val_accuracy: 0.3645\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.9610 - accuracy: 0.6621 - val_loss: 0.3220 - val_accuracy: 0.8985\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2716 - accuracy: 0.9193 - val_loss: 0.1850 - val_accuracy: 0.9464\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.1584 - accuracy: 0.9601 - val_loss: 0.1015 - val_accuracy: 0.9797\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0842 - accuracy: 0.9846 - val_loss: 0.0578 - val_accuracy: 0.9919\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0461 - accuracy: 0.9952 - val_loss: 0.0317 - val_accuracy: 0.9978\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0265 - accuracy: 0.9983 - val_loss: 0.0203 - val_accuracy: 0.9991\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.1093 - accuracy: 0.9751 - val_loss: 0.0696 - val_accuracy: 0.9909\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0457 - accuracy: 0.9955 - val_loss: 0.0207 - val_accuracy: 0.9991\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0169 - accuracy: 0.9994 - val_loss: 0.0126 - val_accuracy: 0.9997\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 0.0087 - val_accuracy: 0.9999\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0072 - accuracy: 0.9999 - val_loss: 0.0065 - val_accuracy: 0.9999\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9999\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 32\n",
    "max_output_length = y_train.shape[-1]\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=len(input_chars) + 1, \n",
    "                           output_dim=embedding_size, \n",
    "                          input_shape=[None]),\n",
    "    keras.layers.LSTM(128)\n",
    "])\n",
    "\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(128, return_sequences=True),\n",
    "    keras.layers.Dense(len(output_chars) + 1, activation='softmax')\n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    encoder, \n",
    "    keras.layers.RepeatVector(max_output_length),\n",
    "    decoder\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, \n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=20, \n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABYeElEQVR4nO3dd3xTVf/A8c/JaNO0pXQX2kLZMsosIHvJciEqwwkoKk7ce/BTn8e99QFREXCBoig4WLKXUqBQ9pLRQks33c04vz9uWgt0N21Ke96vV2hy77k334b0m5NzzxBSShRFUZT6S+fqABRFUZSapRK9oihKPacSvaIoSj2nEr2iKEo9pxK9oihKPWdwdQAlCQgIkBEREa4OQ1EU5ZKxffv2ZCllYEn76mSij4iIIDo62tVhKIqiXDKEECdK26eabhRFUeo5legVRVHqOZXoFUVR6rk62UavKErdYbFYiIuLIy8vz9WhKIDJZCIsLAyj0VjhY1SiVxSlTHFxcXh7exMREYEQwtXhNGhSSlJSUoiLi6NFixYVPk413SiKUqa8vDz8/f1Vkq8DhBD4+/tX+tuVSvSKopRLJfm6oyr/F/Um0edZbHy67igbDye7OhRFUZQ6pd4keje9js82HGPBtpOuDkVRFCfz8vJydQiXtHqT6HU6wbDLgll3MIkCq93V4SiKotQZ9SbRAwzvEExmvpWtx1JcHYqiKDVASskTTzxBp06diIyMZOHChQCcOXOGgQMH0rVrVzp16sSGDRuw2WxMnjy5qOx7773n4uhdp151r+zfJgAPo56V+xIZ2LbEuX0URamG/1u6l32nzzn1nB2aNuKlazpWqOxPP/1ETEwMu3btIjk5mZ49ezJw4EC+/fZbRo4cyXPPPYfNZiMnJ4eYmBji4+PZs2cPAOnp6U6N+1JSbo1eCDFHCHFWCLGnlP1PCCFiHLc9QgibEMLPse+4ECLWsa/GZykzGfUMaBPAqv2JqLVwFaX+2bhxIzfddBN6vZ7g4GAGDRrEtm3b6NmzJ19++SUzZswgNjYWb29vWrZsybFjx3jwwQdZtmwZjRo1cnX4LlORGv1c4GNgfkk7pZRvAW8BCCGuAR6RUqYWKzJESllrXWGGdwhmxb5E9sSfIzLMp7aeVgE+3vkx4d7hjGk9xtWhKDWkojXv2jZw4EDWr1/Pb7/9xuTJk3n00Ue5/fbb2bVrF8uXL2fWrFl8//33zJkzx9WhukS5NXop5XogtbxyDjcB31Uromoa1j4YnYCV+xJcGUaD9MOhH/jjnz9cHYZSjw0YMICFCxdis9lISkpi/fr19OrVixMnThAcHMxdd93F1KlT2bFjB8nJydjtdm644QZeffVVduzY4erwXcZpbfRCCDMwCnig2GYJrBBCSOBTKeXsMo6/G7gboFmzZlWOw8/TjajmfqzYl8ijI9pV+TxK5eTb8knNS+Vs7llXh6LUY2PHjmXLli106dIFIQRvvvkmISEhzJs3j7feeguj0YiXlxfz588nPj6eKVOmYLdrvfBee+01F0fvOs68GHsNsOmCZpv+Usp4IUQQsFIIccDxDeEijg+B2QBRUVHVamAf3iGY//y+n1OpOYT7matzKqWCErMTAUjKSXJxJEp9lJWVBWijQt966y3eeuut8/ZPmjSJSZMmXXRcQ67FF+fM7pUTuaDZRkoZ7/h5FlgM9HLi85VqeIdgAFbtT6yNp1OAhGytqSw9P50CW4GLo1EUpTinJHohhA8wCPil2DZPIYR34X1gBFBizx1niwjwpE2QFyv3qURfW85knym6n5SravWKUpdUpHvld8AWoJ0QIk4IcacQYpoQYlqxYmOBFVLK7GLbgoGNQohdwN/Ab1LKZc4MvixXdAjmr39Sycix1NZTNmiFNXpQzTeKUteU20YvpbypAmXmonXDLL7tGNClqoFV1/AOwcxce5Q1B89yXbdQV4XRYCTk/Jvoz+aoC7KKUpfUqykQiusa1phAb3fVfFNLErITaOrZFFBNN4pS19TbRK/TCa5oH8Tag2fJt9pcHU69l5CdQFu/thh1RlWjV5Q6pt4metCab7ILbGw5qiY5q2mJ2Yk08WxCkDlItdErSh1TrxN931YBmN30qvmmhmVbssm0ZBLiGUKgR6AaNKVcsqxWq6tDqBH1OtGbjHoGtglk1f5E7HY1yVlNKexxE2IOIdAcqJpulBpx3XXX0aNHDzp27Mjs2dog+2XLltG9e3e6dOnCsGHDAG1w1ZQpU4iMjKRz5878+OOPwPmLlyxatIjJkycDMHnyZKZNm0bv3r158skn+fvvv+nTpw/dunWjb9++HDx4EACbzcbjjz9Op06d6Ny5Mx999BGrV6/muuuuKzrvypUrGTt2bC28GpVTr6YpLsnwDsEs25tAbHwGXcIbuzqceqko0XuGEGQOYsvpLS6OSKkxfzwNCbHOPWdIJIx+vdxic+bMwc/Pj9zcXHr27MmYMWO46667WL9+PS1atCA1VRuU/8orr+Dj40NsrBZnWlpaueeOi4tj8+bN6PV6zp07x4YNGzAYDKxatYpnn32WH3/8kdmzZ3P8+HFiYmIwGAykpqbi6+vLfffdR1JSEoGBgXz55Zfccccd1Xs9akC9T/RDLwtCrxOs3JeoEn0NKZ7oAz0CybJkkWPJwWxU008ozvPhhx+yePFiAE6dOsXs2bMZOHAgLVq0AMDPzw+AVatWsWDBgqLjfH19yz33uHHj0Ov1AGRkZDBp0iQOHz6MEAKLxVJ03mnTpmEwGM57vttuu42vv/6aKVOmsGXLFubPL3GiX5eq94ne19ONqOa+rNyXyOMj1SRnNSEhJwGBINAcSJA5CNC6WDY3NndxZIrTVaDmXRPWrl3LqlWr2LJlC2azmcGDB9O1a1cOHDhQ4XMIIYru5+XlnbfP09Oz6P4LL7zAkCFDWLx4McePH2fw4MFlnnfKlClcc801mEwmxo0bV/RBUJfU6zb6QsM7BHMwMZOTKTmuDqVeOpN1hkCPQIw6I4FmbWUv1U6vOFNGRga+vr6YzWYOHDjA1q1bycvLY/369fzzzz8ARU03w4cP55NPPik6trDpJjg4mP3792O324u+GZT2XKGh2iDLuXPnFm0fPnw4n376adEF28Lna9q0KU2bNuXVV19lypQpzvulnajBJHqAlWqSsxqRkJNAiFcIAEEejhq96mKpONGoUaOwWq20b9+ep59+mssvv5zAwEBmz57N9ddfT5cuXZgwYQIAzz//PGlpaXTq1IkuXbqwZs0aAF5//XWuvvpq+vbtS5MmTUp9rieffJJnnnmGbt26ndcLZ+rUqTRr1ozOnTvTpUsXvv3226J9t9xyC+Hh4bRv376GXoHqEXVxyb2oqCgZHe3clQdHvLcOP083Ftzdx6nnVeCaxdfQ1rct7wx+h8yCTPp+15fHox5nUseLp41VLj379++vswmsrnjggQfo1q0bd955Z608X0n/J0KI7VLKqJLKN4gaPWi1+m3H00jPUVPoOpOUkoTsBEI8tRq9l9ELD4OHarpRGowePXqwe/dubr31VleHUqoGlOhDsNklqw+oBORMGfkZ5NnyihK9EIJAj0DVdKM0GNu3b2f9+vW4u7u7OpRSNZhE3znUhyA1yZnTFc5aWZjoAW3QlBodqyh1RoNJ9Dqd4IoOwaw7lESeRU1y5izFR8UWUvPdKErd0mASPWjt9DlqkjOnKj5YqlCQRxBJuUnUxQv9itIQNahE37eVP55uelao5hunSchOwKAz4O/hX7Qt0BxIrjWXTEumCyNTFKVQg0r07gY9g9qpSc6cKSEngWBzMDrx71upaHSsar5RlDqhImvGzhFCnBVClLiwtxBisBAiQwgR47i9WGzfKCHEQSHEESHE084MvKqGdwgmKTOfXXHprg6lXkjI1hJ9cYEeanSs4lrFZ6q80PHjx+nUqVMtRuN6FanRzwVGlVNmg5Syq+P2MoAQQg98AowGOgA3CSE6VCdYZxjSTpvkbJUaJesUxfvQFyo+342iKK5XkcXB1wshIqpw7l7AEcci4QghFgBjgH1VOJfTNDa70TNCm+TsiZGXuTKUS55d2knMSbwo0Qd4BACqRl8fvfH3GxxIrfhEYhVxmd9lPNXrqTLLPP3004SHh3P//fcDMGPGDAwGA2vWrCEtLQ2LxcKrr77KmDFjKvXceXl53HvvvURHR2MwGHj33XcZMmQIe/fuZcqUKRQUFGC32/nxxx9p2rQp48ePJy4uDpvNxgsvvFA07UJd56w2+j5CiF1CiD+EEB0d20KBU8XKxDm2lUgIcbcQIloIEZ2UVLM1weEdQjiUmMWJlOwafZ76LiU3BavdShPP8+cNMRvNeBu9VRu94jQTJkzg+++/L3r8/fffM2nSJBYvXsyOHTtYs2YNjz32WKV7en3yyScIIYiNjeW7775j0qRJ5OXlMWvWLKZPn05MTAzR0dGEhYWxbNkymjZtyq5du9izZw+jRpXX0FF3OGM+zR1AcylllhDiSuBnoE1lTyKlnA3MBm2uGyfEVaoRHYJ55dd9rNyXyNQBLWvyqeq1krpWFgo0B6qmm3qovJp3TenWrRtnz57l9OnTJCUl4evrS0hICI888gjr169Hp9MRHx9PYmIiISEXvx9Ls3HjRh588EEALrvsMpo3b86hQ4fo06cP//nPf4iLi+P666+nTZs2REZG8thjj/HUU09x9dVXM2DAgJr6dZ2u2jV6KeU5KWWW4/7vgFEIEQDEA+HFioY5trlcuJ+Zy0K8VTfLaippVGwhtaSg4mzjxo1j0aJFLFy4kAkTJvDNN9+QlJTE9u3biYmJITg4+KJ55qvq5ptvZsmSJXh4eHDllVeyevVq2rZty44dO4iMjOT555/n5Zdfdspz1YZqJ3ohRIhwzOgvhOjlOGcKsA1oI4RoIYRwAyYCS6r7fM4yvEMw0cdTSc1Wk5xVVUmjYgsFeajRsYpzTZgwgQULFrBo0SLGjRtHRkYGQUFBGI1G1qxZw4kTJyp9zgEDBvDNN98AcOjQIU6ePEm7du04duwYLVu25KGHHmLMmDHs3r2b06dPYzabufXWW3niiSfYsWOHs3/FGlNu040Q4jtgMBAghIgDXgKMAFLKWcCNwL1CCCuQC0yUWkOZVQjxALAc0ANzpJR7a+S3qILhHYL5aPURVh84y409wlwdziUpITsBk96Ej7vPRfsK57uRUp63so+iVFXHjh3JzMwkNDSUJk2acMstt3DNNdcQGRlJVFQUl11W+c4V9913H/feey+RkZEYDAbmzp2Lu7s733//PV999RVGo5GQkBCeffZZtm3bxhNPPIFOp8NoNDJz5swa+C1rRoOZj/5CUkr6vLaaLuE+fHpbiVM4K+V4bO1jHEo7xNKxSy/a983+b3j979dZP2E9vqby1+xU6i41H33do+ajryAhBFd0CGL9oWQ1yVkVJeQkEOwZXOK+wr70qp1eUVyvwSZ60LpZ5lpsbDqS7OpQLkkJ2Qklts+DGh2ruF5sbCxdu3Y979a7d29Xh+USdW+58lp0eUs/vNwNrNyXyLD2JddMlZJZ7VaSc5NL7HEDanSs4nqRkZHExMS4Oow6oUHX6N0Nega1DWTV/rNqkrNKSspJwi7tpSZ6NTpWUeqOBp3oQet9k5yVT4ya5KxSzmSfAUruQw/gpnfD191XdbFUlDqgwSf6wknO1BKDlVPYh/7C6Q+KU0sKKkrd0OATvY/ZSO8WfirRV1JZo2ILBZrVIuGKUhfUm0QvpWTWrlnsT9lf6WOHdwjmyNks/klWk5xVVEJ2At5GbzyNnqWWUaNjFVcpaz76hqjeJPpzBef48fCP3LvqXk5lnir/gGKGd9B63Kzcl1ATodVLCdml96EvFGgOJDkvGZtdjVNQGiar1erqEIB61L3Sx92HT6/4lNuX3c60ldOYP3r+eeuYliXM10z7Jo1YuS+Ruwe2quFI64eSFhy5UJBHEHZpJzUvlUBzYC1FptSkhP/+l/z9zp2P3r39ZYQ8+2yZZZw5H31WVhZjxowp8bj58+fz9ttvI4Sgc+fOfPXVVyQmJjJt2jSOHTsGwMyZM2natClXX301e/ZoC++9/fbbZGVlMWPGDAYPHkzXrl3ZuHEjN910E23btuXVV1+loKAAf39/vvnmG4KDg8nKyuLBBx8kOjoaIQQvvfQSGRkZ7N69m/fffx+Azz77jH379vHee+9V9eUF6lGNHqBl45Z8PPRjzuac5YE/HyDHklPhY4d3CGb7iTRSsvJrMML6o6QFRy5UmNzVBVmlupw5H73JZCrxuL179/Lqq6+yevVqdu3axQcffADAQw89xKBBg9i1axc7duygY8eO5TwDFBQUEB0dzWOPPUb//v3ZunUrO3fuZOLEibz55psAvPLKK/j4+BAbG8vu3bsZOnQo48ePZ+nSpVgsFgC+/PJL7rjjjqq8ZOepNzX6Ql2DuvLWoLeYvmY6j657lI+GfoRRZyz3uBEdgvnwz8P8uf8s43uGl1u+Icu35ZOal1rqqNhChWvJJuUkQcW+XCl1XHk175rizPnopZQ8++yzFx23evVqxo0bR0CANgbEz88PgNWrVzN//nwA9Ho9Pj4+pKWllfkcxVeeiouLY8KECZw5c4aCggJatGgBwKpVq1iwYEFROV9fbU6ooUOH8uuvv9K+fXssFguRkZGVfLUuVq9q9IUGhw/mxctfZFP8JmZsnlGhT/mOTRvRMsCTWeuOkm9VbcplSczWeihVuEavBk0pTuCs+eidMY+9wWDAbrcXPb7weE/PfzspPPjggzzwwAPExsby6aeflvtcU6dOZe7cuXz55ZdMmTKlUnGVpl4meoAb2t7A/V3vZ8nRJby/4/1yywsheOnajhxLzmbW2mM1H+AlrKyVpYrzM/mhEzqV6BWncNZ89KUdN3ToUH744QdSUlIASE1NBWDYsGFFUxLbbDYyMjIIDg7m7NmzpKSkkJ+fz6+//lrm84WGaquozps3r2j78OHD+eSTT4oeF35L6N27N6dOneLbb7/lpptuqujLU6Z6m+gB7ul8D+PbjmfOnjl8ve/rcssPahvI1Z2b8MnaI6qrZRkq0ocewKAz4G/yV/PdKE5R0nz00dHRREZGMn/+/ArPR1/acR07duS5555j0KBBdOnShUcffRSADz74gDVr1hAZGUmPHj3Yt28fRqORF198kV69ejF8+PAyn3vGjBmMGzeOHj16FDULATz//POkpaXRqVMnunTpwpo1a4r2jR8/nn79+hU151SblLLO3Xr06CGdxWqzyodXPywj50bKP479UW75xIxc2enFZfKWz7ZKu93utDjqk1kxs2SnuZ1kriW33LLjl46X01ZOq4WolJqyb98+V4fQ4Fx11VVy1apVpe4v6f8EiJal5NR6XaMH0Ov0vD7wdboFdePZjc/y15m/yiwf1MjEE6PasfFIMkt2na6lKC8tCTkJ+Lr7YjKYyi2rBk0pSsWlp6fTtm1bPDw8GDZsmNPOW+8TPYC73p0Ph35I80bNmb5mOgdSy+4HfEvv5nQO8+GVX/eTkWuppSgvHRXpQ18o0Byomm4Ul7gU56Nv3Lgxhw4d4ocffnDqeRtEogdtQNXMK2biZfTi3lX3EpcZV2pZvU7w37GRpGbn89Zy5w4OqQ8qm+hT81Kx2NQH5qVM1sElR8tTOB998dtff5X9jf5SUJX/i3ITvRBijhDirBBiTyn7bxFC7BZCxAohNgshuhTbd9yxPUYIUbOLwFZAiGcInw7/lAJbAdNWTSM1L7XUsp1CfZjUN4Jv/jrJzpNl95ltaBKzyx8sVSjIQ1uAJDlXreJ1qTKZTKSkpFySyb6+kVKSkpKCyVR+s2lxFRkwNRf4GJhfyv5/gEFSyjQhxGhgNlD8+9EQKWWd+Stv1bgVHw/7mLtW3MX9q+7ni5FfYDaaSyz72Ih2/BGbwHOL97DkgX4Y9A3mC1Cpsi3ZZFoyK1WjB210bBOv0qc0VuqusLAw4uLiSEpSTXB1gclkIiwsrFLHlJvopZTrhRARZezfXOzhVqByEbhAt6BuvDnwTR5Z+wiPrXuMD4d+WOLoWS93Ay9d04F7v9nB3M3HmTqgpQuirVuK+tCXMyq2UNGSguqC7CXLaDQWjeZULk3OrqLeCfxR7LEEVgghtgsh7i7rQCHE3UKIaCFEdG3UHIY2G8rzlz/PxviNZY6eHdUphCHtAnl35SFOp+fWeFx1XUUHSxVSi4Qrius5LdELIYagJfqnim3uL6XsDowG7hdCDCzteCnlbClllJQyKjCwdmY6HNd2HPd1uY8lR5fwwY4PSiwjhODlMZ2wS8nLS/fVSlx1WWUTva/JF4POoHreKIoLOSXRCyE6A58DY6SUKYXbpZTxjp9ngcVAL2c8nzNN6zKNG9veyBd7vuCb/d+UWCbcz8xDw9qwbG8Cf+5v2CtRJeQkIBAVnnZYJ3QEegSqGr2iuFC1E70QohnwE3CblPJQse2eQgjvwvvACKDEnjuuJITg+d7PMzR8KG/8/QZLjy4tsdzU/i1pE+TFi7/sJaegbiwm4AoJ2QkEegRWaEbQQoFmlegVxZUq0r3yO2AL0E4IESeEuFMIMU0IMc1R5EW0SWj/d0E3ymBgoxBiF/A38JuUclkN/A7VptfpeWPgG0SFRPHsxmdLnBfHzaDjP2MjiU/P5YM/D7sgyrrhTPaZCjfbFFKjYxXFtSrS66bM6dOklFOBqSVsPwZ0ufiIuslkMDHzipk8tf4p3tj2Bsm5yUzvPh0hRFGZXi38GB8Vxhcb/mFst1AuC2nkwohdIzE7kTa+bSp1TKA5kL8SLv2BKopyqVIdw4tx17vzzqB3GNd2HF/s+YIXNr2AxX7+iM6nR7fH22Tg+cV7sNsb1gASKSUJ2Qk08axcf/ggcxCZBZnkWlWvJUVxBZXoL6DX6Xnh8he4r8t9/HL0Fx5e8/B5CcrP041nr2xP9Ik0vo+u3CLkl7qM/AzybHmVbrop7GKZnFNnxs0pSoOiEn0JhBDc2/VeXrj8BTbGb2Tqiqmk56UX7b+xRxi9Wvjx2h8HGtQasxWdh/5Cau1YRXEtlejLML7deN4Z9A4HUg5w+7LbOZN1BtA+CP47thM5BVb++3vDmfSssqNiCxXOd6MuyCqKa6hEX44rml/BrOGzSMpJ4tY/buVwmtbjpnWQN3cPbMmPO+LYcjSlnLPUD5UdLFVIrR2rKK6lEn0F9AzpydxRc5FSMmnZJHYk7gDggSFtCPfz4LmfYxvEguIJ2Qna8oAe/pU6rpFbI9z17mp0rKK4iEr0FdTOrx1fXfkV/iZ/7l55N2tOrsHDTc8rYzpxLCmbz9bX/wXFE3ISCDYHoxOVe9sIIdToWEVxIZXoKyHUK5R5o+fR1rctD699mJ8O/8TgdkFcFdmEj1Yf4URK/V5QPCFbS/RVEWQOUjV6RXERlegryc/kx+cjPqdPkz68tPklZu+ezQtXt8eo1/H8z3vq9eIMlVlZ6kJB5iBVo1cUF1GJvgrMRjMfDfuIq1tezUc7P2LOgfd4dHgrNhxOZunuM64Or0bYpZ3EnIqvLHWhwvlu6vMHoaLUVSrRV5FRZ+Q//f/D5I6T+e7Ad+yxziQyzMz/LdlLanaBq8NzupTcFKx2a9Vr9B5B5FpzybbU7+YtRamLVKKvBp3Q8VjUYzwe9TgrT6zAq/k8zhVkMmPJXleH5nRV7UNfSA2aUhTXUYneCSZ1nMR/+/+XA2m7iIxcw5Jdp1mxN8HVYTlV4ajYqq77qpYUVBTXUYneSa5pdQ03tb+JY3kbad3EwvM/7yEjx1L+gZeIatfo1ZKCiuIyKtE70W3tb0MA3SNjScku4JXf6s/SgwnZCZj0Jnzcfap0fGHTjepiqSi1TyV6J2ri1YTRLUaz9sxSpgwIZNH2ONYcrB812MKulcXn568MT6MnnkZP1XSjKC6gEr2TTe40mVxrLn5NttM6yItnf4olM+/Sb8JJyEkg2LNqg6UKqdGxiuIaKtE7WVvftvQP7c/Cg9/xn7HtSDyXVy9muEzITqhy+3whNTpWUVyjQoleCDFHCHFWCFHi4t5C86EQ4ogQYrcQonuxfZOEEIcdt0nOCrwuu6PTHaTmpXKiYD1TB7Tku79PsunIpbvohtVuJTk3ucp96AupRcIVxTUqWqOfC4wqY/9ooI3jdjcwE0AI4Qe8BPQGegEvCSF8qxrspSIqOIrIgEjm7p3L9GGtaBHgyVM/7iY73+rq0KokKScJu7RXO9EXLhKuRscqSu0qd3FwACnleiFERBlFxgDzpfYXvFUI0VgI0QQYDKyUUqYCCCFWon1gfFetqOs4IQRTOk3h0bWPsunMWt68MYrxn27hreUHmXFtR1eHV2lnsrVpHaqd6M1BFNgLyMjPoLGpsRMiuzRImw2Zl4c9Lw97bi4yNxe74yazMrCfS8WelY79XDoU5CFtVrBZHT9tYLcibbbz79u1x9JeuN2GtNsR5sbomndB39gfnZcXOi9vdF6e6L28HI+90Ht5IczmCl9Yl1Iic3OxZWVhz8rGnp2FPStLe5yp3bdnZWFLOIJMT9RikxIp7WC3Q9FPCdJebLt07HP8lPZ/KwHS8Y8sCqJ4ROeVOX+XqysR1Xt+vacHTeb/6aRY/lWhRF8BoUDxBVTjHNtK234RIcTdaN8GaNasmZPCcp2h4UNp5t2ML/d8ybdXDWdSnwjmbj7OlZFN6NXCz9XhVUp1+9AXKj469lJL9NJux5aRgS0lBWtqKrbUNKypKdhS07ClpmI9G4/t7BlsmZlaUs8vQOZZsBdYkVa7c4MREgQIx30hcDxw5Evb3+WfQ6dD5+npSPyejg8ELxBoyTyrWDLPytISc3lh6SVC54gHWRSTtrPYDwGI8zcUfeact/2C85+3rYRyle4QVrUeZDV5Wr05x3lxFOOsRF9tUsrZwGyAqKgoV38sV5tep2dSx0m8svUVtiVs48lR3fnzQCJPLtrFH9MH4uGmd3WIFVbVtWIvVHx0bFvfttWOy1mklFji4sjduZOCEyexpaViLUzghck8Pb3UZKdzs2Nwt6F3t2N0k+iMEmGS6PxB5+6GMLmjM7kjPDzQeZjReXoizF7oPL3RefkgvHzQefuia+SHMHmC0R1hcAODEfRGhNEdHI+F3g30RtAZtJveCDoj6Bzvp9M7kNvmYY9ZjD07G5s5HHvzEdib9MVmdytK4raszPMSuj07q+h31Hl749a8GTrPwm8Bxb4ReHqh8zCiT41Fd/JPdAl/ozPa0Lfqi+hxC7QYCHo3R3y6f+MU+n+3KbXOWYk+Hggv9jjMsS0erfmm+Pa1TnrOOm9M6zF8EvMJc/bOYdYVvXjj+s7c/PlfvLvyIM9d1cHV4VVYQnYC3kZvvNy8qnWeujI61p6fT97efeTu3EluzE5ydsZgS/73YrnO2wtDIzN6TwPuJhv65lb0ze0YRAZ6dxsGdzt6k8QQFIK+aRtEcFvwbw0BbaBRKLg3AlMjMJgurIbWvNAeiNAe6K98Hf3+JRh3fg3HZ8Opz6H1cOh2K7S9TvvgqAwpIS4aYr6BbT9Bfgb4NIOrHoMuE8GvZY38OopzOCvRLwEeEEIsQLvwmiGlPCOEWA78t9gF2BHAM056zjrPXe/Ore1v5cOdH3Iw9SB9W7fj5t7N+GLjP4yObEL3ZpfGdemE7Or3oQfXjY61nD1LbkwMuTtjyN25k7y9e5EWbWyDMTwUr07N8AgMxcN0CnfrYYQ8/e/B7j4Q0Br8uzp+ttESul9LMHrU6u9RKW5mLQF3mQgpR7UEHfMtfH8bmAO07d1ug6DLyj7PuTOwe4F2bPIhMHhAhzHQ9WaIGKBq6JeICiV6IcR3aDXzACFEHFpPGiOAlHIW8DtwJXAEyAGmOPalCiFeAbY5TvVy4YXZhmJ8u/F8FvsZc/fO5bUBr/HM6MtYe+AsTy7aza8P9sdkrPtNONVZcKQ4d707Pu4+NVqjl1Yr+YcPk7NzZ1Fit8TFASDc3DC1b4PfqCg8fLPx0B/GkOt4axpM0DQKmt6lJfLChO4ZWPu1cmfzbwXDXoQhz8GRP2HnfPhrFmz5GMJ6arX8jtdr30IALHlw8Hftw+Hoaq3hv1kfuPZjLckXllMuGRXtdXNTOfslcH8p++YAcyofWv3g4+7DjW1v5Nv93/Jgtwdp6tWU/14fyeQvt/HR6sM8MbKcGlUdkJiTSMcA5/QWCvQIdPo0CNa0NLJWr+bcihXkbovGnqNd0NIHBGDu0ArfAS0xeyfjbtmDLneldpCuMYRfDs1uh+Z9oUnXyjdnXGp0emg7QrtlJ8OuBbDzK1g6HZY9Ax3Hat9SYhdBXjo0CoMBj0GXm7QPC+WSVWcuxtZnt3e4ne/2f8dX+77iqV5PMbhdEDf2CGPWumOM6tiEyLCqTRRWG/Jt+aTmpVa7x00hZ42OtSYnk7lqFZkrVpD9199gs2EMbYrPsN54BEk8POIxntuJKNjt6PEWBq0HQLPLoVlfCLysYTc7eAZA3wegz/0Qv11L+LE/gt0C7a/VmmZaDPz3Iq9ySVOJvhaEeIZwZcsr+fHwj9zT+R4amxrzwlUdWH8oiScW7WLJA/1xM9TNpJOYnQhUv8dNoUCPQI6mH63SsZbERDJXrCRz+XJytm8HKXGLiMB/6lS8+3XFtPUxROo3kA2YL4PIG7TaerPLofGl32W3RggBYVHabdQbIG3g5unqqBQnU4m+lkzqOIklR5ew8OBC7ulyDz5mI/8ZG8ld86P539ojPHxF3eluWFxRH3onJfogcxDJucnYpR2dKP/DrSAunswVK8hcsYLcmBgA3Nu0IeC++/AeOQL3Nm0Q5+Jh7tVac8QNX0CroWC+tMYq1AlGk6sjUGqISvS1pK1vWwaEDuDbA98yqeMkTAYTwzsEc22Xpny8+ggjO4bQvkndu8jlrD70hQLNgdikjdS8VAI8AkosU3D8OOccNfe8vdqyjO4d2hP48MN4jxiBe8sW/xZOP6kl+dw0uP1nrWaqKMp56mZ7QT01pdMUUvNS+eXIL0XbZlzbER8PI08u2o3V5uQRlE5wJkub/iDYXP3ulaDNdwMl96U/t2w5x8Zcx9FRo0l6913Q6wl64nFarVxBy59+ImDaPecn+bTj8OVV2oVDleQVpVQq0dei4pOd2ew2APw83Xh5TCdi4zOYveGYiyO8WEJOAr7uvpgMzvlaX9rasdJq5cyLLyILCgh+5mlar/6TFt8vxP/OO3ELD7/4RKnHtCSffw5uXwKhPZwSn6LUR6rpphYJIbij0x08svYRVp1cxciIkQBc1bkJv+4O4f2VhwlpZMLspscuwS61CZuK//x3e+G2Yo+BQW0Dae7vvItpzupDX6j4fDfF5cbGYj93jsD/m0Gj0aPLPknKUa25xpoHk5ZCk85Oi09R6iOV6GvZkPAhNG/UnDl75jCi+YiiGQRfHtOJv/9Zz6Pf76rW+XtG+PLDtL7OCBXQEn2Yd5jTzufv4Y9AXFSjz960GYTAfPnlZZ8g+bCW5O1WmPwrBF96s4EqSm1Tib6WFU529vKWl9mWsI1eTXoBEOjtzurHBhOXnoNOaLP56YRAJ7RvAoX3dY4PBp3u38eFZRduO8Vbyw+y93QGHZs6p29+YnYiPUN6OuVcAEadET+T30Vt9NmbNmGKjMTgW8a0EGcPwLxrAKkl+aD2TotLUeoz1UbvAte2uhY/kx9z9pw/YNjHbKRjUx/aN2nEZSGNaBvsTesgb1oFetEiwJPm/p6E+5kJ9zMT2tiDJj4eBDcyEeRtIsDLnVt7N8fDqGfe5uNOiTPbkk2mJdOpTTdw8aAp27lz5O7ejWe/Mr6JJO6DeVdr/b4n/6aSvKJUgkr0LlA42dmm05s4mHrQaef1MRsZ2z2Un2NOk5pdUO3zOWse+gsFms+fBiF761aw2fDq16+UQPZoSV5n0JJ8YDunxqMo9Z1K9C4yvt14zAYzX+790qnnndw3ggKrnQXbTlb7XJUaLGWzwInNcGZXuav8BHqcv3Zs9qbN6Dw98ejS5eLCZ3ZpSd5g0pJ8QJtK/Q6Koqg2epcpnOzsm/3f8FC3h2jq1dQp520b7E3fVv58veUEdw9oiUFf9c/ychN91lk4vBIOL4eja7SujqDNU37ZVdqtWR/Qn/82CzIHkZqXisVuwSAMZG/ciPnyyxFG4/nnP70T5l8H7t5a7xq/FiiKUnmqRu9Ct3W4DYFg/r75Tj3v5L4RnM7IY+W+xEodl//PP9jOnSt6nJCTgEAUdYnEbteS79rXYfYQeLsN/HIfnPwLOl4HE77WprIN7gjRc7Sa+Ntt4Of74MBvYMkFtKYbiSQlNwXLiRNY4uMvbp+P2w7zHFPiTv5NJXlFqQZVo3ehwsnOfjr8E9M6T3PaOqrD2gcT5uvBl5uPMzqySZllrWlpnPv1NzIWLyZv3z68R44k7IP3Aa1GH+jhj/HAH1qt/fBKyEoEhDZAachz0GYENOly/pzt3W+D/Cw4+qeW4A/8qs1tbjRDq6EENdXa2JNyknDbtBvg/Pb5U9vg6+u1+Wom/QqNSxgwpShKhalE72KTO05mydElLDi4gGldpjnlnHqd4PY+zfnv7wfYd/ocHZqeP4eOtFrJ2rCBjMU/k7lmDVgsmDp0wKNHD7LWrsV+ag+6uPWcObKMkPxz2qpE7j7Qeii0GQmtrwCvwLKDcPfSFqnoMEZrvz++UUv4B34j8NhyCG3C2d+n03iZB8bQJrg1b64dd3IrfH2jdv5Jv4JPiWvJK4pSCSrRu1gb3zYMDBvIt/u/ZXLHyU6bamB8VDjvrjzEvM3HeeNGbeRo/uHDpC/+mYwlS7AlJ6P388Pv5pvxuX4sptYtyZnzFCe255P10jAaNcsjsXlz2vhEwPDPtal+9cayn7Q0eiO0GqLdRr9F0PE1sOFhkrLTCIuNp1FELnw6CFoOgr8/h0ZNtCTfqOxvI4qiVIxqo68DpnScQlp+2nmTnVVXY7MbY7uFsfLvw8R/+RX/jBvPsWuuJXX+fDy6diHsk49ps24twc88jSnQDeaMxOPUF+jNes5ZeiMfiiHB6E5Iy2HQYkDVk/yFdDr8WgxBL/QU+IzEbtXhOeI67fybPgCfMK1NXiV5RXGaiq4ZOwr4ANADn0spX79g/3vAEMdDMxAkpWzs2GcDYh37Tkopr3VC3PVKj+AedA7ozNy9c7mh7Q0YdNX7oiVtNrI3b+b2ld9z07o1nFtiw71dO4KfeZpGV1+Nwd//38Kxi2Dpw6DTISbMw1sXQ8aSpaQLD/JseU7vQw+gEzoCPALw2HoQ9Ho8p/wHvL0hOwVMPhf10lEUpXrK/YsSQuiBT4DhQBywTQixREq5r7CMlPKRYuUfBLoVO0WulLKr0yKuh4QQTOk0hUfWPsLy48u5quVVlT6HlJKCI0fIWLKUjF9+wXr2LHofH/7qPIRl4VF89dqtGA3FloXLz4I/ntQukoZfDjd8Bo2b0ehcMOkLFpKwdhngvHnoLxRkDiIg9ggeXbqg9/bWNnr6l32QoihVUpGqUy/giJTyGIAQYgEwBthXSvmbgJecE17DMSR8CO182zFj8wy83bwZGDaw3GPseXnk/PUXWevWkbVuPZb4eNDr8RowAJ/nnsNryGCOHUpl69fb+fPAWUZ1cjSHnNkFi+7QZoEc+CQMeqqoFm3u2RN948ZkrVwNvaGJZ800oYTbfAg6lYnnGOdNwKYoSskqkuhDgVPFHscBvUsqKIRoDrQAVhfbbBJCRANW4HUp5c+lHHs3cDdAs2YNb31PvU7Pp8M/5d5V9zJ99XRe6f8KV7e8+qJylvh4MtetI2vdOnK2/oXMz0d4eODZpw/+d92F97ChGAL/7RFzRfsgQht7MHfzcUZ1DIGtM2HVS2AO0AYhtRhw3vmFwYDXFcMo+G0phh6yxmr07f+xoJOUPu2BoihO4+zG0InAIimlrdi25lLKeCFES2C1ECJWSnnR6tBSytnAbICoqKiyx9DXU/4e/swZOYfpa6bzzIZnyMjP4ObW48nZsZOs9VpyLziivXTGZs1oPH48XgMHYu7VE527e4nnNOh13NanObP/+JusL9/E6+RqaHelNrCplKaSRiNHkrHoR7qdMOLvUTPNKc0PpJNlAtGhbq6Vqyj1SUUSfTxQfMRKmGNbSSYC9xffIKWMd/w8JoRYi9Z+f1GiVzRebl582PUV5n0xnfxn/kPsyTcx5hSA0Yg5qgeNb7wRr4GDcGsRUTSXfXluDfqH692fwf1UNlz5NvScev4Apwt49u5NgYeBQYfdKrSAd2VJKfHffYroCEGT/FTC3MxOfw5FUf5VkUS/DWgjhGiBluAnAjdfWEgIcRngC2wpts0XyJFS5gshAoB+wJvOCLy+kQUFpH7zLed+/5282FiGALk+Jta3ycc8cCC33f4WRu9KLh5us8Ca/+K18T1yTM24Medp5nWaRONyPiCEmxsHOzWm8540ZEEBws2t6r9YCQqOHsWYco7dvXR0y01y6sImiqJcrNzqmpTSCjwALAf2A99LKfcKIV4WQhTvKjkRWCDleVMXtgeihRC7gDVobfSlXcRtsHJ27OTY9ddz9o03QCcInP4QLX76ka5btmN58i7e89rMsztewWKzVPykacdhzijY+C50v43UW1awyxLOwm2nyj0U4K92AlOujey//q7aL1WG7E2bANjVQpS4SLiiKM5VoTZ6KeXvwO8XbHvxgsczSjhuMxBZjfjqNVtmJmfffZf07xZgaNqEsFkz8R48+Lwyj/R4BF93X97Z/g7nCs7x3uD3MBvLaerY86PWNx4BN34Jna7nMqB3Cz/mbznB1AEt0etKr9XbpZ0NoeeYbDKSuWI5XgP6V/dXPU/Wxk3oI5qR7HP6oiUFFUVxPjUy1gWklJxbvoJjV15F+sLv8Zs0iVZLl16U5AtN7jSZl/u+zNYzW7lrxV2k56WXfOKCbPjlfq3rZOBlMG0DdLq+aPeUfhHEp+eyan/Zs1qm5KaQq7OR2bMdmav+RFqtVfxNL2bPzydn2zYa9R+AUWe8aJFwRVGcTw1BrGWWM2dIeOVVslavxr1De8JmzsSjU0dIOgRrZkL6SW3ha7tNa2O3W8FuZazdSiNh4En7biZ9O4BPz9kJsf67H5sVbPnacQMeh8FPXzRtwRXtg2nqY2LupuOM7Fh6t8nCeegZ3Afbhs/IiY7Gs7xFuysod8cOZF4env36EZS6UTXdKEotUIm+lkibjbRvvyPpvfeQUhL05JP43X4bInEXLLwV9v+qraIU1F5L0DoDGNxA56nd1xsZptMzS+bwYN4Rbvdz51PvPrRw89H2F97ajoTmJQ9C0rpaRvDGsgMcTMikXYh3ieUScrRE7zt4KOLtrzm3fLnTEn32pk1gNOLZqxdB64NU042i1AKV6GtB3sGDnHnhRfJ278ZzwABCXnwBt4Ij8M1Y+Ge9Nr/LwMeh9zTwDCjzXD2BOSn7uHfVvUzKP8TMgTPp6N+xwrFM7BnO+6sOMXfzcV67vuTLJ0UrS/k3J3vgQDJXrSLk+ecRen2J5Ssja+MmzN26ofP0JNAjkENph6p9TkVRyqba6GuQPTeXs++8wz/X34AlLo6mb71J+PTRuP1+K3x1ndZcM/wVeGQvDH2+3CRfqIN/B+aPno+HwYM7lt3B32cq3jPG19ON67qGsnhnHBk5JffiSchOwKQ30di9Md4jhmNLSiZ3584KP0dprElJ5B84gKdjNGyQOYikXFWjV5SaphJ9DcnatIlj144h5bPP8RlzLa1evx2f4zMQiyZDfiZc8yE8vBv6PaStiVpJzRs1Z/7o+TT1asq0VdNYdWJVhY+d1DeCPIudhdElLyCekJ1AiGcIQgi8Bg1GuLlxbsWKSsd4oewt2hCLwkQfaA4k25JNtiW72udWFKV0KtE7mTU1ldNPPcWpO6cidIJmT15HU//F6Fc/CW6eMG4uPLANekwCQ8nTFlRUsGcwc0fNpb1/ex5b9xg/HvqxQsd1aNqIXo6uljb7xbNNJOQkEOwZDIDeyxPPAQPIXLESabdXK96sjRvR+/pi6tAegEAPbU4e1U6vKDVLJXonkRYL6YsWcezKq8j47XcCRkfSYsABPE/+D/xbwW2L4e510HEs6Krf1l3Ix92Hz4Z/Rp+mfZixZQbz9s6r0HGT+0YQl5bLnyV0tUzITjhvHvpGI4ZjTUggb/fuKscp7XayN2/Bs29fhE572wWZgwBIyk3Cbpe8sewAP26Pq/JzKIpSMnUxtprsubmk//gTqXPmYDl9Go8IX5r0T8Hdazm0vhr6PwJhUTUag9lo5qMhH/HUhqd4O/ptPAwejG83vsxjRnQIpomPiXlbjjOiWFdLq91Kcm7yebNWeg0ZAkYj51asxKNr1yrFmH/oELbk5KJmG9CabgASsxP5v6V7mbflBAFeblzbtSlGvaqDKIqzqL+mKrKdO0fyrFkcGXYFia++isFsI2xwJs37HMS9/3Vw/98w8ZsaT/KFjHojbwx4g4FhA3l166v8euzXMssb9Dpuvbw5m46kcCgxs2h7Uk4Sdmk/L9HrGzXCs28fMpcv5/wZLiqucNoDz37/dv0M8tBq9D/H7mfelhP0buFHclYBaw6ovvWK4kwq0VeS5exZzr79NkeGDCXp/Q8wtQqj+Q1eRETtxHvIEMT0GLjufxDYrtZjM+qNvDPoHaJConh+4/OsPrm6zPI39WqGm0HH3M3Hi7adyT4DXLyyVKMRI7DEx5O3t2pTFWVt3Ih7mzYYg4OLtnkaPTEKExuOHePGHmF8PbU3AV7u/KCabxTFqVSir6CCkyc589IMjl4xnJQ5X+I1oC8tHu1Ps1bLMftlwcRvYcJX0Di8/JPVIJPBxEdDP6KDfwceX/c4W05vKbWsn6cbY7o0ZfGO+KKulkV96C9YK9Zr6FDQ68msQu8be24uudHbz2u2Afg9NoH8fC9C/Ap4/fpIjHod13cPZc2BsyRn5Vf6eRRFKZlK9OXIO3CA+Mce5+io0WT89BM+111Hq4+fIDR8JabTP0Dve+CBv+Gyyq/zWlM8jZ7MvGImET4RTF8znZizMaWWndQ3glyLje+jtVktC0fFXlijN/j64tm7N+eWL6t0801OdDTSYjkv0W88nMzDC3fiqfcjPMiCwdEmP65HGFa75OedpS15oChKZalEX4qc7ds5ec89/HPdWLLWrMFvymRa/fINTTocwW39dDD7wdQ/YfQbVeoHX9N83H2YPXw2QeYg7lt1HwdSD5RYrlOoDz0jfJm/9Tg2uyQhOwEvoxdebl4XlfUeMQLLiZPkH6rcaNbsjRsRbm6Ye2rXK3bHpXPPV9G0CvSiX0RLUooNmmoT7E2X8Mb8EB1X5esBiqKcTyX6YqSUZK1bx/FbbuXELbeStzuWwOkP0frPlQQPaoxxwWg4sgqu+D+4ey2E9XB1yGUK8Ajgs+Gf4enmyT0r7+FYxrESy03u24JTqbmsPnC2aLBUSbyvGAY6HZnLK9d8k7VpE+aoKHQmE8eSspj85TZ8Pd2Yd0cvQr2DScpNOi+pj+sRxsHETGLjMyr1PIqilEwlesCel0f6okX8M+Y6Tt0zDcuZ0wQ/9xytV/9JwPUD0S8aB78/rvWguW8L9H/4opkh66omXk34fMTnCAR3rbiL+KyLm0RGdAwmpJGJeZuPk5D972CpCxkCAjBHRXFuxfIKP78lIYGCI0fx7NePhIw8bvvibwTw1Z29CW5kIsgcRL4tn3MF54qOuaZLU9wNOn6IVhdlFcUZGnSit5w5w9l33+PI4CGcef4FEIImr71G6+XL8Zt4A7pNb8KnAyHtH7j+M23Qk19LV4ddac0bNefT4Z+SZ81j6vKpF00NbHQsIL7xSDLxWWdo4tmk1HN5jxhBwZGj5B+t2LK/hd0q7T16cfucv8jItTDvjl60CPAEig2aKjY61sfDyMiOISzZdZo8i+3ikyqKUikNLtFLKcnZsYO4hx/hyBXDSfn8c8w9o2g2fx4tfl5M47HXIU5tgv/10Zbh6zwBHoiGzuPLXFC7rmvn146ZV8wkNS+Vu1fcTVpe2nn7J/YMx81o41xBOrk53qW2j3sPHw5Q4d432Zs2oQ8I4J5N6RxPzmH27T3oFOpTtL9w0NSFC5Dc2COMjFxLuYukKIpSvgaT6O0FBaQv/pnjN9zIiZtvIXvzZvwmT6LVihWEffQRnr16IXJSYfE0mD9GS+q3L9H6xJv9XB2+U3QO7MzHwz4mLiuOaaumkVWQVbTP38udZ67RavKL/s7imo83smzPGewXzIVjDA7Co3t3zlWgnV7abGRt2syukHbExGXw4U1d6dvq/Bk6CwdNXTjfTb/WATTxManmG0VxggoleiHEKCHEQSHEESHE0yXsnyyESBJCxDhuU4vtmySEOOy4TXJm8BVhSTxL0ocfcmTIUM488wz2gnxCZsygzdo1BD/xBG5hoVrB9FMwqz/E/qCt0HTvZmg5qLbDrXE9Q3ry7uB3OZR6iPv/vJ9ca27Rvo7hWlKf2qcbWXlWpn29g5Hvr2fxzjistn8nNPMeMZz8AwcoOHGizOfK3bsPe0YGv7s359XrIhnV6eImoQCzlvgvnK5YrxPc0D2MDYeTSMjIq/LvqyhKBRK9EEIPfAKMBjoANwkhOpRQdKGUsqvj9rnjWD/gJaA30At4SQjh67Toy5C7axfxjz/BkWHDSJ45C4/OnWk25wtaLl2K78QJ6MzFFtjOy4Bvx0NBltZlctgLYPSojTBdYmDYQF4b+BoxSTE8suYRCmwFwL996G/q3plVjw7ig4ld0QnBIwt3MfSddXz390nyrTYajRgBUObUxVJKfpuzGIDLx4/i5t7NSiznYfDA2827xCUFb+wRhl3CjztUrV5RqqMiNfpewBEp5TEpZQGwABhTwfOPBFZKKVOllGnASmBU1UItnywoIGPpr/wzfgLHJ0wka+1a/G65mVbLlxE+83/azIkXtrPbLPD97ZB8SBvZ2rRrTYVXp4yKGMWMPjPYdHoTT294GqvdypksbfqDYHMwBr2OMV1D+WP6AGbf1gNfs5Fnfopl0Jtr+epYPm6dIsvsZjlr3THktr9Ia9qCu68te76fII+SlxSMCPCkV4Qfi7arPvWKUh0Vmb0yFDhV7HEcWg39QjcIIQYCh4BHpJSnSjk2tKQnEULcDdwN0KxZybW/stiysjh25VVYz57FLSKC4Oefx+e669B7eZZ+kJTw68NwbC2M+R+0HFzp572UjW0zlixLFm9ue5OXNr+EUWfE190Xk8FUVEanE4zoGMLwDsFsOJzMx2uO8PKv+7jd0IKbYpaQduwEvi2bn3fehdtO8uHSGH5IO0HgHVMu/nC9QKA58KKLsYVujArjyUW72X4ijaiI+nGtRFFqm7OmKV4KfCelzBdC3APMA4ZW5gRSytnAbICoqKhKV9/0Xl40vvFGPLp2wbN//6I5z8u04W3Y+TUMegq63VLZp6wXbutwG9mWbD6J+QSjzkjrxq1LLCeEYGDbQAa2DWTb8VS+/tEOMUt449mZBN0xhSn9WuDr6cbyvQk881Msk92S0NttePXvV+L5igsyB7EtYVuJ+66KbMKMJXv5ITpOJXpFqaKKNN3EA8Vn6gpzbCsipUyRUhbOQvU50KOixzpT4EMP4jVwYMWS/O7vYfWr0HkiDH6mpkK6JNzT+R4md5yMxW4pdbBUcT0j/PjgsWuQrdsyPGkvH64+Qr83VvP0j7t58LuddA5rzB3uiQgPDzy6dy/3fIEegUXTI1/I093AlZFN+HX3aXIKrFX6/RSloatIot8GtBFCtBBCuAETgSXFCwghinenuBbY77i/HBghhPB1XIQd4djmWsc3wi/3Q8QAuPajS7p/vDMIIXi0x6NM7z6dm9rdVOHjgq4eTdP4Iyy/9TJGdAjm++hTNPMz8+XknuRv2YK5V090bm7lnifQHIhVWi/q219oXI8wsgts/BGbUOHYFEX5V7mJXkppBR5AS9D7ge+llHuFEC8LIa51FHtICLFXCLELeAiY7Dg2FXgF7cNiG/CyY5vrJB2EBTeDbwvt4quh/ETUEAghmBo5lb6hfcsv7OA9YiQAgTu38P7Ebmx+ehg/3dcXz7SzFJw4gVe/8ptt4PwlBUvSq4Ufzf3N/LD9VIn7FUUpW4X60Uspf5dStpVStpJS/sex7UUp5RLH/WeklB2llF2klEOklAeKHTtHStnacfuyZn6NCso6C9/cCHo3uOUH8KiVnp71lnvLFri3aU3mcu1LWoiPiUYmI9kbHatJ9e9fofMUJvqSuliC9iF0Y/cwth5L5WRKjhMiV5SGpcGMjKUgB76bCFlJcPNC8G1e/jFKubxHjCRn+3asyclF27I3bcLQpAluLVpU6ByljY4t7voeYQih+tQrSlU0jERvt8FPd0H8DrjxCwit29MLX0q8R44AKclctQoAabWSvXUrnv1KGLNQigAPbXRsaV0sAUIbe9CvVQCLtsddNC2DoihlaxiJfsULcOBXGPV6nVoJqj5wb9MGt4iIoknOcnfHYs/MrHD7PGhr3fqZ/Mqs0QOMiwojPj2XrcdSqhWzojQ09T/R//UpbP0ELr8PLp/m6mjqHSEE3iNHkv3X31jT0rRpiYXAs0+fSp2nsItlWUZ2DMHbZFCLhytKJdXvRH/gN/jjKbjsahjxqqujqbcajRwBNhtZf/5J9qZNmCIj0TduXKlzlDU6tpDJqOeaLk35Y88ZzuVZqhGxojQs9TfRx2+HRXdC027aoiE6vasjqrfc27fHGBZG+qIfyd29G89+Fe+iWSjIXPJ8Nxca1yOMPIud33afqUqoitIg1c9En3YCvp0IXoFaDxs3c/nHKFWmNd+MIDcmBux2vCrYrbK4QI9AUvJSsNrLHv3aNbwxrYO8+CFa9alXlIqqf4k+Nx2+GQe2fLhlEXgFuTqiBqHRSG3wlM7TE4/OnSt9fJA5CLu0k5pX9ng6IQTjeoSx42Q6R85mlVlWURRN/Ur01gJYeCukHoMJ30BgO1dH1GCYIiMxNmuG54ABCGPlF04P9HAsKVjKoKnixnYPRa8TLFIXZRWlQpw1e6XrSQlLH4LjG2DsbGgxwNURNShCCCK++RphMpVfuATljY49r6y3icFtA/lpRxyPj2iLQV+/6iuK4mz15y8kN00bEDXkeegywdXRNEiGwED03t5VOrZwkfCKXJAFrU/92cx8NhxOLr+wojRw9adGb/aDu1aDWxkLjSh1lr/JH53QldvFstDQy4Lx83Rj0fY4hlymrsMoSlnqT40ewN2rwU85fKnS6/QEmAI4nXW6QuXdDDrGdG3Kyn2JpOcU1HB0inJpq1+JXrmk9QjpwW/HfmPhgYUVKn9jjzAKbHZ+ianYh4OiNFQq0St1xst9X2ZQ2CBe/etVPo/9vNwFwTs29aFDk0ZqnnpFKYdK9EqdYTKYeHfIu1zV8io+2PEB721/r9xkPy4qjD3x59h/5lwtRakolx6V6JU6xagz8t/+/2Viu4l8ufdL/m/L/2Gz20otP6ZrKEa94Ido1adeUUqjEr1S5+iEjmd7P8tdkXfx4+EfeWrDU1hsJU9i5ufpxhXtg/k5Jp4C68WLiyuKUsFEL4QYJYQ4KIQ4IoR4uoT9jwoh9gkhdgsh/hRCNC+2zyaEiHHcllx4rKKURAjBQ90f4vGox1l+fDkPrnmQXGtuiWXHRYWRml3A6gMV65qpKA1NuYleCKEHPgFGAx2Am4QQHS4othOIklJ2BhYBbxbblyul7Oq4XYuiVMKkjpP4v77/x5bTW7hn5T2cK7i4LX5gm0CCvN1ZpC7KKkqJKlKj7wUckVIek1IWAAuAMcULSCnXSCkLV23eCoQ5N0ylIbu+zfW8NfAtYpNjuXP5naTknr/ClEGvY2z3UNYcTOJsZp6LolSUuqsiiT4UKF5VinNsK82dwB/FHpuEENFCiK1CiOtKO0gIcbejXHRSUsWGwSsNx4iIEXw89GOOZxxn8rLJnMk6fz76cT3CsdmluiirKCVw6sVYIcStQBTwVrHNzaWUUcDNwPtCiFYlHSulnC2ljJJSRgUGBjozLKWe6Bfaj9kjZpOSm8Lty27nn4x/iva1DvKif+sA3lp+kGd+ilUrUFXBX8dSWKOuc9RLFUn08UB4scdhjm3nEUJcATwHXCulzC/cLqWMd/w8BqwFulUjXqWB6xbUjTmj5lBgK2DyssnsT9lftO+z26O4e2BLFm47yYh31/Pn/kQXRnppOZaUxeQvtzF1fjTbT5S9JoBy6alIot8GtBFCtBBCuAETgfN6zwghugGfoiX5s8W2+woh3B33A4B+wD5nBa80TJf5Xca8UfNw17tzx/I72J64HQAPNz3PXtmen+7rh4+HkTvnRfPQdztJycov54wNm8Vm5+GFMbgZdDRtbOLBb3eSlq3mD6pPyk30Ukor8ACwHNgPfC+l3CuEeFkIUdiL5i3AC/jhgm6U7YFoIcQuYA3wupRSJXql2iJ8Ipg/ej4BHgFMWzmNDXEbivZ1DW/M0gf78/AVbfhjzxmGv7eeJbtOlzvKtqF6f9Uhdsdl8Pr1kfzv5h4kZxXw+A+71OtVj4i6+J8ZFRUlo6OjXR2GcglIzUtl2sppHE47zGsDXmNUi1Hn7T+YkMmTi3axKy6DK9oH8ep1kYT4VG1xlPror2MpTPxsK+N6hPHmjV0AmLvpH2Ys3cdzV7bnroEtXRyhUlFCiO2O66EXUSNjlUuan8mPL0Z+QefAzjy5/knm7JmDxf7vhdh2Id78dF8/nruyPRuPJDP83XV89/dJVVsFMnItPLIwhuZ+Zl66pmPR9kl9IxjVMYQ3lh1gx8k0F0aoOItK9Molz9vNm1nDZzG02VDe2/4e1/9yPevj1hclc71OcNfAliybPpCOoY145qdYbvn8L06m5JRz5vpLSslzi2NJzMzn/Ynd8HT/dw0iIQRv3NiZEB+tvV7N93/pU4leqRc8DB68N/g9Phn2CQD3/3k/01ZN40jakaIyEQGefDv1cv47NpLdcRmMeH8dn284hs3e8Gr3i3fG8+vuMzxyRRu6hje+aL+Ph5FPbu7O2cw8Hv9ht/oGdIlTiV6pN4QQDAwbyE9jfuKpnk8RmxzLDUtv4NWtr5KWpzVB6HSCm3s3Y+WjA+nbKoBXf9vPDTM3cygx08XR155TqTm8+Mteekb4cu/g1qWW6xLemKdHt2fV/kS+2PhPqeWUuk8leqXeMeqM3NrhVn4f+zsT2k1g0aFFXPXTVczfO79oFswmPh58MSmKDyZ25URKNld9uIEP/zxc72fAtDq6UgrgvQld0evKXnrzjn4RDO8QzBvLDhBzKr1WYlScT/W6Ueq9o+lHeSv6LTbFb6J5o+Y81uMxBocPRjjWF07Oyuf/lu5j6a7TNPc3c8/AVtzQIxR3g97FkTvfB6sO896qQ3wwsStjupY1k8m/MnIsXPnhBoSA3x4cgI/ZWMNRKlWhet0oDVqrxq2YdcUs/jfsf+iEjofWPMRdK+/iYOpBAAK83Pnopm7MmRxFI5ORZxfHMuCNNcxef5SsfKuLo3ee7SfS+HD1YcZ2C61wkgfwMRv5+OZuJGTk8cQi1b/+UqRq9EqDYrFb+OHgD/xv1//ILMjkhjY3cH/X+/H38Ae03iibjqQwc90RNh1JoZHJwKS+EUzuG4G/l7uLo6+6zDytVi4l/D59AI1Mla+Vf77hGK/+tp+XrunAlH4taiBKpTrKqtGrRK80SBn5GczaNYsFBxZgMpi4p/M93Nz+Ztz0bkVlYk6lM3PtEZbvTcRk1DGxZzPuGtiS0MYeLoy8ah77fheLd8bx/T19iIrwq9I5pJTcNT+adYeS+PHevnQOa+zcIJVqUYleUUpxLOMY70S/w/q49YR7h3NnpzsZFD6IAI+AojJHzmYya90xft6pzeU3pmso0wa1pE2wt6vCrpSlu07z4Hc7eWhYGx4d3rZa50rPKeDKDzag1wt+fXAAPh6qvb6uUIleUcqxKX4Tb0e/zZF0rd99ZEAkg8IGMSh8EO182yGEID49l8/WH2PBtpPkWeyM6BDMfUNal9gPva6IT89l9PvraRXkxQ/39MGgr/5lue0n0pjw6RaGdwjmf7d0L7qorbiWSvSKUgFSSg6mHWTdqXWsi1tHbHIsAMHm4KKk3yukFzn5OuZu+oe5m49zLs9K31b+3De4Nf1a+9eppGezS27+bCt74jP4ffoAmvt7Ou3cn647ymt/HODlMR25vU+E086rVJ1K9IpSBcm5yWyI28D6uPVsPr2ZHGsOJr2J3k16Myh8ED0C+/FnbB6fbTjG2cx8Oof5MLFnM6IifGkd6IWunD7qNe1/a4/w5rKDvD2uCzf2cO7qnna7ZOr8aDYeTuan+/rSKdTHqedXKk8lekWppgJbAdEJ0ayL02r78Vlae317v/b0Dx2ANbM9S7bpOJ6cC4C3yUDX8MZ0b+ZL9+a+dA1vXKvt2bvj0rn+f5sZ2SmEj2/qVuo3DSkle1P2svz4clYcX4HVbmVY82GMaD6CbkHd0OtKH0uQll3AlR9uwM2g49cH++NdhZ48ivOoRK8oTiSl5Gj6UdbFrWN93HpikmKwSzsBHgG0b9wNo60pWZmBnDjjw7EEA3YpEAJaB3rRo7mvI/k3pmVAzdT6cwqsXPXhRvIsNpZNH3jRACcpJftS9xUl9/iseAw6A32b9sVN58aG+A3k2/IJ8AjgimZXMDJiZKlJP/p4KhNmb2VUOR8oSs1TiV5RalBaXhob4zeyPm49scmxRbV9AC+jF8GmFrjZm5KdGcSpRB/OnQsAu4lGJgPdmv2b+LuGN3ZKrfiZn3azYNspvp16OX1a/Ts+4EDqAZYfX87y48uJy4rDIAxc3vRyRkaMZEj4EHzcteaXHEsO6+LWseL4igol/Zlrj/LGsgO8cl0nbru8ebXjV6pGJXpFqUVZBVkcST/CobRDHEo7xOG0wxxOO0ym5d+J03yMQZjsYWRnBZKc6octrwnS4k+4rzehjT1o2tiDUF8PQhubtPuObSZj2dMyLNuTwLSvt3Pv4FY8ObIdh9IOFSX3k5kn0Qs9lzfRkvvQZkOLkntpykr6IyJG0D2oOwIdd8zbxuajKXx/Tx+6hPmomr0LqESvKC4mpSQhO4HD6YfP+wA4nnEcq9SmWdBjxA1/pM0TS4EHefkm7FZPpM2MtGk/GxkbE+zlT6i3P80a+xPqaybM998PgXGfbibEP53Rlyfy58mVHD93HL3Q0yukV1Fy9zX5Vul3yLHksD5uPcuPL78o6V8ePIRnvsvi7DkLnm56wv3MhPmaCffzINzXTLifdj/M14xXsbnvFeepdqIXQowCPgD0wOdSytcv2O8OzAd6ACnABCnlcce+Z4A7ARvwkJRyeXnPpxK90lAU2Ar4J+OfosR/Ovs06XnppOenk5afRmpeGtZiK2YVJ6U470NA2swY3JMRbmfRCR09Q3oyMmIkw5oNw89UtdGwpSkp6fu6+xNgaIfFYiKvwEB2joGMHD35BW5gNyHt7kibiUbunjRt5Ee4jy/N/RrTzM9L+yDw9SCokQmTQeeU/v4NTbUSvRBCDxwChgNxwDbgpuKLfAsh7gM6SymnCSEmAmOllBOEEB2A74BeQFNgFdBWSmkr6zlVolcUjZSSXGsuaflppOdpyT8tL037IMhL42x2KglZKSTnppGen0awZwA3tLuKYc2GFc3fU9MKk/6KEys4nHaYbEs2WZYscq255R4rpQC7G9JuQtpMIN2QUo+QBvTCgE4YMQgjemHEoDNidNzcdG4Y9Ubc9O64642Y9G64G9xw17th0Bsw6gwYdHqMOj1GvUG76bSbm8GAW+FjvXbfzWDAXW/EqNcXHafXaz8NOp2jrM5xbj1uej16oceo16PXiTrRVFVWoq/Id6hewBEp5THHyRYAY4B9xcqMAWY47i8CPhbabz4GWCClzAf+EUIccZxvS1V+EUVpaIQQmI1mzEYzoV4Vn3GyNpmNZka1GHXRwuxWu5Ucaw5ZBVlkWbK0D4AC7WemJZPsgmwyC7JIys7gbHY6qbmZZFtysNgtWO0WrPYCrDILq7Rgl1ZypZVsLEisSLsVpB3qwOSiUgpAB1IA/94XFCZ/xza0/QJRVFZLkwKkDoHATXjz9x0/Oz3GiiT6UOBUscdxQO/SykgprUKIDMDfsX3rBceW+G4VQtwN3A3QrFmzisSuKEodZtAZaOTWiEZujWrk/Da7DYvdgsVuocBWQI4ln+yCfApsVvKtVgpsFgqsVgrsVixWK/k2KwWOm8VmxWIv/Gkremy1W7Ha7djtdmzShk1qP897bLdhp7CMtl1K7b5d2pCAlHbs0o5EIqXEjh0pJRI7dimRxfY59iKlHQ+980YvF1dnropIKWcDs0FrunFxOIqi1HF6nR69To8JEwD+l96korWmIlc84oHwYo/DHNtKLCOEMAA+aBdlK3KsoiiKUoMqkui3AW2EEC2EEG7ARGDJBWWWAJMc928EVkvtKu8SYKIQwl0I0QJoA/ztnNAVRVGUiii36cbR5v4AsByte+UcKeVeIcTLQLSUcgnwBfCV42JrKtqHAY5y36NduLUC95fX40ZRFEVxLjVgSlEUpR5Qi4MriqI0YCrRK4qi1HMq0SuKotRzKtEriqLUc3XyYqwQIgk4UcXDA4BkJ4bjbCq+6lHxVY+Kr3rqcnzNpZSBJe2ok4m+OoQQ0aVdea4LVHzVo+KrHhVf9dT1+Eqjmm4URVHqOZXoFUVR6rn6mOhnuzqAcqj4qkfFVz0qvuqp6/GVqN610SuKoijnq481ekVRFKUYlegVRVHquUs20QshRgkhDgohjgghni5hv7sQYqFj/19CiIhajC1cCLFGCLFPCLFXCDG9hDKDhRAZQogYx+3F2orP8fzHhRCxjue+aAY5ofnQ8frtFkJ0r8XY2hV7XWKEEOeEEA9fUKZWXz8hxBwhxFkhxJ5i2/yEECuFEIcdP31LOXaSo8xhIcSkksrUUHxvCSEOOP7/FgshGpdybJnvhRqMb4YQIr7Y/+GVpRxb5t96Dca3sFhsx4UQMaUcW+OvX7VJKS+5G9p0yUeBloAbsAvocEGZ+4BZjvsTgYW1GF8ToLvjvjfa4uoXxjcY+NWFr+FxIKCM/VcCf6AtdHk58JcL/68T0AaDuOz1AwYC3YE9xba9CTztuP808EYJx/kBxxw/fR33fWspvhGAwXH/jZLiq8h7oQbjmwE8XoH//zL/1msqvgv2vwO86KrXr7q3S7VGX7RguZSyAChcsLy4McA8x/1FwDBRS0u1SynPSCl3OO5nAvspZa3cOmwMMF9qtgKNhRBNXBDHMOColLKqI6WdQkq5Hm2theKKv8fmAdeVcOhIYKWUMlVKmQasBEaVUM7p8UkpV0gpC5fP3oq2wptLlPL6VURF/tarraz4HHljPPCds5+3tlyqib6kBcsvTKTnLVgOFC5YXqscTUbdgL9K2N1HCLFLCPGHEKJj7UaGBFYIIbY7Fma/UEVe49owkdL/wFz5+gEESynPOO4nAMEllKkrr+MdaN/QSlLee6EmPeBoWppTStNXXXj9BgCJUsrDpex35etXIZdqor8kCCG8gB+Bh6WU5y7YvQOtOaIL8BHwcy2H119K2R0YDdwvhBhYy89fLqEtXXkt8EMJu139+p1Hat/h62RfZSHEc2grvH1TShFXvRdmAq2ArsAZtOaRuugmyq7N1/m/pUs10VdnwfJaIYQwoiX5b6SUP124X0p5TkqZ5bj/O2AUQgTUVnxSynjHz7PAYrSvyMXVhYXdRwM7pJSJF+5w9evnkFjYnOX4ebaEMi59HYUQk4GrgVscH0YXqcB7oUZIKROllDYppR34rJTndfXrZwCuBxaWVsZVr19lXKqJvjoLltc4R5veF8B+KeW7pZQJKbxmIITohfZ/USsfREIITyGEd+F9tIt2ey4otgS43dH75nIgo1gzRW0ptSblytevmOLvsUnALyWUWQ6MEEL4OpomRji21TghxCjgSeBaKWVOKWUq8l6oqfiKX/MZW8rzVuRvvSZdARyQUsaVtNOVr1+luPpqcFVvaL1CDqFdkX/Ose1ltDc1gAntK/8R4G+gZS3G1h/ta/xuIMZxuxKYBkxzlHkA2IvWi2Ar0LcW42vpeN5djhgKX7/i8QngE8frGwtE1fL/ryda4vYpts1lrx/aB84ZwILWTnwn2jWfP4HDwCrAz1E2Cvi82LF3ON6HR4AptRjfEbT27cL3YGEvtKbA72W9F2opvq8c763daMm7yYXxOR5f9LdeG/E5ts8tfM8VK1vrr191b2oKBEVRlHruUm26URRFUSpIJXpFUZR6TiV6RVGUek4lekVRlHpOJXpFUZR6TiV6RVGUek4lekVRlHru/wEz1WdKDUivDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for metric in history.history.keys():\n",
    "    plt.plot(history.history[metric], label=metric)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\"September 17, 2009\", \"July 14, 1789\"]\n",
    "\n",
    "sample_tensor = strs_to_tensor(sample, input_chars)\n",
    "\n",
    "pred = model.predict(sample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  1,  1, 10, 11,  1, 10, 11,  2,  8],\n",
       "       [ 2,  8,  9, 10, 11,  1,  8, 11,  2,  5]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_id = np.argmax(pred, axis=-1)\n",
    "pred_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_strings(idxs, chars):\n",
    "    return [\"\".join([([\"?\"] + chars)[i] for i in idx]) for idx in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-09-17\n",
      "1789-07-14\n"
     ]
    }
   ],
   "source": [
    "for pred in index_to_strings(pred_id, output_chars):\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = strs_to_tensor([\"May 02, 2020\", \"July 14, 1789\"], input_chars)\n",
    "pred = model.predict(sample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-02\n",
      "1789-02-14\n"
     ]
    }
   ],
   "source": [
    "pred_id = np.argmax(pred, axis=-1)\n",
    "for pred in index_to_strings(pred_id, output_chars):\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = x_train.shape[1]\n",
    "\n",
    "def prepare_date_padding(strs):\n",
    "    x = strs_to_tensor(strs, input_chars)\n",
    "    if x.shape[1] < max_input_length:\n",
    "        x = tf.pad(x, [[0, 0], [0, max_input_length - x.shape[1]]])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_date(strs):\n",
    "    x = prepare_date_padding(strs)\n",
    "    pred_idx = np.argmax(model.predict(x), axis=-1)\n",
    "    return index_to_strings(pred_idx, output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-05-02', '1789-07-14']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_date([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = len(output_chars) + 1\n",
    "\n",
    "def shifted_output_sequences(y):\n",
    "    sos_tokens = tf.fill(dims=(len(y), 1), value=sos_id)\n",
    "    return tf.concat([sos_tokens, y[:, :-1]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_decoder = shifted_output_sequences(y_train)\n",
    "x_val_decoder = shifted_output_sequences(y_val)\n",
    "x_test_decoder = shifted_output_sequences(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 10])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_decoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 8s 16ms/step - loss: 1.9375 - accuracy: 0.3113 - val_loss: 1.4087 - val_accuracy: 0.4684\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.3229 - accuracy: 0.4999 - val_loss: 0.9370 - val_accuracy: 0.6533\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.8100 - accuracy: 0.7032 - val_loss: 0.4014 - val_accuracy: 0.8729\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3158 - accuracy: 0.9071 - val_loss: 0.1274 - val_accuracy: 0.9757\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0993 - accuracy: 0.9859 - val_loss: 0.0541 - val_accuracy: 0.9964\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0412 - accuracy: 0.9983 - val_loss: 0.0424 - val_accuracy: 0.9969\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0253 - accuracy: 0.9991 - val_loss: 0.0149 - val_accuracy: 0.9999\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9999\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "lstm_units = 128\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "encoder_embedding = keras.layers.Embedding(\n",
    "    input_dim=len(input_chars) + 1, \n",
    "    output_dim=encoder_embedding_size)(encoder_input)\n",
    "_, encoder_state_h, encoder_state_c = keras.layers.LSTM(\n",
    "    lstm_units, return_state=True)(encoder_embedding)\n",
    "encoder_state = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "decoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "decoder_embedding = keras.layers.Embedding(\n",
    "    input_dim=len(output_chars) + 2, \n",
    "    output_dim=decoder_embedding_size)(decoder_input)\n",
    "decoder_lstm_output = keras.layers.LSTM(lstm_units, return_sequences=True)(\n",
    "    decoder_embedding, initial_state=encoder_state)\n",
    "decoder_output = keras.layers.Dense(len(output_chars) + 1, \n",
    "                                   activation='softmax')(decoder_lstm_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_input, decoder_input], \n",
    "                          outputs=[decoder_output])\n",
    "\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit([x_train, x_train_decoder], y_train, epochs=10, \n",
    "                   validation_data=([x_val, x_val_decoder], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for metric in history.history.keys():\n",
    "    plt.plot(history.history[metric], label=metric)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = len(output_chars) + 1\n",
    "max_output_length = y_train.shape[-1]\n",
    "\n",
    "def predict_date(strs):\n",
    "    x = prepare_date_padding(strs)\n",
    "    y_pred = tf.fill(dims=(len(x), 1), value=sos_id)\n",
    "    for index in range(max_output_length):\n",
    "        pad_size = max_output_length - y_pred.shape[-1]\n",
    "        x_decoder = tf.pad(y_pred, [[0, 0], [0, pad_size]])\n",
    "        y_proba_next = model.predict([x, x_decoder])[:, index:index + 1]\n",
    "        y_pred_next = tf.argmax(y_proba_next, axis=-1, output_type=tf.int32)\n",
    "        y_pred = tf.concat([y_pred, y_pred_next], axis=1)\n",
    "    return index_to_strings(y_pred[:, 1:], output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_date([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## teacher forcing ( TF-Addons ) - training_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "313/313 [==============================] - 8s 17ms/step - loss: 1.9192 - accuracy: 0.3118 - val_loss: 1.4655 - val_accuracy: 0.4412\n",
      "Epoch 2/15\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 1.4371 - accuracy: 0.4329 - val_loss: 1.2304 - val_accuracy: 0.5215\n",
      "Epoch 3/15\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 1.1008 - accuracy: 0.5848 - val_loss: 0.8424 - val_accuracy: 0.6824\n",
      "Epoch 4/15\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.5856 - accuracy: 0.7975 - val_loss: 0.2256 - val_accuracy: 0.9485\n",
      "Epoch 5/15\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.1692 - accuracy: 0.9692 - val_loss: 0.0695 - val_accuracy: 0.9944\n",
      "Epoch 6/15\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.1223 - accuracy: 0.9793 - val_loss: 0.0347 - val_accuracy: 0.9984\n",
      "Epoch 7/15\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0276 - accuracy: 0.9996 - val_loss: 0.0195 - val_accuracy: 0.9997\n",
      "Epoch 8/15\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9999\n",
      "Epoch 9/15\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9999\n",
      "Epoch 10/15\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9999\n",
      "Epoch 11/15\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9999\n",
      "Epoch 12/15\n",
      "313/313 [==============================] - 13s 43ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9999\n",
      "Epoch 13/15\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "units = 128\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_length = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "encoder_embeddings = keras.layers.Embedding(\n",
    "    len(input_chars) + 1, encoder_embedding_size)(encoder_inputs)\n",
    "decoder_embedding_layer = keras.layers.Embedding(\n",
    "    len(output_chars) + 2, decoder_embedding_size)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "encoder = keras.layers.LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(units)\n",
    "output_layer = keras.layers.Dense(len(output_chars) + 1)\n",
    "\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, \n",
    "                                                 output_layer=output_layer)\n",
    "\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings, initial_state=encoder_state)\n",
    "y_proba = keras.layers.Activation('softmax')(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "                          outputs=[y_proba])\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit([x_train, x_train_decoder], y_train, epochs=15, \n",
    "                   validation_data=([x_val, x_val_decoder], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for metric in history.history.keys():\n",
    "    plt.plot(history.history[metric], label=metric)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_date([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### efficient way to perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_sampler = tfa.seq2seq.sampler.GreedyEmbeddingSampler(\n",
    "    embedding_fn=decoder_embedding_layer)\n",
    "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
    "    decoder_cell, inference_sampler, output_layer=output_layer,\n",
    "    maximum_iterations=max_output_length)\n",
    "batch_size=tf.shape(encoder_inputs)[:1]\n",
    "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
    "final_outputs, final_state, final_sequence_lengths = inference_decoder(\n",
    "    start_tokens, initial_state=encoder_state, start_tokens=start_tokens, \n",
    "    end_token=0)\n",
    "inference_model = keras.models.Model(inputs=[encoder_inputs], \n",
    "                                    outputs=[final_outputs.sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_predict_date(strs):\n",
    "    x = prepare_date_padding(strs)\n",
    "    y_pred = inference_model.predict(x)\n",
    "    return index_to_strings(y_pred, output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_predict_date([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341 ms ± 32 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit predict_date([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.2 ms ± 862 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fast_predict_date([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## teacher forcing ( TF-Addons ) - scheduled_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2",
   "language": "python",
   "name": "tensorflow_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
