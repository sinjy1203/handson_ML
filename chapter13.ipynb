{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.repeat(3).batch(7, drop_remainder=True)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int64)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-15e8a30c9761>:1: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.unbatch()`.\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.apply(tf.data.experimental.unbatch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: x < 10)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.take(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 6], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_mean = scaler.mean_\n",
    "x_std = scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "    \n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, 'wt', encoding='utf-8') as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[x_train, y_train]\n",
    "valid_data = np.c_[x_valid, y_valid]\n",
    "test_data = np.c_[x_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5214</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.049945</td>\n",
       "      <td>1.106548</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>1.605993</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-122.43</td>\n",
       "      <td>1.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.490060</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>3.443340</td>\n",
       "      <td>33.69</td>\n",
       "      <td>-117.39</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.542373</td>\n",
       "      <td>1.591525</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2.250847</td>\n",
       "      <td>38.44</td>\n",
       "      <td>-122.98</td>\n",
       "      <td>1.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1736</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.289003</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>33.55</td>\n",
       "      <td>-117.70</td>\n",
       "      <td>2.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.312457</td>\n",
       "      <td>1.085092</td>\n",
       "      <td>3297.0</td>\n",
       "      <td>2.244384</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-116.93</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n",
       "1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n",
       "2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n",
       "3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n",
       "4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -122.43             1.442  \n",
       "1    -117.39             1.687  \n",
       "2    -122.98             1.621  \n",
       "3    -117.70             2.621  \n",
       "4    -116.93             0.956  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
      "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
      "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
      "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
      "7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
     ]
    }
   ],
   "source": [
    "with open(train_filepaths[0]) as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets\\\\housing\\\\my_train_00.csv',\n",
       " 'datasets\\\\housing\\\\my_train_01.csv',\n",
       " 'datasets\\\\housing\\\\my_train_02.csv',\n",
       " 'datasets\\\\housing\\\\my_train_03.csv',\n",
       " 'datasets\\\\housing\\\\my_train_04.csv',\n",
       " 'datasets\\\\housing\\\\my_train_05.csv',\n",
       " 'datasets\\\\housing\\\\my_train_06.csv',\n",
       " 'datasets\\\\housing\\\\my_train_07.csv',\n",
       " 'datasets\\\\housing\\\\my_train_08.csv',\n",
       " 'datasets\\\\housing\\\\my_train_09.csv',\n",
       " 'datasets\\\\housing\\\\my_train_10.csv',\n",
       " 'datasets\\\\housing\\\\my_train_11.csv',\n",
       " 'datasets\\\\housing\\\\my_train_12.csv',\n",
       " 'datasets\\\\housing\\\\my_train_13.csv',\n",
       " 'datasets\\\\housing\\\\my_train_14.csv',\n",
       " 'datasets\\\\housing\\\\my_train_15.csv',\n",
       " 'datasets\\\\housing\\\\my_train_16.csv',\n",
       " 'datasets\\\\housing\\\\my_train_17.csv',\n",
       " 'datasets\\\\housing\\\\my_train_18.csv',\n",
       " 'datasets\\\\housing\\\\my_train_19.csv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for item in filepath_dataset:\n",
    "    lst += [item.numpy().decode('utf-8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "                                     cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 8\n",
    "\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - x_mean) / x_std, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 0.16579159,  1.216324  , -0.05204564, -0.39215982, -0.5277444 ,\n",
       "        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5, n_read_threads=None,\n",
    "                      shuffle_buffer_size=10000, n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1), \n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 1.6435 - val_loss: 0.7933\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.7066 - val_loss: 0.6534\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.6290 - val_loss: 0.6088\n",
      "Epoch 4/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.5678\n",
      "Epoch 5/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.5442 - val_loss: 0.5376\n",
      "Epoch 6/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.5713 - val_loss: 0.5176\n",
      "Epoch 7/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.5373 - val_loss: 0.4993\n",
      "Epoch 8/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.5182 - val_loss: 0.5013\n",
      "Epoch 9/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.4937 - val_loss: 0.4691\n",
      "Epoch 10/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.4636 - val_loss: 0.4571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1710b1c3f48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "batch_size = 32\n",
    "model.fit(train_set, epochs=10, steps_per_epoch=len(x_train) // batch_size, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e157f0b45a6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_data.tfrecord'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\"This is the first record\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\"And this is the second record\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.io.TFRecordWriter('my_data.tfrecord') as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filepaths = ['my_data.tfrecord']\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.io.TFRecordOptions(compression_type='GZIP')\n",
    "with tf.io.TFRecordWriter('my_compressed.tfrecord', options) as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(['my_compressed.tfrecord'], compression_type='GZIP')\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting person.proto\n"
     ]
    }
   ],
   "source": [
    "%%writefile person.proto\n",
    "syntax = \"proto3\";\n",
    "message Person {\n",
    "  string name = 1;\n",
    "  int32 id = 2;\n",
    "  repeated string email = 3;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!protoc person.proto --python_out=. --descriptor_set_out=person.desc --include_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Is'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "!Is person*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"AI\"\n",
      "id: 123\n",
      "email: \"a@b.com\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from person_pb2 import Person\n",
    "\n",
    "person = Person(name='AI', id=123, email=['a@b.com'])\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a@b.com'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person.name='Alice'\n",
    "person.email[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "person.email.append('c@d.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\x05Alice\\x10{\\x1a\\x07a@b.com\\x1a\\x07c@d.com'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = person.SerializeToString()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person2 = Person()\n",
    "person2.ParseFromString(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person == person2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "person_example = Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"name\": Feature(bytes_list=BytesList(value=[b'Alice'])),\n",
    "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "            \"emails\": Feature(bytes_list=BytesList(value=[b'a@b.com', b'c@d.com']))\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"emails\": tf.io.VarLenFeature(tf.string)\n",
    "}\n",
    "\n",
    "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
    "    parsed_example = tf.io.parse_single_example(serialized_example, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'ISLAND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.lookup_ops.KeyValueTensorInitializer at 0x20f26876f88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_oov_buckets = 2\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = tf.constant(['NEAR BAY', 'DESERT', 'INLAND', 'INLAND'])\n",
    "cat_indices = table.lookup(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 2\n",
    "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
    "embedding_matrix = tf.Variable(embed_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
       "array([[0.7230369 , 0.39920306],\n",
       "       [0.92811704, 0.8523536 ],\n",
       "       [0.9702226 , 0.2862773 ],\n",
       "       [0.3358699 , 0.26669073],\n",
       "       [0.36563587, 0.9234767 ],\n",
       "       [0.34648645, 0.29476976],\n",
       "       [0.90271723, 0.30463648]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = tf.constant(['NEAR BAY', 'DESERT', 'INLAND', 'INLAND'])\n",
    "cat_indices = table.lookup(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.3358699 , 0.26669073],\n",
       "       [0.34648645, 0.29476976],\n",
       "       [0.92811704, 0.8523536 ],\n",
       "       [0.92811704, 0.8523536 ]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[-0.02716175,  0.03295377],\n",
       "       [ 0.04791096,  0.02315411],\n",
       "       [ 0.01688908,  0.0195048 ],\n",
       "       [ 0.01688908,  0.0195048 ]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = keras.layers.Embedding(input_dim=len(vocab) + num_oov_buckets, \n",
    "                                  output_dim = embedding_dim)\n",
    "embedding(cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_inputs = keras.layers.Input(shape=[8])\n",
    "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
    "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
    "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
    "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "model = keras.models.Model(inputs=[regular_inputs, categories], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None,)              0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 2)            12          lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 10)           0           input_1[0][0]                    \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            11          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 23\n",
      "Trainable params: 23\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_transform as tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputs):\n",
    "    median_age = inputs[\"housing_median_age\"]\n",
    "    ocean_proximity = inputs['ocean_proximity']\n",
    "    standardized_age = tft.scale_to_z_score(median_age)\n",
    "    ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
    "    return {\n",
    "        \"standardized_median_age\": standardized_age,\n",
    "        \"ocean_proximity_id\": ocean_proximity_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to C:\\Users\\sinjy\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead set\n",
      "data_dir=gs://tfds-data/datasets.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425abc5debd4408e9d8262fdab0cecdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\sinjy\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset = tfds.load(name='mnist')\n",
    "mnist_train, mnist_test = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 9 번"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_valid, x_train = x_train_full[:5000], x_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(len(x_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                \"label\": Feature(int64_list=Int64List(value=[label]))\n",
    "            }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\rI\\000\\000\\001\\004\\000\\000\\000\\000\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000$\\210\\177>6\\000\\000\\000\\001\\003\\004\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000f\\314\\260\\206\\220{\\027\\000\\000\\000\\000\\014\\n\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\233\\354\\317\\262k\\234\\241m@\\027M\\202H\\017\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000E\\317\\337\\332\\330\\330\\243\\177yz\\222\\215X\\254B\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\001\\000\\310\\350\\350\\351\\345\\337\\337\\327\\325\\244\\177{\\304\\345\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\267\\341\\330\\337\\344\\353\\343\\340\\336\\340\\335\\337\\365\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\344\\332\\325\\306\\264\\324\\322\\323\\325\\337\\334\\363\\312\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\003\\000\\014\\333\\334\\324\\332\\300\\251\\343\\320\\332\\340\\324\\342\\305\\3214\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000c\\364\\336\\334\\332\\313\\306\\335\\327\\325\\336\\334\\365w\\2478\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\0007\\354\\344\\346\\344\\360\\350\\325\\332\\337\\352\\331\\331\\321\\\\\\000\\000\\000\\001\\004\\006\\007\\002\\000\\000\\000\\000\\000\\355\\342\\331\\337\\336\\333\\336\\335\\330\\337\\345\\327\\332\\377M\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000>\\221\\314\\344\\317\\325\\335\\332\\320\\323\\332\\340\\337\\333\\327\\340\\364\\237\\000\\000\\000\\000\\000\\022,Rk\\275\\344\\334\\336\\331\\342\\310\\315\\323\\346\\340\\352\\260\\274\\372\\370\\351\\356\\327\\000\\0009\\273\\320\\340\\335\\340\\320\\314\\326\\320\\321\\310\\237\\365\\301\\316\\337\\377\\377\\335\\352\\335\\323\\334\\350\\366\\000\\003\\312\\344\\340\\335\\323\\323\\326\\315\\315\\315\\334\\360P\\226\\377\\345\\335\\274\\232\\277\\322\\314\\321\\336\\344\\341\\000b\\351\\306\\322\\336\\345\\345\\352\\371\\334\\302\\327\\331\\361AIju\\250\\333\\335\\327\\331\\337\\337\\340\\345\\035K\\314\\324\\314\\301\\315\\323\\341\\330\\271\\305\\316\\306\\325\\360\\303\\343\\365\\357\\337\\332\\324\\321\\336\\334\\335\\346C0\\313\\267\\302\\325\\305\\271\\276\\302\\300\\312\\326\\333\\335\\334\\354\\341\\330\\307\\316\\272\\265\\261\\254\\265\\315\\316s\\000z\\333\\301\\263\\253\\267\\304\\314\\322\\325\\317\\323\\322\\310\\304\\302\\277\\303\\277\\306\\300\\260\\234\\247\\261\\322\\\\\\000\\000J\\275\\324\\277\\257\\254\\257\\265\\271\\274\\275\\274\\301\\306\\314\\321\\322\\322\\323\\274\\274\\302\\300\\330\\252\\000\\002\\000\\000\\000B\\310\\336\\355\\357\\362\\366\\363\\364\\335\\334\\301\\277\\263\\266\\266\\265\\260\\246\\250c:\\000\\000\\000\\000\\000\\000\\000\\000\\000(=,H)#\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image, label in valid_set.take(1):\n",
    "    print(create_example(image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = ['{}.tfrecord-{:05d}-of-{:05d}'.format(name, index, n_shards)\n",
    "            for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
    "                  for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    example =tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example['image'], out_type=tf.uint8)\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                 n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,\n",
    "                                     num_parallel_reads=n_parse_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28) (32,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for x, y in train_set.take(1):\n",
    "    print(x.shape, y.shape)\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(x[i].numpy(), cmap='binary')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
    "    \n",
    "standardization = Standardization(input_shape=[28, 28])\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()), \n",
    "                              axis=0).astype(np.float32)\n",
    "standardization.adapt(sample_images)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5837 - accuracy: 0.8065 - val_loss: 0.5892 - val_accuracy: 0.8624\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3477 - accuracy: 0.8769 - val_loss: 0.4070 - val_accuracy: 0.8730\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3313 - accuracy: 0.8930 - val_loss: 0.4155 - val_accuracy: 0.8750\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2684 - accuracy: 0.9034 - val_loss: 0.4100 - val_accuracy: 0.8866\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2573 - accuracy: 0.9101 - val_loss: 0.3720 - val_accuracy: 0.8838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f0223ded48>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "logs = os.path.join(os.curdir, \"my_logs\",\n",
    "                   \"run_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=10)\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set,\n",
    "         callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/sinjy/.keras/datasets/aclImdb')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://ai.stanford.edu/~amaas/data/sentiment/\"\n",
    "FILENAME = \"aclImdb_v1.tar.gz\"\n",
    "filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, extract=True)\n",
    "path = Path(filepath).parent / \"aclImdb\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinjy\\.keras\\datasets\\aclImdb ['test', 'train'] ['imdb.vocab', 'imdbEr.txt', 'README']\n",
      "('C:\\\\', 'Users', 'sinjy', '.keras', 'datasets', 'aclImdb')\n",
      "('C:\\\\', 'Users', 'sinjy', '.keras', 'datasets', 'aclImdb')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for name, subdirs, files in os.walk(path):\n",
    "    print(name, subdirs, files)\n",
    "    print(Path(name).parts)\n",
    "    print(path.parts)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb\\\n",
      "    README\n",
      "    imdb.vocab\n",
      "    imdbEr.txt\n",
      "    test\\\n",
      "        labeledBow.feat\n",
      "        urls_neg.txt\n",
      "        urls_pos.txt\n",
      "        neg\\\n",
      "            0_2.txt\n",
      "            10000_4.txt\n",
      "            10001_1.txt\n",
      "            ...\n",
      "        pos\\\n",
      "            0_10.txt\n",
      "            10000_7.txt\n",
      "            10001_9.txt\n",
      "            ...\n",
      "    train\\\n",
      "        labeledBow.feat\n",
      "        unsupBow.feat\n",
      "        urls_neg.txt\n",
      "        ...\n",
      "        neg\\\n",
      "            0_3.txt\n",
      "            10000_4.txt\n",
      "            10001_4.txt\n",
      "            ...\n",
      "        pos\\\n",
      "            0_9.txt\n",
      "            10000_8.txt\n",
      "            10001_10.txt\n",
      "            ...\n",
      "        unsup\\\n",
      "            0_0.txt\n",
      "            10000_0.txt\n",
      "            10001_0.txt\n",
      "            ...\n"
     ]
    }
   ],
   "source": [
    "for name, subdirs, files in os.walk(path):\n",
    "    indent = len(Path(name).parts) - len(path.parts)\n",
    "    print(\"    \" * indent + Path(name).parts[-1] + os.sep)\n",
    "    for index, filename in enumerate(sorted(files)):\n",
    "        if index == 3:\n",
    "            print(\"    \" * (indent + 1) + \"...\")\n",
    "            break\n",
    "        print(\"    \" * (indent + 1) + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/sinjy/.keras/datasets/aclImdb/imdb.vocab'),\n",
       " WindowsPath('C:/Users/sinjy/.keras/datasets/aclImdb/imdbEr.txt'),\n",
       " WindowsPath('C:/Users/sinjy/.keras/datasets/aclImdb/README'),\n",
       " WindowsPath('C:/Users/sinjy/.keras/datasets/aclImdb/test'),\n",
       " WindowsPath('C:/Users/sinjy/.keras/datasets/aclImdb/train')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(path.glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def review_paths(dirpath):\n",
    "    return [str(path) for path in dirpath.glob(\"*.txt\")]\n",
    "\n",
    "train_pos = review_paths(path / \"train\" / \"pos\")\n",
    "train_neg = review_paths(path / \"train\" / \"neg\")\n",
    "test_valid_pos = review_paths(path / \"test\" / \"pos\")\n",
    "test_valid_neg = review_paths(path / \"test\" / \"neg\")\n",
    "\n",
    "len(train_pos), len(train_neg), len(test_valid_pos), len(test_valid_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.shuffle(test_valid_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = test_valid_pos[:5000]\n",
    "test_neg = test_valid_neg[:5000]\n",
    "valid_pos = test_valid_pos[5000:]\n",
    "valid_neg = test_valid_neg[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)):\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath, encoding='UTF-8') as review_file:\n",
    "                reviews.append(review_file.read())\n",
    "            labels.append(label)\n",
    "    return tf.data.Dataset.from_tensor_slices((tf.constant(reviews), \n",
    "                                              tf.constant(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b\"Airport '77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman Philip Stevens (James Stewart) who is flying them & a bunch of VIP's to his estate in preparation of it being opened to the public as a museum, also on board is Stevens daughter Julie (Kathleen Quinlan) & her son. The luxury jetliner takes off as planned but mid-air the plane is hi-jacked by the co-pilot Chambers (Robert Foxworth) & his two accomplice's Banker (Monte Markham) & Wilson (Michael Pataki) who knock the passengers & crew out with sleeping gas, they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent Chambers almost hits an oil rig in the Ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the Bermuda Triangle. With air in short supply, water leaking in & having flown over 200 miles off course the problems mount for the survivor's as they await help with time fast running out...<br /><br />Also known under the slightly different tile Airport 1977 this second sequel to the smash-hit disaster thriller Airport (1970) was directed by Jerry Jameson & while once again like it's predecessors I can't say Airport '77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons. Out of the three Airport films I have seen so far I actually liked this one the best, just. It has my favourite plot of the three with a nice mid-air hi-jacking & then the crashing (didn't he see the oil rig?) & sinking of the 747 (maybe the makers were trying to cross the original Airport with another popular disaster flick of the period The Poseidon Adventure (1972)) & submerged is where it stays until the end with a stark dilemma facing those trapped inside, either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened & it's a decent idea that could have made for a great little disaster flick but bad unsympathetic character's, dull dialogue, lethargic set-pieces & a real lack of danger or suspense or tension means this is a missed opportunity. While the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks & there's not as much urgency as I thought there should have been. Even when the Navy become involved things don't pick up that much with a few shots of huge ships & helicopters flying about but there's just something lacking here. George Kennedy as the jinxed airline worker Joe Patroni is back but only gets a couple of scenes & barely even says anything preferring to just look worried in the background.<br /><br />The home video & theatrical version of Airport '77 run 108 minutes while the US TV versions add an extra hour of footage including a new opening credits sequence, many more scenes with George Kennedy as Patroni, flashbacks to flesh out character's, longer rescue scenes & the discovery or another couple of dead bodies including the navigator. While I would like to see this extra footage I am not sure I could sit through a near three hour cut of Airport '77. As expected the film has dated badly with horrible fashions & interior design choices, I will say no more other than the toy plane model effects aren't great either. Along with the other two Airport sequels this takes pride of place in the Razzie Award's Hall of Shame although I can think of lots of worse films than this so I reckon that's a little harsh. The action scenes are a little dull unfortunately, the pace is slow & not much excitement or tension is generated which is a shame as I reckon this could have been a pretty good film if made properly.<br /><br />The production values are alright if nothing spectacular. The acting isn't great, two time Oscar winner Jack Lemmon has said since it was a mistake to star in this, one time Oscar winner James Stewart looks old & frail, also one time Oscar winner Lee Grant looks drunk while Sir Christopher Lee is given little to do & there are plenty of other familiar faces to look out for too.<br /><br />Airport '77 is the most disaster orientated of the three Airport films so far & I liked the ideas behind it even if they were a bit silly, the production & bland direction doesn't help though & a film about a sunken plane just shouldn't be this boring or lethargic. Followed by The Concorde ... Airport '79 (1979).\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b\"This film lacked something I couldn't put my finger on at first: charisma on the part of the leading actress. This inevitably translated to lack of chemistry when she shared the screen with her leading man. Even the romantic scenes came across as being merely the actors at play. It could very well have been the director who miscalculated what he needed from the actors. I just don't know.<br /><br />But could it have been the screenplay? Just exactly who was the chef in love with? He seemed more enamored of his culinary skills and restaurant, and ultimately of himself and his youthful exploits, than of anybody or anything else. He never convinced me he was in love with the princess.<br /><br />I was disappointed in this movie. But, don't forget it was nominated for an Oscar, so judge for yourself.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x, y in imdb_dataset(train_pos, train_neg).take(3):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.6 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for x, y in imdb_dataset(train_pos, train_neg).repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative, n_read_threads=5):\n",
    "    dataset_neg = tf.data.TextLineDataset(filepaths_negative, \n",
    "                                          num_parallel_reads=n_read_threads)\n",
    "    dataset_neg = dataset_neg.map(lambda review: (review, 0))\n",
    "    dataset_pos = tf.data.TextLineDataset(filepaths_positive, \n",
    "                                         num_parallel_reads = n_read_threads)\n",
    "    dataset_pos = dataset_pos.map(lambda review: (review, 1))\n",
    "    return tf.data.Dataset.concatenate(dataset_pos, dataset_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for x, y in imdb_dataset(train_pos, train_neg).repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.2 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for x, y in imdb_dataset(train_pos, train_neg).cache().repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_set = imdb_dataset(train_pos, train_neg).shuffle(25000).batch(batch_size).prefetch(1)\n",
    "valid_set = imdb_dataset(valid_pos, valid_neg).batch(batch_size).prefetch(1)\n",
    "test_set = imdb_dataset(test_pos, test_neg).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x_batch, n_words=50):\n",
    "    shape = tf.shape(x_batch) * tf.constant([1, 0]) + tf.constant([0, n_words])\n",
    "    z = tf.strings.substr(x_batch, 0, 300)\n",
    "    z = tf.strings.lower(z)\n",
    "    z = tf.strings.regex_replace(z, b\"<br\\\\s*/?>\", b\" \")\n",
    "    z = tf.strings.regex_replace(z, b\"[^a-z]\", b\" \")\n",
    "    z = tf.strings.split(z)\n",
    "    return z.to_tensor(shape=shape, default_value=b\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=string, numpy=\n",
       "array([[b'it', b's', b'a', b'great', b'great', b'movie', b'i', b'loved',\n",
       "        b'it', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
       "       [b'it', b'was', b'terrible', b'run', b'away', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>']], dtype=object)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_example = tf.constant([\"It's a great, great movie! I loved it.\", \"It was terrible, run away!!!\"])\n",
    "preprocess(x_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_vocabulary(data_sample, max_size=1000):\n",
    "    preprocessed_reviews = preprocess(data_sample).numpy()\n",
    "    counter = Counter()\n",
    "    for words in preprocessed_reviews:\n",
    "        for word in words:\n",
    "            if word != b\"<pad>\":\n",
    "                counter[word] += 1\n",
    "    return [b\"<pad>\"] + [word for word, count in counter.most_common(max_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>',\n",
       " b'it',\n",
       " b'great',\n",
       " b's',\n",
       " b'a',\n",
       " b'movie',\n",
       " b'i',\n",
       " b'loved',\n",
       " b'was',\n",
       " b'terrible',\n",
       " b'run',\n",
       " b'away']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vocabulary(x_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextVectorization(keras.layers.Layer):\n",
    "    def __init__(self, max_vocabulary_size=1000, n_oov_buckets=100, \n",
    "                 dtype=tf.string, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.max_vocabulary_size = max_vocabulary_size\n",
    "        self.n_oov_buckets = n_oov_buckets\n",
    "    \n",
    "    def adapt(self, data_sample):\n",
    "        self.vocab = get_vocabulary(data_sample, self.max_vocabulary_size)\n",
    "        words = tf.constant(self.vocab)\n",
    "        word_ids = tf.range(len(self.vocab), dtype=tf.int64)\n",
    "        vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "        self.table = tf.lookup.StaticVocabularyTable(vocab_init, self.n_oov_buckets)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        preprocessed_inputs = preprocess(inputs)\n",
    "        return self.table.lookup(preprocessed_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[ 1,  3,  4,  2,  2,  5,  6,  7,  1,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 1,  8,  9, 10, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0]], dtype=int64)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization = TextVectorization()\n",
    "text_vectorization.adapt(x_example)\n",
    "text_vectorization(x_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocabulary_size = 1000\n",
    "n_oov_buckets = 100\n",
    "\n",
    "sample_review_batches = train_set.map(lambda review, label: review)\n",
    "sample_reviews = np.concatenate(list(sample_review_batches.as_numpy_iterator()), \n",
    "                                axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (None,), types: tf.string>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(max_vocabulary_size, n_oov_buckets, \n",
    "                                      input_shape=[])\n",
    "text_vectorization.adapt(sample_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_vectorization.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[  9,  14,   2,  64,  64,  12,   5, 256,   9,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  9,  13, 269, 531, 335,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization(x_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>', b'the', b'a', b'of', b'and', b'i', b'to', b'is', b'this', b'it']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[2., 2., 0., 1.],\n",
       "       [3., 0., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_example = tf.constant([[1, 3, 1, 0, 0], [2, 2, 0, 0, 0]])\n",
    "tf.reduce_sum(tf.one_hot(simple_example, 4), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWords(keras.layers.Layer):\n",
    "    def __init__(self, n_tokens, dtype=tf.int32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.n_tokens = n_tokens\n",
    "    def call(self, inputs):\n",
    "        one_hot = tf.one_hot(inputs, self.n_tokens)\n",
    "        return tf.reduce_sum(one_hot, axis=1)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[2., 0., 1.],\n",
       "       [0., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = BagOfWords(n_tokens=4)\n",
    "bag_of_words(simple_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = max_vocabulary_size + n_oov_buckets + 1\n",
    "bag_of_words = BagOfWords(n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 30s 34ms/step - loss: 0.5838 - accuracy: 0.6737 - val_loss: 0.5105 - val_accuracy: 0.7391\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 9s 8ms/step - loss: 0.4638 - accuracy: 0.7770 - val_loss: 0.5102 - val_accuracy: 0.7428\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 9s 8ms/step - loss: 0.4129 - accuracy: 0.8107 - val_loss: 0.5152 - val_accuracy: 0.7347\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 9s 8ms/step - loss: 0.3483 - accuracy: 0.8535 - val_loss: 0.5382 - val_accuracy: 0.7346\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 9s 8ms/step - loss: 0.2641 - accuracy: 0.9071 - val_loss: 0.5761 - val_accuracy: 0.7309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x207b9db5088>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    text_vectorization,\n",
    "    bag_of_words,\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_embedding(inputs):\n",
    "    not_pad = tf.math.count_nonzero(inputs, axis=-1)\n",
    "    n_words = tf.math.count_nonzero(not_pad, axis=-1, keepdims=True)\n",
    "    sqrt_n_words = tf.math.sqrt(tf.cast(n_words, tf.float32))\n",
    "    return tf.reduce_mean(inputs, axis=1) * sqrt_n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_example = tf.constant([[[1., 2., 3.], [4., 5., 0.], [0., 0., 0.]],\n",
    "                               [[6., 0., 0.], [0., 0., 0.], [0., 0., 0.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int64, numpy=\n",
       "array([[2],\n",
       "       [1]], dtype=int64)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.count_nonzero(tf.math.count_nonzero(another_example, axis=-1), axis=-1,\n",
    "                     keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [1.]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.constant([[2], [1]]), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[2.3570225, 3.2998314, 1.4142135],\n",
       "       [2.       , 0.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mean_embedding(another_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 20\n",
    "model = keras.models.Sequential([\n",
    "    text_vectorization,\n",
    "    keras.layers.Embedding(input_dim=n_tokens,\n",
    "                          output_dim=embedding_size,\n",
    "                          mask_zero=True),\n",
    "    keras.layers.Lambda(compute_mean_embedding),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 7s 5ms/step - loss: 0.6057 - accuracy: 0.6517 - val_loss: 0.5138 - val_accuracy: 0.7386\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 6s 5ms/step - loss: 0.4917 - accuracy: 0.7553 - val_loss: 0.5076 - val_accuracy: 0.7394\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 6s 5ms/step - loss: 0.4804 - accuracy: 0.7638 - val_loss: 0.5191 - val_accuracy: 0.7340\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 6s 5ms/step - loss: 0.4734 - accuracy: 0.7628 - val_loss: 0.5083 - val_accuracy: 0.7413\n",
      "Epoch 5/5\n",
      "760/782 [============================>.] - ETA: 0s - loss: 0.4688 - accuracy: 0.7652"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2",
   "language": "python",
   "name": "tensorflow_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
